[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02\n\n\n\n\n\n\nPython\n\n\nPyTorch\n\n\nMachine Learning\n\n\nGradient Descent\n\n\n\n\n\n\n\n\n\nJul 5, 2023\n\n\nLinus Lach\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01\n\n\n\n\n\n\nPython\n\n\nPyTorch\n\n\nMachine Learning\n\n\nLogistic Regression\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\nLinus Lach\n\n\n\n\n\n\n\n\n\n\n\n\nAn Introduction to Optimal Control\n\n\n\n\n\n\nPython\n\n\nOptimal Control\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\nLinus Lach\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Pytorch/Post_01.html",
    "href": "posts/Pytorch/Post_01.html",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01",
    "section": "",
    "text": "In this series of blog posts, I’d like to introduce some fundamentals of the PyTorch framework and neural networks. If you haven’t lived under a rock like me for the past few years, you have probably already heard some things about those magical ✨neural networks✨ and their applications like ChatGPT.\nThe structure of this post is as follows: First, we familiarize ourselves a bit with the PyTorch framework. To build on this newly gained knowledge, we build a logistic model with PyTorch and gain some understanding about the binary cross-entropy loss in a theoretical setting. In the final part we will learn how to train our logistic regression model to achieve a good fit on given data.\n\n\n\n#Some packages needed throughout the article\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nOne of the most basic objects within the PyTorch framework is a tensor, which can be thought of as a scalar, vector, or matrix depending on how it is used. The basic syntax is as follows. The datatype can also be specified which will be important later on for classification tasks.\n\nx = torch.tensor([0])\ny = torch.tensor([0.0,1.0,2.0])\nz = torch.tensor([[1,-1,1],[0,1,0],[0,0,1]])\nprint('x = ',x,'\\n',\"y = \",y,'\\n',\"z = \",z)\n\nx =  tensor([0]) \n y =  tensor([0., 1., 2.]) \n z =  tensor([[ 1, -1,  1],\n        [ 0,  1,  0],\n        [ 0,  0,  1]])\n\n\nIn the code above, x represents a scalar, y a vector, and z a matrix. Note, that in the vector y we did not use the default datatype which is long or more specifically torch.LongTensor rather than float or torch.FloatTensor which is automatically assigned when using floating point notation. The data type can also be specified manually by setting the dtype argument to the desired type and can be checked with the .type() method or dtype attribute.\n\nprint(\"x.type() = \",x.type(),'\\n',\"x.dtype = \",x.dtype)\n\nx.type() =  torch.LongTensor \n x.dtype =  torch.int64\n\n\nNote that torch.LongTensor and torch.int64 are synonyms and both refer to the 64-bit signed integer type. Similar to lists in the numpy or base python framework, elements of a tensor can be accessed via their respective indexes.\n\nprint(\"The first element of x:\", x[0])\nprint(\"The second column of the matrix z:\", z[:,1])\n\nThe first element of x: tensor(0)\nThe second column of the matrix z: tensor([-1,  1,  0])\n\n\nWe can also work with tensors in functions which will be of more importance in the later sections. Furthermore, without additional settings, tensors can be plotted by using the familiar pyplot package. See the example below.\n\nx = torch.arange(-3,3,0.1)\n\ndef f(t):\n    return 1/(1+torch.exp(-2*t))\n\nplt.plot(x,f(x));\n\n\n\n\n\n\n\n\nNote, that syntax in PyTorch is quite similar to the syntax of the Numpy package (e.g. torch.arange has the same functionality as np.arange and accessing elements in a tensor works analogously to simple Python lists). Thus, it is obvious to ask why we should use the PyTorch framework to begin with. The answer to that question is, that we can conveniently calculate derivatives within the PyTorch framework. To do so, we need to set the requires_grad parameter for a given tensor to True. Check out the following example:\n\nx = torch.tensor([1.], requires_grad= True)\nprint(\"f(x) = f(1) =\", f(x))\nf(x).backward()\nprint(x.grad)\n\nf(x) = f(1) = tensor([0.8808], grad_fn=&lt;MulBackward0&gt;)\ntensor([0.2100])\n\n\nWe first define a tensor x with the requires_grad parameter set to True which allows us to calculate the derivative of any function that takes x as an input. Without getting into too much detail, note that the return value of f(x) is now a tensor with the additional grad_fn attribute, which is a pointer into a graph storing the data created by the operations on the tensor. For more details see Autograd Mechanics. By plugging x into the previously defined function f and calling the method backward() we calculate the derivative of f in the point x. The result can then be viewed by calling the x.grad attribute. If we call x.grad without previously plugging x into a function the return value will be None as there is no gradient to be calculated.\nCalculating the derivative over a range of values requires a small adjustment to the code. The backward() method stores the values of the gradient of any function in x.grad as we have seen in the example above. Thus, x.grad needs to have the same shape as x. However, if x is not a scalar, i.e., a list of values, f(x).backward() would try to calculate the derivative of each element in f(x) with respect to every element in the list x. This dimension mismatch can be solved by setting the gradient to torch.ones_like(x) which calculates the gradient of each element in f(x) with respect to the corresponding element in x.\nTo plot the results with pyplot, we have to detach the gradients (i.e., the pointer into the graph) from the vectors to handle tensors like numpy lists.\n\nx = torch.arange(-3, 3, 0.1, requires_grad = True)\nf(x).backward(gradient=torch.ones_like(x))\nplt.plot(x.detach(),f(x).detach(), label = \"$f(x)$\")\nplt.plot(x.detach(),x.grad.detach(), label = \" $\\dfrac{\\partial}{\\partial x} f(x)$\")\nplt.legend();\n\n\n\n\n\n\n\n\n\n\n\nNow, that we have established a very basic understanding of the PyTorch module, we can move on to some basic applied statistics aka ✨machine learning✨. A brief recap of logistic regression and linear models serves as a great introduction to classification problems in a mathematical way. Let us assume that we have a one-dimensional input, i.e., \\(x\\in\\mathbb{R}\\), and two classes labeled \\(0\\) and \\(1\\), i.e., \\(y\\in\\{0,1\\}\\). The main idea is to tackle a binary classification problem (e.g. will a loan default? Does the picture show a cat?). In theory, a simple linear model is applied to the data and then plugged into the sigmoid function, i.e., let the linear model be given by \\[\\begin{equation}\n\\hat y = b+w* x\n\\end{equation}\\] where \\(\\hat y\\) is the estimate of \\(y\\) given the parameters \\(b\\) and \\(w\\) and the input \\(x\\). Then, the value of the logistic model is given by \\[\\begin{equation}\n\\sigma(\\hat y) = \\sigma(b+w*x) = \\frac{1}{1+\\exp(-1*(b+w*x))}.\n\\end{equation}\\] The output of the sigmoid function \\(\\sigma\\) can be interpreted as a probability of a feature \\(x\\) belonging either to class \\(0\\) or \\(1\\). If for a given feature \\(x\\) the value of \\(\\sigma(\\hat y)\\) is closer to \\(1\\) we can say that it belongs to class \\(1\\) with probability \\(\\sigma(\\hat y)\\), whereas a small value of \\(\\sigma(\\hat y)\\) can be interpreted as \\(x\\) belonging to class \\(0\\) with probability \\(1-\\sigma(\\hat y)\\).\n\n# Create a dataset class that produces our example data\n\nclass Data_2(Dataset):\n\n    def __init__(self, soft_max=False):\n        self.x = torch.arange(-2, 2, 0.1).view(-1, 1)\n        if soft_max:\n            self.y = torch.zeros(self.x.shape[0])\n        else:\n            self.y = torch.zeros(self.x.shape[0], 1)\n        self.y[self.x[:, 0] &gt; 0.5] = 1\n        if soft_max:\n            self.y = self.y.type(torch.LongTensor)\n        self.len = self.x.shape[0]\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n\n    def __len__(self):\n        return self.len\n\n# A function for plotting the data and model results\n\ndef plot_data_2(data, model = None, est_line=False, soft_max=False):\n    if est_line:\n        plt.plot(data.x,\n                 torch.sigmoid(list(model.parameters())[0].item() * data.x + list(model.parameters())[1].item()),\n                 color='black',\n                 label='estimated decision boundary')\n    if soft_max:\n        X = data[:][0]\n        y_label = ['yhat=0', 'yhat=1']\n        y_color = ['r', 'b']\n        Y = []\n        for w, b, y_l, y_c in zip(model.state_dict()['0.weight'], model.state_dict()['0.bias'], y_label, y_color):\n            Y.append((w * X + b).numpy())\n            plt.plot(X.numpy(), (w * X + b).numpy(), y_c, label=y_l)\n    plt.plot(data.x.numpy()[(data.y == 0)], data.y.numpy()[(data.y == 0)], 'ro', label=\"class 0\")\n    plt.plot(data.x.numpy()[(data.y == 1)], data.y.numpy()[(data.y == 1)], 'bo', label=\"class 1\")\n    plt.legend()\n    plt.ylim(-0.5, 3)\n    plt.show()\n\nConsider the following dataset consisting of two classes labeled \\(0\\) and \\(1\\). Then, the goal is to apply the theoretic results from above in order to find the optimal parameters \\(b\\) and \\(w\\).\n\ndata_2 = Data_2()\nplot_data_2(data_2)\n\n\n\n\n\n\n\n\nThe parameters of the best fitting line can be either be calculated explicitly in the case of a standard linear model, or by minimizing some error term numerically. We will focus on the latter, as our models and the underlying data will be increasingly more complicated. We can build a linear model in PyTorch as we would do in base Python.\n\ndef forward(x,b = 0, w = 2):\n    return b + w * x\n\nThen, by applying the sigmoid function we obtain the logistic model.\n\ndef forward(x, b= 0, w = 2):\n    return 1/(1+torch.exp(-1*(b + w * x)))\n\n\nx = torch.arange(-2,2,0.1)\nplt.plot(x,forward(x));\n\n\n\n\n\n\n\n\nInstead of using our custom function, we can also use the nn.Linear submodule. The nn.Linear submodule applies a linear transformation to the incoming data in the same way as the forward function. However, we can specify the input and output dimensions directly and do not have to bother with that any further. Check out the example below.\n\ndim_in = 2; dim_out = 1\nf = nn.Linear(dim_in,dim_out)\nx = torch.tensor([0.0,1.0])\nprint(f(x))\n\ntensor([-0.5982], grad_fn=&lt;AddBackward0&gt;)\n\n\nThe weight and bias of the module instance f can be accessed via the state_dict method, which stores the weights and biases of the model:\n\nprint(\"weights: \",f.state_dict()['weight'],'\\n', \"bias: \", f.state_dict()['bias'])\n\nweights:  tensor([[-0.6328, -0.1698]]) \n bias:  tensor([-0.4284])\n\n\nNote that the weights are assigned randomly. The reason is that randomized initial weights generally lead to a better performance of the model during the training phase. We can now define our first model:\n\nclass Logistic_regression(nn.Module):\n    def __init__(self,n_inputs):\n        super(Logistic_regression, self).__init__()\n        self.linear = nn.Linear(n_inputs,1)\n        \n    def forward(self,x):\n        return torch.sigmoid(self.linear(x))\n\nInstead of defining a simple logistic model in the form of a function as above, we define the model as a class. Defining the model as a class allows us to work with several instances/objects of the class at the same time without a need for code duplication. The class structure can be explained as follows. The nn.Module class is passed as a superclass, meaning that our class can inherit all the submodules, to all the models we will be building. Those pre-programmed submodules include the nn.Linear model which we will be using a lot. If nn.Module is passed as a superclass , the __init__ and forward functions have to be specified manually. Considering the __init__ method, it is directly inherited from the nn.Module class and a linear variable is defined. The forward function is the key to our logistic model as it takes a tensor x as an input and returns the sigmoid function applied to the output of the linear model. Let us create an instance of the logistic model defined above and see what it looks like.\n\nmodel = Logistic_regression(1)\nx = torch.arange(-2,2,0.1).view(-1,1)\nplot_data_2(data_2, model = model, est_line=True)\n\n\n\n\n\n\n\n\nNeedless to say, the model above does a bad job of classifying the data correctly. Thus, let’s train our model, i.e., find a good fit for the parameters. Before doing that, let’s talk briefly about loss functions, in particular, the binary cross entropy loss and how it’s derived. In case you’re not interested in the mathematical nitty-gritty details, you can skip the following paragraph.\n\n\n\nAssume we have a two-class classification problem with class labels \\(0\\) and \\(1\\), and a labeled data-sample \\((x_1,y_1),...,(x_N,y_N),, N\\in\\mathbb{N}\\) with \\(x_i \\in\\mathbb{R}\\) for all \\(i\\in\\{1,...,N\\}\\). Let’s say there is some \\(n \\in\\mathbb{N}\\) with \\(1&lt;n&lt;N\\) such that \\(y_i = 0\\) for all \\(i&lt;n\\) and \\(y_i = 1\\) for all \\(i\\geq n\\), i.e. the data is linearly separable. Then, we are interested in maximizing the probability \\[\\begin{equation}\n    \\mathbb{P}(Y|wX+b):=\\prod_{i=1}^{n-1}\\mathbb{P}(y_i= 0|wx_i+b)\\prod_{i=n}^{N}\\mathbb{P}(y_i= 1|wx_i+b),\n\\end{equation}\\] where \\(Y=(y_1,...,y_N)\\), \\(X = (x_1,...,x_N)\\), and \\(w,b \\in\\mathbb{R}\\), as this yields the optimal estimation for the parameters \\(w\\) and \\(b\\).\nNote, that \\[\\begin{align}\n   \\mathbb{P}(y_i= 0|wx_i+b) &= 1-\\sigma(wx_i+b),\\\\\n   \\mathbb{P}(y_i= 1|wx_i+b) &= \\sigma(wx_i+b),\n\\end{align}\\] where \\(\\sigma\\) denotes the sigmoid function, i.e., \\(\\sigma:\\mathbb{R}\\to [0,1],\\,\\sigma(x) = \\frac{e^x}{e^x+1}\\). Then, \\[\\begin{align}\n    \\mathbb{P}(Y|wX+b) = \\prod_{i=1}^{n-1}1-\\sigma(wx_i+b)\\prod_{i=n}^{N}\\sigma(wx_i+b).\n\\end{align}\\] Since \\(y_i \\in\\{0,1\\}\\) for all \\(i\\in\\{1,...,N\\}\\), the expression above is equivalent to \\[\\begin{equation}\n    \\mathbb{P}(Y|wX+b) = \\prod_{i=1}^{N}(1-\\sigma(wx_i+b))^{1-y_i}\\sigma(wx_i+b)^{y_i}\n\\end{equation}\\] which can be maximized by applying maximum likelihood estimation.\nRecall, that \\[\\begin{equation}\n    \\underset{w,b}{\\text{argmax }}\\mathbb{P}(Y|wX+b) = \\underset{w,b}{\\text{argmax }}\\log\\left(\\mathbb{P}(Y|wX+b)\\right),\n\\end{equation}\\] since the logarithm is monotonically increasing. Thus, we can apply the logarithm to \\(\\mathbb{P}(Y|wX+b)\\) which yields \\[\\begin{align}\n    \\log\\left(\\mathbb{P}(Y|wX+b)\\right) &= \\sum_{n=1}^{N}\\log\\left((1-\\sigma(wx_i+b))^{1-y_i}\\cdot\\sigma(wx_i+b)^{y_i}\\right)\\\\\n                                        &= \\sum_{n=1}^{N}(1-y_i)\\log(1-\\sigma(wx_i+b))\\cdot y_i\\log(\\sigma(wx_i+b))\n\\end{align}\\] Instead of maximizing \\(\\log\\left(\\mathbb{P}(Y|wX+b)\\right)\\) we can equivalently minimize \\((-1)\\log\\left(\\mathbb{P}(Y|wX+b)\\right)\\). We can also average the latter which yields \\[\\begin{align}\n     -\\frac{1}{N}\\log\\left(\\mathbb{P}(Y|wX+b)\\right) &= -\\frac{1}{N}\\sum_{n=1}^{N}(1-y_i)\\log(1-\\sigma(wx_i+b))\\cdot y_i\\log(\\sigma(wx_i+b))\\\\\n     &=-\\frac{1}{N}\\sum_{n=1}^{N}(1-y_i)\\log(1-\\hat y_i)\\cdot y_i\\log(\\hat y_i) =: \\text{CEL}(\\hat Y, Y),\n\\end{align}\\] where \\(\\hat y = \\sigma(wx+b)\\). \\(\\text{CEL}(\\hat Y, Y)\\) is nothing but the binary cross-entropy loss. The binary cross-entropy loss can then be minimized by applying an appropriate algorithm like (stochastic) gradient descent, which will be covered in the next post. Implementing the binary cross-entropy loss in PyTorch works as follows. Note, that by adding the parameter \\(\\varepsilon\\) we avoid having to deal with singularities of the logarithm.\n\ndef BinaryCELoss(yhat,y):\n    eps = 9e-10\n    return -1*torch.mean(y*torch.log(yhat+eps)+(1-y)*torch.log(1-yhat+eps))\n\n\n\n\nIn order to train the model, we have to take care of some initial steps:\n\nDefine a model instance (that will be trained) of the previously built class.\nSet a learning rate for the optimization algorithm (this will also be elaborated on in the next post).\nSet a loss function (like the BinaryCELoss we defined above) and an optimizer (like PyTorchs stochastic gradient descent optimizer).\n\n\nmodel = Logistic_regression(1)\nlr = 0.1\noptimizer = torch.optim.SGD(model.parameters(),lr=lr)\n\nTraining the model usually works as follows:\n\nWe define a train_model method which takes the number of training steps (or formally epochs) as an input.\nThe LOSS_Custom and LOSS lists are used to store the loss of the model depending on the loss function.\nFor each epoch we perform the actual training:\n\nFirst, we calculate the estimate \\(\\hat y\\).\nThen, we calculate the loss of our estimate and the true class labels and add them to the LOSS List\nAfter calculating the loss, we calculate the gradient by using the backward.\n\n\n\ndef train_model(epochs):\n    LOSS = []\n    for iter in range(epochs):\n        yhat = model(data_2.x)\n        loss = BinaryCELoss(yhat,data_2.y)\n        LOSS.append(loss.data)\n        loss.backward()\n        optimizer.step()\n    plot_data_2(data_2, model, est_line = True)\n    plt.plot(np.arange(0,epochs,1),LOSS)\n    plt.title(\"Loss during different epochs\")\n\n\nest = train_model(200)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe accuracy of the model can be calculated as follows:\n\nSet the estimates \\(\\hat y\\) to True (corresponding to class \\(1\\)) if \\(\\hat y\\) is bigger than \\(0.5\\) and to False if \\(\\hat y \\leq 0.5\\) (corresponding to class \\(0\\)) and save them in a list called label.\nConvert the true labels \\(y\\) to a ByteTensor which takes the values 0 or 1 and compares them to the label list.\nTaking the mean returns a value between \\(0\\) and \\(1\\), where \\(1\\) stands for a perfect accuracy.\n\n\nyhat = model(data_2.x)\nlabel = yhat &gt; 0.5\nprint(\"Accuracy: \",torch.mean((label==data_2.y.type(torch.ByteTensor)).type(torch.float)))\n\nAccuracy:  tensor(1.)\n\n\n\n\n\nIn this short introduction, we reviewed logistic regression and learned how to implement it using the PyTorch framework. Additionally, we familiarised ourselves with the binary cross-entropy loss and learned how to train a simple model using (stochastic) gradient descent. In the next post, we’ll take a closer look at gradient descent in one dimension."
  },
  {
    "objectID": "posts/Pytorch/Post_01.html#pytorch-and-tensors",
    "href": "posts/Pytorch/Post_01.html#pytorch-and-tensors",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01",
    "section": "",
    "text": "#Some packages needed throughout the article\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nOne of the most basic objects within the PyTorch framework is a tensor, which can be thought of as a scalar, vector, or matrix depending on how it is used. The basic syntax is as follows. The datatype can also be specified which will be important later on for classification tasks.\n\nx = torch.tensor([0])\ny = torch.tensor([0.0,1.0,2.0])\nz = torch.tensor([[1,-1,1],[0,1,0],[0,0,1]])\nprint('x = ',x,'\\n',\"y = \",y,'\\n',\"z = \",z)\n\nx =  tensor([0]) \n y =  tensor([0., 1., 2.]) \n z =  tensor([[ 1, -1,  1],\n        [ 0,  1,  0],\n        [ 0,  0,  1]])\n\n\nIn the code above, x represents a scalar, y a vector, and z a matrix. Note, that in the vector y we did not use the default datatype which is long or more specifically torch.LongTensor rather than float or torch.FloatTensor which is automatically assigned when using floating point notation. The data type can also be specified manually by setting the dtype argument to the desired type and can be checked with the .type() method or dtype attribute.\n\nprint(\"x.type() = \",x.type(),'\\n',\"x.dtype = \",x.dtype)\n\nx.type() =  torch.LongTensor \n x.dtype =  torch.int64\n\n\nNote that torch.LongTensor and torch.int64 are synonyms and both refer to the 64-bit signed integer type. Similar to lists in the numpy or base python framework, elements of a tensor can be accessed via their respective indexes.\n\nprint(\"The first element of x:\", x[0])\nprint(\"The second column of the matrix z:\", z[:,1])\n\nThe first element of x: tensor(0)\nThe second column of the matrix z: tensor([-1,  1,  0])\n\n\nWe can also work with tensors in functions which will be of more importance in the later sections. Furthermore, without additional settings, tensors can be plotted by using the familiar pyplot package. See the example below.\n\nx = torch.arange(-3,3,0.1)\n\ndef f(t):\n    return 1/(1+torch.exp(-2*t))\n\nplt.plot(x,f(x));\n\n\n\n\n\n\n\n\nNote, that syntax in PyTorch is quite similar to the syntax of the Numpy package (e.g. torch.arange has the same functionality as np.arange and accessing elements in a tensor works analogously to simple Python lists). Thus, it is obvious to ask why we should use the PyTorch framework to begin with. The answer to that question is, that we can conveniently calculate derivatives within the PyTorch framework. To do so, we need to set the requires_grad parameter for a given tensor to True. Check out the following example:\n\nx = torch.tensor([1.], requires_grad= True)\nprint(\"f(x) = f(1) =\", f(x))\nf(x).backward()\nprint(x.grad)\n\nf(x) = f(1) = tensor([0.8808], grad_fn=&lt;MulBackward0&gt;)\ntensor([0.2100])\n\n\nWe first define a tensor x with the requires_grad parameter set to True which allows us to calculate the derivative of any function that takes x as an input. Without getting into too much detail, note that the return value of f(x) is now a tensor with the additional grad_fn attribute, which is a pointer into a graph storing the data created by the operations on the tensor. For more details see Autograd Mechanics. By plugging x into the previously defined function f and calling the method backward() we calculate the derivative of f in the point x. The result can then be viewed by calling the x.grad attribute. If we call x.grad without previously plugging x into a function the return value will be None as there is no gradient to be calculated.\nCalculating the derivative over a range of values requires a small adjustment to the code. The backward() method stores the values of the gradient of any function in x.grad as we have seen in the example above. Thus, x.grad needs to have the same shape as x. However, if x is not a scalar, i.e., a list of values, f(x).backward() would try to calculate the derivative of each element in f(x) with respect to every element in the list x. This dimension mismatch can be solved by setting the gradient to torch.ones_like(x) which calculates the gradient of each element in f(x) with respect to the corresponding element in x.\nTo plot the results with pyplot, we have to detach the gradients (i.e., the pointer into the graph) from the vectors to handle tensors like numpy lists.\n\nx = torch.arange(-3, 3, 0.1, requires_grad = True)\nf(x).backward(gradient=torch.ones_like(x))\nplt.plot(x.detach(),f(x).detach(), label = \"$f(x)$\")\nplt.plot(x.detach(),x.grad.detach(), label = \" $\\dfrac{\\partial}{\\partial x} f(x)$\")\nplt.legend();"
  },
  {
    "objectID": "posts/Pytorch/Post_01.html#logistic-regression-with-two-class-datasets",
    "href": "posts/Pytorch/Post_01.html#logistic-regression-with-two-class-datasets",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01",
    "section": "",
    "text": "Now, that we have established a very basic understanding of the PyTorch module, we can move on to some basic applied statistics aka ✨machine learning✨. A brief recap of logistic regression and linear models serves as a great introduction to classification problems in a mathematical way. Let us assume that we have a one-dimensional input, i.e., \\(x\\in\\mathbb{R}\\), and two classes labeled \\(0\\) and \\(1\\), i.e., \\(y\\in\\{0,1\\}\\). The main idea is to tackle a binary classification problem (e.g. will a loan default? Does the picture show a cat?). In theory, a simple linear model is applied to the data and then plugged into the sigmoid function, i.e., let the linear model be given by \\[\\begin{equation}\n\\hat y = b+w* x\n\\end{equation}\\] where \\(\\hat y\\) is the estimate of \\(y\\) given the parameters \\(b\\) and \\(w\\) and the input \\(x\\). Then, the value of the logistic model is given by \\[\\begin{equation}\n\\sigma(\\hat y) = \\sigma(b+w*x) = \\frac{1}{1+\\exp(-1*(b+w*x))}.\n\\end{equation}\\] The output of the sigmoid function \\(\\sigma\\) can be interpreted as a probability of a feature \\(x\\) belonging either to class \\(0\\) or \\(1\\). If for a given feature \\(x\\) the value of \\(\\sigma(\\hat y)\\) is closer to \\(1\\) we can say that it belongs to class \\(1\\) with probability \\(\\sigma(\\hat y)\\), whereas a small value of \\(\\sigma(\\hat y)\\) can be interpreted as \\(x\\) belonging to class \\(0\\) with probability \\(1-\\sigma(\\hat y)\\).\n\n# Create a dataset class that produces our example data\n\nclass Data_2(Dataset):\n\n    def __init__(self, soft_max=False):\n        self.x = torch.arange(-2, 2, 0.1).view(-1, 1)\n        if soft_max:\n            self.y = torch.zeros(self.x.shape[0])\n        else:\n            self.y = torch.zeros(self.x.shape[0], 1)\n        self.y[self.x[:, 0] &gt; 0.5] = 1\n        if soft_max:\n            self.y = self.y.type(torch.LongTensor)\n        self.len = self.x.shape[0]\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n\n    def __len__(self):\n        return self.len\n\n# A function for plotting the data and model results\n\ndef plot_data_2(data, model = None, est_line=False, soft_max=False):\n    if est_line:\n        plt.plot(data.x,\n                 torch.sigmoid(list(model.parameters())[0].item() * data.x + list(model.parameters())[1].item()),\n                 color='black',\n                 label='estimated decision boundary')\n    if soft_max:\n        X = data[:][0]\n        y_label = ['yhat=0', 'yhat=1']\n        y_color = ['r', 'b']\n        Y = []\n        for w, b, y_l, y_c in zip(model.state_dict()['0.weight'], model.state_dict()['0.bias'], y_label, y_color):\n            Y.append((w * X + b).numpy())\n            plt.plot(X.numpy(), (w * X + b).numpy(), y_c, label=y_l)\n    plt.plot(data.x.numpy()[(data.y == 0)], data.y.numpy()[(data.y == 0)], 'ro', label=\"class 0\")\n    plt.plot(data.x.numpy()[(data.y == 1)], data.y.numpy()[(data.y == 1)], 'bo', label=\"class 1\")\n    plt.legend()\n    plt.ylim(-0.5, 3)\n    plt.show()\n\nConsider the following dataset consisting of two classes labeled \\(0\\) and \\(1\\). Then, the goal is to apply the theoretic results from above in order to find the optimal parameters \\(b\\) and \\(w\\).\n\ndata_2 = Data_2()\nplot_data_2(data_2)\n\n\n\n\n\n\n\n\nThe parameters of the best fitting line can be either be calculated explicitly in the case of a standard linear model, or by minimizing some error term numerically. We will focus on the latter, as our models and the underlying data will be increasingly more complicated. We can build a linear model in PyTorch as we would do in base Python.\n\ndef forward(x,b = 0, w = 2):\n    return b + w * x\n\nThen, by applying the sigmoid function we obtain the logistic model.\n\ndef forward(x, b= 0, w = 2):\n    return 1/(1+torch.exp(-1*(b + w * x)))\n\n\nx = torch.arange(-2,2,0.1)\nplt.plot(x,forward(x));\n\n\n\n\n\n\n\n\nInstead of using our custom function, we can also use the nn.Linear submodule. The nn.Linear submodule applies a linear transformation to the incoming data in the same way as the forward function. However, we can specify the input and output dimensions directly and do not have to bother with that any further. Check out the example below.\n\ndim_in = 2; dim_out = 1\nf = nn.Linear(dim_in,dim_out)\nx = torch.tensor([0.0,1.0])\nprint(f(x))\n\ntensor([-0.5982], grad_fn=&lt;AddBackward0&gt;)\n\n\nThe weight and bias of the module instance f can be accessed via the state_dict method, which stores the weights and biases of the model:\n\nprint(\"weights: \",f.state_dict()['weight'],'\\n', \"bias: \", f.state_dict()['bias'])\n\nweights:  tensor([[-0.6328, -0.1698]]) \n bias:  tensor([-0.4284])\n\n\nNote that the weights are assigned randomly. The reason is that randomized initial weights generally lead to a better performance of the model during the training phase. We can now define our first model:\n\nclass Logistic_regression(nn.Module):\n    def __init__(self,n_inputs):\n        super(Logistic_regression, self).__init__()\n        self.linear = nn.Linear(n_inputs,1)\n        \n    def forward(self,x):\n        return torch.sigmoid(self.linear(x))\n\nInstead of defining a simple logistic model in the form of a function as above, we define the model as a class. Defining the model as a class allows us to work with several instances/objects of the class at the same time without a need for code duplication. The class structure can be explained as follows. The nn.Module class is passed as a superclass, meaning that our class can inherit all the submodules, to all the models we will be building. Those pre-programmed submodules include the nn.Linear model which we will be using a lot. If nn.Module is passed as a superclass , the __init__ and forward functions have to be specified manually. Considering the __init__ method, it is directly inherited from the nn.Module class and a linear variable is defined. The forward function is the key to our logistic model as it takes a tensor x as an input and returns the sigmoid function applied to the output of the linear model. Let us create an instance of the logistic model defined above and see what it looks like.\n\nmodel = Logistic_regression(1)\nx = torch.arange(-2,2,0.1).view(-1,1)\nplot_data_2(data_2, model = model, est_line=True)\n\n\n\n\n\n\n\n\nNeedless to say, the model above does a bad job of classifying the data correctly. Thus, let’s train our model, i.e., find a good fit for the parameters. Before doing that, let’s talk briefly about loss functions, in particular, the binary cross entropy loss and how it’s derived. In case you’re not interested in the mathematical nitty-gritty details, you can skip the following paragraph."
  },
  {
    "objectID": "posts/Pytorch/Post_01.html#derivation-of-the-cross-entropy-error-in-a-two-class-setting",
    "href": "posts/Pytorch/Post_01.html#derivation-of-the-cross-entropy-error-in-a-two-class-setting",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01",
    "section": "",
    "text": "Assume we have a two-class classification problem with class labels \\(0\\) and \\(1\\), and a labeled data-sample \\((x_1,y_1),...,(x_N,y_N),, N\\in\\mathbb{N}\\) with \\(x_i \\in\\mathbb{R}\\) for all \\(i\\in\\{1,...,N\\}\\). Let’s say there is some \\(n \\in\\mathbb{N}\\) with \\(1&lt;n&lt;N\\) such that \\(y_i = 0\\) for all \\(i&lt;n\\) and \\(y_i = 1\\) for all \\(i\\geq n\\), i.e. the data is linearly separable. Then, we are interested in maximizing the probability \\[\\begin{equation}\n    \\mathbb{P}(Y|wX+b):=\\prod_{i=1}^{n-1}\\mathbb{P}(y_i= 0|wx_i+b)\\prod_{i=n}^{N}\\mathbb{P}(y_i= 1|wx_i+b),\n\\end{equation}\\] where \\(Y=(y_1,...,y_N)\\), \\(X = (x_1,...,x_N)\\), and \\(w,b \\in\\mathbb{R}\\), as this yields the optimal estimation for the parameters \\(w\\) and \\(b\\).\nNote, that \\[\\begin{align}\n   \\mathbb{P}(y_i= 0|wx_i+b) &= 1-\\sigma(wx_i+b),\\\\\n   \\mathbb{P}(y_i= 1|wx_i+b) &= \\sigma(wx_i+b),\n\\end{align}\\] where \\(\\sigma\\) denotes the sigmoid function, i.e., \\(\\sigma:\\mathbb{R}\\to [0,1],\\,\\sigma(x) = \\frac{e^x}{e^x+1}\\). Then, \\[\\begin{align}\n    \\mathbb{P}(Y|wX+b) = \\prod_{i=1}^{n-1}1-\\sigma(wx_i+b)\\prod_{i=n}^{N}\\sigma(wx_i+b).\n\\end{align}\\] Since \\(y_i \\in\\{0,1\\}\\) for all \\(i\\in\\{1,...,N\\}\\), the expression above is equivalent to \\[\\begin{equation}\n    \\mathbb{P}(Y|wX+b) = \\prod_{i=1}^{N}(1-\\sigma(wx_i+b))^{1-y_i}\\sigma(wx_i+b)^{y_i}\n\\end{equation}\\] which can be maximized by applying maximum likelihood estimation.\nRecall, that \\[\\begin{equation}\n    \\underset{w,b}{\\text{argmax }}\\mathbb{P}(Y|wX+b) = \\underset{w,b}{\\text{argmax }}\\log\\left(\\mathbb{P}(Y|wX+b)\\right),\n\\end{equation}\\] since the logarithm is monotonically increasing. Thus, we can apply the logarithm to \\(\\mathbb{P}(Y|wX+b)\\) which yields \\[\\begin{align}\n    \\log\\left(\\mathbb{P}(Y|wX+b)\\right) &= \\sum_{n=1}^{N}\\log\\left((1-\\sigma(wx_i+b))^{1-y_i}\\cdot\\sigma(wx_i+b)^{y_i}\\right)\\\\\n                                        &= \\sum_{n=1}^{N}(1-y_i)\\log(1-\\sigma(wx_i+b))\\cdot y_i\\log(\\sigma(wx_i+b))\n\\end{align}\\] Instead of maximizing \\(\\log\\left(\\mathbb{P}(Y|wX+b)\\right)\\) we can equivalently minimize \\((-1)\\log\\left(\\mathbb{P}(Y|wX+b)\\right)\\). We can also average the latter which yields \\[\\begin{align}\n     -\\frac{1}{N}\\log\\left(\\mathbb{P}(Y|wX+b)\\right) &= -\\frac{1}{N}\\sum_{n=1}^{N}(1-y_i)\\log(1-\\sigma(wx_i+b))\\cdot y_i\\log(\\sigma(wx_i+b))\\\\\n     &=-\\frac{1}{N}\\sum_{n=1}^{N}(1-y_i)\\log(1-\\hat y_i)\\cdot y_i\\log(\\hat y_i) =: \\text{CEL}(\\hat Y, Y),\n\\end{align}\\] where \\(\\hat y = \\sigma(wx+b)\\). \\(\\text{CEL}(\\hat Y, Y)\\) is nothing but the binary cross-entropy loss. The binary cross-entropy loss can then be minimized by applying an appropriate algorithm like (stochastic) gradient descent, which will be covered in the next post. Implementing the binary cross-entropy loss in PyTorch works as follows. Note, that by adding the parameter \\(\\varepsilon\\) we avoid having to deal with singularities of the logarithm.\n\ndef BinaryCELoss(yhat,y):\n    eps = 9e-10\n    return -1*torch.mean(y*torch.log(yhat+eps)+(1-y)*torch.log(1-yhat+eps))"
  },
  {
    "objectID": "posts/Pytorch/Post_01.html#training-a-simple-model",
    "href": "posts/Pytorch/Post_01.html#training-a-simple-model",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01",
    "section": "",
    "text": "In order to train the model, we have to take care of some initial steps:\n\nDefine a model instance (that will be trained) of the previously built class.\nSet a learning rate for the optimization algorithm (this will also be elaborated on in the next post).\nSet a loss function (like the BinaryCELoss we defined above) and an optimizer (like PyTorchs stochastic gradient descent optimizer).\n\n\nmodel = Logistic_regression(1)\nlr = 0.1\noptimizer = torch.optim.SGD(model.parameters(),lr=lr)\n\nTraining the model usually works as follows:\n\nWe define a train_model method which takes the number of training steps (or formally epochs) as an input.\nThe LOSS_Custom and LOSS lists are used to store the loss of the model depending on the loss function.\nFor each epoch we perform the actual training:\n\nFirst, we calculate the estimate \\(\\hat y\\).\nThen, we calculate the loss of our estimate and the true class labels and add them to the LOSS List\nAfter calculating the loss, we calculate the gradient by using the backward.\n\n\n\ndef train_model(epochs):\n    LOSS = []\n    for iter in range(epochs):\n        yhat = model(data_2.x)\n        loss = BinaryCELoss(yhat,data_2.y)\n        LOSS.append(loss.data)\n        loss.backward()\n        optimizer.step()\n    plot_data_2(data_2, model, est_line = True)\n    plt.plot(np.arange(0,epochs,1),LOSS)\n    plt.title(\"Loss during different epochs\")\n\n\nest = train_model(200)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe accuracy of the model can be calculated as follows:\n\nSet the estimates \\(\\hat y\\) to True (corresponding to class \\(1\\)) if \\(\\hat y\\) is bigger than \\(0.5\\) and to False if \\(\\hat y \\leq 0.5\\) (corresponding to class \\(0\\)) and save them in a list called label.\nConvert the true labels \\(y\\) to a ByteTensor which takes the values 0 or 1 and compares them to the label list.\nTaking the mean returns a value between \\(0\\) and \\(1\\), where \\(1\\) stands for a perfect accuracy.\n\n\nyhat = model(data_2.x)\nlabel = yhat &gt; 0.5\nprint(\"Accuracy: \",torch.mean((label==data_2.y.type(torch.ByteTensor)).type(torch.float)))\n\nAccuracy:  tensor(1.)"
  },
  {
    "objectID": "posts/Pytorch/Post_01.html#summary",
    "href": "posts/Pytorch/Post_01.html#summary",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 01",
    "section": "",
    "text": "In this short introduction, we reviewed logistic regression and learned how to implement it using the PyTorch framework. Additionally, we familiarised ourselves with the binary cross-entropy loss and learned how to train a simple model using (stochastic) gradient descent. In the next post, we’ll take a closer look at gradient descent in one dimension."
  },
  {
    "objectID": "posts/Optimal-Control/Predator_Prey_Intro.html",
    "href": "posts/Optimal-Control/Predator_Prey_Intro.html",
    "title": "An Introduction to Optimal Control",
    "section": "",
    "text": "This article aims to introduce the basics of Optimal Control Theory by discussing the Lotka-Volterra model, also known as the predator-prey model. The model in its original form describes the interaction between two species namely, predator and prey. Predatory populations can only grow if there is enough prey, however, an increasing number in predators also leads to a decline in prey, since prey might not be able to reproduce fast enough. The dynamics of the model can be represented as a system of non-linear first order differential equations given by \\[\\begin{align*}\n&\\frac{\\partial}{\\partial t} x_1(t) = \\alpha x_1(t) - \\beta x_1(t)x_2(t),\\\\\n&\\frac{\\partial}{\\partial t} x_2(t) = \\delta x_1(t)x_2(t) - \\gamma x_2(t)\\\\\n&\\text{with initial conditions}\\\\\n&x_1(0) = a, \\quad x_2(0) = b,\\quad a,b\\in [0,1],\n\\end{align*}\\] and \\(\\alpha,\\beta,\\delta,\\gamma \\in (0,\\infty)\\). Here, \\(\\frac{\\partial}{\\partial t}x_1(t)\\) can be interpreted as the change in the prey population at time \\(t\\) and \\(\\frac{\\partial}{\\partial t} x_2(t)\\) as the change in the predator population at time \\(t\\), for some \\(t\\in [0,T], T&gt;0\\). The positive parameters \\(\\alpha,\\beta,\\delta,\\gamma\\) describe the interaction between the two species. In the following we will consider the explicit model \\[\\begin{align*}\n&\\frac{\\partial}{\\partial t} x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4x_1(t),\\\\\n&\\frac{\\partial}{\\partial t} x_2(t) = - x_2(t) + x_1(t)x_2(t) - 0.2x_2(t) \\\\\n&\\text{with initial conditions}\\\\\n&x_1(0) = a, \\quad x_2(0) = b,\\quad a,b\\in [0,1],\n\\end{align*}\\] i.e., \\(\\alpha = 0.6, \\beta = \\delta = 1, \\gamma = 1.2\\) and \\(T = 12\\). In order to give an intuition of how this system behaves depending on the initial population values, check out the following interactive plot or run the plot code yourself online using the binder button (it might take a minute or two to load). You can also simply take a look at the static version below.\n  \n\n\nCode\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets, Layout\n%matplotlib inline\n\n\n\n\nCode\ndef model(x):\n    return np.array([x[0]-x[0]*x[1]-0.4*x[0],\n                     -x[1]+x[0]*x[1]-0.2*x[1]])\ndef plot_pp(a,b):\n    t0 = 0\n    tmax = 12\n    sol = solve_ivp(lambda t, x:model(x), [t0, tmax], np.array([a,b]), t_eval=np.linspace(t0, tmax, 100))\n    plt.subplot(1,2,1)\n    plt.plot(sol.t,sol.y[0], label = 'Prey')\n    plt.plot(sol.t,sol.y[1], label = 'Predator')\n    plt.xlabel(\"time\")\n    plt.ylabel(\"population\")\n    plt.title(\"Solution of the ODE system\")\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(sol.y[1],sol.y[0], label = 'Prey', color = \"r\")\n    plt.rcParams[\"figure.figsize\"]=10,5\n    plt.title(\"Phase portrait of the solution\")\n    plt.xlabel(\"predator population\")\n    plt.ylabel(\"prey population\")\n\nstyle = {'description_width': 'initial'}\nlayout = Layout(width = \"400px\")\nslid1 = widgets.FloatSlider(description = 'Initial Prey Population',min=0, max=1, step=0.1, value=0.5,style = style, layout = layout)\nslid2 = widgets.FloatSlider(description = 'Initial Predator Population',min=0, max=1, step=0.1, value=0.7, style = style, layout = layout)\ninteract(plot_pp, a= slid1 ,b=slid2);\n\n\n\n\n\n\n\nCode\nplot_pp(a=0.5,b=0.7)\n\n\n\n\n\n\n\n\n\n\n\n\nThe goal is to stabilize both populations over time and eventually have both populations approach the same value. Given the evolution of the model, the idea is to introduce some sort of control function that increases or decreases the population decline in order achieve the goal. In our given model we can incorporate such a function as follows. \\[\\begin{align*}\n&\\frac{\\partial}{\\partial t} x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4u(t)x_1(t),\\\\\n&\\frac{\\partial}{\\partial t} x_2(t) = - x_2(t) + x_1(t)x_2(t) - 0.2u(t)x_2(t) \\\\\n&\\text{with initial conditions}\\\\\n&x_1(0) = a, \\quad x_2(0) = b,\\quad a,b\\in [0,1],\\\\\n&\\text{and control function }\\\\\n&u:[0,12]\\to[0,1]\n\\end{align*}\\] The function \\(u\\) taking values between \\(-1\\) and \\(1\\) is potentially decreasing or increasing the population decline of both, predators and prey.\nHow does a function \\(u:[0,12]\\to[0,1]\\) actually influence the system? Let us consider an example: Choose \\[\\begin{equation*}\nu(t) = \\begin{cases}\n            0, \\quad &\\text{ if } t\\in [0,2],\\\\\n            1, \\quad &\\text{ if } t\\in (2,4.5],\\\\\n            0.5, \\quad &\\text{ if } t\\in (4.5,7.5],\\\\\n            0, \\quad &\\text{ if } t\\in (7.5,12].\n        \\end{cases}\n\\end{equation*}\\] A visualization of the function \\(u\\) can be found below.\n\n\nCode\ndef u(t):\n    if 0&lt;= t &lt;= 2:\n        return 0\n    elif 2&lt; t &lt;= 4.5:\n        return 1\n    elif 4.5&lt; t &lt;=7.5:\n        return 0.5\n    else:\n        return 0\nvu = np.vectorize(u,otypes=[np.float64])\nt = np.linspace(0,12,100)\n\nplt.plot(t,vu(t), label = 'u(t)')\nplt.xlabel(\"time\")\nplt.ylabel(\"control value\")\nplt.title(\"control function\")\nplt.rcParams[\"figure.figsize\"]=5,5\nplt.legend();\n\n\n\n\n\n\n\n\n\nThe control function above is therefore decreasing the population decline whenever it takes a value in \\([0,1)\\) and not changing the dynamics if it takes the value \\(1\\). The adapted system can be solved in the same fashion as before which results in different solutions depending on the starting value. As above ypu can check out the following interactive plot or run the plot code yourself online using the binder button (it might take a minute or two to load). Alternatively you can also simply take a look at the static version below.\n  \n\n\nCode\ndef model_control_ex(t,x):\n    return np.array([x[0]-x[0]*x[1]-0.4*x[0]*u(t), -x[1]+x[0]*x[1]-0.2*x[1]*u(t)])\ndef plot_pp(a,b):\n    t0 = 0\n    tmax = 12\n    sol = solve_ivp(lambda t, x:model_control_ex(t,x), [t0, tmax], np.array([a,b]), t_eval=np.linspace(t0, tmax, 100))\n    plt.subplot(1,2,1)\n    plt.plot(sol.t,sol.y[0], label = 'Prey')\n    plt.plot(sol.t,sol.y[1], label = 'Predator')\n    plt.xlabel(\"time\")\n    plt.ylabel(\"population\")\n    plt.title(\"Solution of the ODE system\")\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(sol.y[1],sol.y[0], label = 'Prey', color = \"r\")\n    plt.rcParams[\"figure.figsize\"]=10,5\n    plt.title(\"Phase portrait of the solution\")\n    plt.xlabel(\"predator population\")\n    plt.ylabel(\"prey population\")\n\nstyle = {'description_width': 'initial'}\nlayout = Layout(width = \"400px\")\nslid1 = widgets.FloatSlider(description = 'Initial Prey Population',min=0, max=1, step=0.1, value=0.5,style = style, layout = layout)\nslid2 = widgets.FloatSlider(description = 'Initial Predator Population',min=0, max=1, step=0.1, value=0.7, style = style, layout = layout)\ninteract(plot_pp, a= slid1 ,b=slid2);\n\n\n\n\n\n\n\nCode\nplot_pp(0.5,0.7)\n\n\n\n\n\n\n\n\n\n\n\n\nThis explicit function \\(u\\) is not quite satisfactory in terms of controlling the population, as both populations are far from equal at terminal time \\(T=12\\). This is due to the fact that \\(u\\) was chosen arbitrarily without further constraints. In order to achieve this desired behaviors we have to pass additional restrictions on the control function and formulate an optimization problem. A first restriction is the introduction of a so-called cost function \\(F\\) taking values in \\([0,\\infty)\\) depending on \\(x_1\\) and \\(x_2\\). This cost function increases if the solution of the system strays further away from the values we want it to take. One possible cost function is given by \\[\\begin{equation*}\n    F(x_1,x_2) := \\int_0^{12} \\|\\left(x_1(t),x_2(t)\\right)^\\top- \\left(y_0,y_0\\right)^\\top\\|_2^2\\: \\mathrm{d}t,\n\\end{equation*}\\] where \\(y_0\\in[0,1]\\). If we desire for both populations to approach the value \\(y_0\\) we need to minimize the function \\(F\\) with respect to \\(u\\) while also solving the initial value problem we previously established. Approach can be formalized as follows. \\[\\begin{align*}\n    \\min_{u}\\;\\ &\\int\\limits_0^{12} (x_1(t)-y_0)^2+(x_2(t)-y_0)^2\\,\\mathrm{d}t\\\\\n    \\text{s.t.}&\\\\\n    &\\dot x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4x_1(t)u(t),\\\\\n    &\\dot x_2(t) = -x_2(t) + x_1(t)x_2(t) - 0.2x_1(t)u(t)\\\\\n    &\\text{with initial conditions}\\\\\n    &x_1(0)= a, \\quad x_2(0)= b\\\\\n    &\\text{and control conditions}\\\\\n    &u(t)\\in [0,1]\\quad \\forall\\,t \\in [0,12].\n\\end{align*}\\]\nThere are a number of different methods for solving the problem above. One rather simple approach we can choose is to modify the optimization problem in a way that the cost function is treated as an additional variable to our system. Define \\(x_3(t) := F(x_1(t),x_2(t))\\), then as a results we obtain an equivalent optimization problem \\[\\begin{align*}\n\\min_{u}\\;\\ &x_3(t)\\\\\n    \\text{s.t.}&\\\\\n    &\\dot x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4x_1(t)u(t),\\\\\n    &\\dot x_2(t) = -x_2(t) + x_1(t)x_2(t) - 0.2x_1(t)u(t)\\\\\n    &\\dot x_3(t) = (x_1(t)-y_0)^2+(x_2(t)-y_0)^2\\\\\n    &\\text{with boundary conditions}\\\\\n    &x_1(0)= a, \\quad x_2(0)= b,\\quad x_3(0) = 0,\\\\\n    &x_1(12)= y_0, \\quad x_2(12)= y_0,\\quad x_3(12) = 0,\\\\\n    &\\text{and control conditions}\\\\\n    &u(t)\\in [0,1]\\quad \\forall\\,t \\in [0,12].\n\\end{align*}\\] Optimization problems of this nature can be solved in python by using the gekko package. Check out the interactive plot or run the plot code yourself online using the binder button (it might take a minute or two to load) to see how the control function changes depending on the starting values. You can also simply take a look at the static version below.\n  \n\n\nCode\nfrom gekko import GEKKO\nm = GEKKO(remote = False)\nn = 100\nT = 12\nm.time = np.linspace(0,T,n)\na = 0.2; b=0.5; y0 = 1\n\nx1 = m.Var(value = a)\nx2 = m.Var(value = b)\nx3 = m.Var(value = (a-y0)**2 + (b-y0)**2)\nu = m.Var(value = 0, lb = -1, ub = 1)\np = np.zeros(n)\np[-1] = T\nfinal = m.Param(value = p)\n\nm.Equation(x1.dt()==x1-x1*x2-0.4*x1*u)\nm.Equation(x2.dt()==-x2+x1*x2-0.2*x1*u)\nm.Equation(x3.dt()==(x1-y0)**2+(x2-y0)**2)\n\nm.Obj(x3)\nm.options.IMODE = 6 # optimal control mode\n\n\n\n\nCode\ndef plot_pp(a,b):\n    m = GEKKO(remote = True)\n    n = 100\n    T = 12\n    m.time = np.linspace(0,T,n)\n    y0 = 1\n\n    x1 = m.Var(value = a)\n    x2 = m.Var(value = b)\n    x3 = m.Var(value = (a-y0)**2 + (b-y0)**2)\n    u = m.Var(value = 0, lb = 0, ub = 1)\n    p = np.zeros(n)\n    p[-1] = T\n\n    m.Equation(x1.dt()==x1-x1*x2-0.4*x1*u)\n    m.Equation(x2.dt()==-x2+x1*x2-0.2*x1*u)\n    m.Equation(x3.dt()==(x1-y0)**2+(x2-y0)**2)\n\n    m.Obj(x3)\n    m.options.IMODE = 6 # optimal control mode\n    \n    m.solve(disp=False)\n    plt.subplot(1,2,1)\n    plt.plot(m.time,x1.value, label = 'Prey')\n    plt.plot(m.time,x2.value, label = 'Predator')\n    plt.xlabel(\"time\")\n    plt.ylabel(\"population\")\n    plt.title(\"Solution to the control problem with $y_0$ =%.1f\" %y0)\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(m.time,u.value, color = \"r\")\n    plt.rcParams[\"figure.figsize\"]=10,5\n    plt.title(\"Control function values\")\n    plt.xlabel(\"time\")\n    plt.ylabel(\"control value\")\n\n\nstyle = {'description_width': 'initial'}\nlayout = Layout(width = \"400px\")\nslid1 = widgets.FloatSlider(description = 'Initial Prey Population $a$',min=0.4, max=0.8, step=0.05, value=0.5,style = style, layout = layout)\nslid2 = widgets.FloatSlider(description = 'Initial Predator Population $b$',min=0.4, max=0.8, step=0.05, value=0.5, style = style, layout = layout)\ninteract(plot_pp, a= slid1 ,b=slid2);\n\n\n\n\n\n\n\nCode\nplot_pp(0.5,0.7)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this post we learned a bit about the Lotka-Volterra model and how we can influence it by incorporating a control function. As the control function needs to be chosen in a way that we can stabilize the populations, we chose modify our system further and add some punishment functional. This punishment functional can be minimized using a optimization algorithm that yields an optimal control function."
  },
  {
    "objectID": "posts/Optimal-Control/Predator_Prey_Intro.html#the-base-model",
    "href": "posts/Optimal-Control/Predator_Prey_Intro.html#the-base-model",
    "title": "An Introduction to Optimal Control",
    "section": "",
    "text": "This article aims to introduce the basics of Optimal Control Theory by discussing the Lotka-Volterra model, also known as the predator-prey model. The model in its original form describes the interaction between two species namely, predator and prey. Predatory populations can only grow if there is enough prey, however, an increasing number in predators also leads to a decline in prey, since prey might not be able to reproduce fast enough. The dynamics of the model can be represented as a system of non-linear first order differential equations given by \\[\\begin{align*}\n&\\frac{\\partial}{\\partial t} x_1(t) = \\alpha x_1(t) - \\beta x_1(t)x_2(t),\\\\\n&\\frac{\\partial}{\\partial t} x_2(t) = \\delta x_1(t)x_2(t) - \\gamma x_2(t)\\\\\n&\\text{with initial conditions}\\\\\n&x_1(0) = a, \\quad x_2(0) = b,\\quad a,b\\in [0,1],\n\\end{align*}\\] and \\(\\alpha,\\beta,\\delta,\\gamma \\in (0,\\infty)\\). Here, \\(\\frac{\\partial}{\\partial t}x_1(t)\\) can be interpreted as the change in the prey population at time \\(t\\) and \\(\\frac{\\partial}{\\partial t} x_2(t)\\) as the change in the predator population at time \\(t\\), for some \\(t\\in [0,T], T&gt;0\\). The positive parameters \\(\\alpha,\\beta,\\delta,\\gamma\\) describe the interaction between the two species. In the following we will consider the explicit model \\[\\begin{align*}\n&\\frac{\\partial}{\\partial t} x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4x_1(t),\\\\\n&\\frac{\\partial}{\\partial t} x_2(t) = - x_2(t) + x_1(t)x_2(t) - 0.2x_2(t) \\\\\n&\\text{with initial conditions}\\\\\n&x_1(0) = a, \\quad x_2(0) = b,\\quad a,b\\in [0,1],\n\\end{align*}\\] i.e., \\(\\alpha = 0.6, \\beta = \\delta = 1, \\gamma = 1.2\\) and \\(T = 12\\). In order to give an intuition of how this system behaves depending on the initial population values, check out the following interactive plot or run the plot code yourself online using the binder button (it might take a minute or two to load). You can also simply take a look at the static version below.\n  \n\n\nCode\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets, Layout\n%matplotlib inline\n\n\n\n\nCode\ndef model(x):\n    return np.array([x[0]-x[0]*x[1]-0.4*x[0],\n                     -x[1]+x[0]*x[1]-0.2*x[1]])\ndef plot_pp(a,b):\n    t0 = 0\n    tmax = 12\n    sol = solve_ivp(lambda t, x:model(x), [t0, tmax], np.array([a,b]), t_eval=np.linspace(t0, tmax, 100))\n    plt.subplot(1,2,1)\n    plt.plot(sol.t,sol.y[0], label = 'Prey')\n    plt.plot(sol.t,sol.y[1], label = 'Predator')\n    plt.xlabel(\"time\")\n    plt.ylabel(\"population\")\n    plt.title(\"Solution of the ODE system\")\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(sol.y[1],sol.y[0], label = 'Prey', color = \"r\")\n    plt.rcParams[\"figure.figsize\"]=10,5\n    plt.title(\"Phase portrait of the solution\")\n    plt.xlabel(\"predator population\")\n    plt.ylabel(\"prey population\")\n\nstyle = {'description_width': 'initial'}\nlayout = Layout(width = \"400px\")\nslid1 = widgets.FloatSlider(description = 'Initial Prey Population',min=0, max=1, step=0.1, value=0.5,style = style, layout = layout)\nslid2 = widgets.FloatSlider(description = 'Initial Predator Population',min=0, max=1, step=0.1, value=0.7, style = style, layout = layout)\ninteract(plot_pp, a= slid1 ,b=slid2);\n\n\n\n\n\n\n\nCode\nplot_pp(a=0.5,b=0.7)"
  },
  {
    "objectID": "posts/Optimal-Control/Predator_Prey_Intro.html#adding-a-control-function",
    "href": "posts/Optimal-Control/Predator_Prey_Intro.html#adding-a-control-function",
    "title": "An Introduction to Optimal Control",
    "section": "",
    "text": "The goal is to stabilize both populations over time and eventually have both populations approach the same value. Given the evolution of the model, the idea is to introduce some sort of control function that increases or decreases the population decline in order achieve the goal. In our given model we can incorporate such a function as follows. \\[\\begin{align*}\n&\\frac{\\partial}{\\partial t} x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4u(t)x_1(t),\\\\\n&\\frac{\\partial}{\\partial t} x_2(t) = - x_2(t) + x_1(t)x_2(t) - 0.2u(t)x_2(t) \\\\\n&\\text{with initial conditions}\\\\\n&x_1(0) = a, \\quad x_2(0) = b,\\quad a,b\\in [0,1],\\\\\n&\\text{and control function }\\\\\n&u:[0,12]\\to[0,1]\n\\end{align*}\\] The function \\(u\\) taking values between \\(-1\\) and \\(1\\) is potentially decreasing or increasing the population decline of both, predators and prey.\nHow does a function \\(u:[0,12]\\to[0,1]\\) actually influence the system? Let us consider an example: Choose \\[\\begin{equation*}\nu(t) = \\begin{cases}\n            0, \\quad &\\text{ if } t\\in [0,2],\\\\\n            1, \\quad &\\text{ if } t\\in (2,4.5],\\\\\n            0.5, \\quad &\\text{ if } t\\in (4.5,7.5],\\\\\n            0, \\quad &\\text{ if } t\\in (7.5,12].\n        \\end{cases}\n\\end{equation*}\\] A visualization of the function \\(u\\) can be found below.\n\n\nCode\ndef u(t):\n    if 0&lt;= t &lt;= 2:\n        return 0\n    elif 2&lt; t &lt;= 4.5:\n        return 1\n    elif 4.5&lt; t &lt;=7.5:\n        return 0.5\n    else:\n        return 0\nvu = np.vectorize(u,otypes=[np.float64])\nt = np.linspace(0,12,100)\n\nplt.plot(t,vu(t), label = 'u(t)')\nplt.xlabel(\"time\")\nplt.ylabel(\"control value\")\nplt.title(\"control function\")\nplt.rcParams[\"figure.figsize\"]=5,5\nplt.legend();\n\n\n\n\n\n\n\n\n\nThe control function above is therefore decreasing the population decline whenever it takes a value in \\([0,1)\\) and not changing the dynamics if it takes the value \\(1\\). The adapted system can be solved in the same fashion as before which results in different solutions depending on the starting value. As above ypu can check out the following interactive plot or run the plot code yourself online using the binder button (it might take a minute or two to load). Alternatively you can also simply take a look at the static version below.\n  \n\n\nCode\ndef model_control_ex(t,x):\n    return np.array([x[0]-x[0]*x[1]-0.4*x[0]*u(t), -x[1]+x[0]*x[1]-0.2*x[1]*u(t)])\ndef plot_pp(a,b):\n    t0 = 0\n    tmax = 12\n    sol = solve_ivp(lambda t, x:model_control_ex(t,x), [t0, tmax], np.array([a,b]), t_eval=np.linspace(t0, tmax, 100))\n    plt.subplot(1,2,1)\n    plt.plot(sol.t,sol.y[0], label = 'Prey')\n    plt.plot(sol.t,sol.y[1], label = 'Predator')\n    plt.xlabel(\"time\")\n    plt.ylabel(\"population\")\n    plt.title(\"Solution of the ODE system\")\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(sol.y[1],sol.y[0], label = 'Prey', color = \"r\")\n    plt.rcParams[\"figure.figsize\"]=10,5\n    plt.title(\"Phase portrait of the solution\")\n    plt.xlabel(\"predator population\")\n    plt.ylabel(\"prey population\")\n\nstyle = {'description_width': 'initial'}\nlayout = Layout(width = \"400px\")\nslid1 = widgets.FloatSlider(description = 'Initial Prey Population',min=0, max=1, step=0.1, value=0.5,style = style, layout = layout)\nslid2 = widgets.FloatSlider(description = 'Initial Predator Population',min=0, max=1, step=0.1, value=0.7, style = style, layout = layout)\ninteract(plot_pp, a= slid1 ,b=slid2);\n\n\n\n\n\n\n\nCode\nplot_pp(0.5,0.7)"
  },
  {
    "objectID": "posts/Optimal-Control/Predator_Prey_Intro.html#finding-an-optimal-control-function",
    "href": "posts/Optimal-Control/Predator_Prey_Intro.html#finding-an-optimal-control-function",
    "title": "An Introduction to Optimal Control",
    "section": "",
    "text": "This explicit function \\(u\\) is not quite satisfactory in terms of controlling the population, as both populations are far from equal at terminal time \\(T=12\\). This is due to the fact that \\(u\\) was chosen arbitrarily without further constraints. In order to achieve this desired behaviors we have to pass additional restrictions on the control function and formulate an optimization problem. A first restriction is the introduction of a so-called cost function \\(F\\) taking values in \\([0,\\infty)\\) depending on \\(x_1\\) and \\(x_2\\). This cost function increases if the solution of the system strays further away from the values we want it to take. One possible cost function is given by \\[\\begin{equation*}\n    F(x_1,x_2) := \\int_0^{12} \\|\\left(x_1(t),x_2(t)\\right)^\\top- \\left(y_0,y_0\\right)^\\top\\|_2^2\\: \\mathrm{d}t,\n\\end{equation*}\\] where \\(y_0\\in[0,1]\\). If we desire for both populations to approach the value \\(y_0\\) we need to minimize the function \\(F\\) with respect to \\(u\\) while also solving the initial value problem we previously established. Approach can be formalized as follows. \\[\\begin{align*}\n    \\min_{u}\\;\\ &\\int\\limits_0^{12} (x_1(t)-y_0)^2+(x_2(t)-y_0)^2\\,\\mathrm{d}t\\\\\n    \\text{s.t.}&\\\\\n    &\\dot x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4x_1(t)u(t),\\\\\n    &\\dot x_2(t) = -x_2(t) + x_1(t)x_2(t) - 0.2x_1(t)u(t)\\\\\n    &\\text{with initial conditions}\\\\\n    &x_1(0)= a, \\quad x_2(0)= b\\\\\n    &\\text{and control conditions}\\\\\n    &u(t)\\in [0,1]\\quad \\forall\\,t \\in [0,12].\n\\end{align*}\\]\nThere are a number of different methods for solving the problem above. One rather simple approach we can choose is to modify the optimization problem in a way that the cost function is treated as an additional variable to our system. Define \\(x_3(t) := F(x_1(t),x_2(t))\\), then as a results we obtain an equivalent optimization problem \\[\\begin{align*}\n\\min_{u}\\;\\ &x_3(t)\\\\\n    \\text{s.t.}&\\\\\n    &\\dot x_1(t) = x_1(t) - x_1(t)x_2(t) - 0.4x_1(t)u(t),\\\\\n    &\\dot x_2(t) = -x_2(t) + x_1(t)x_2(t) - 0.2x_1(t)u(t)\\\\\n    &\\dot x_3(t) = (x_1(t)-y_0)^2+(x_2(t)-y_0)^2\\\\\n    &\\text{with boundary conditions}\\\\\n    &x_1(0)= a, \\quad x_2(0)= b,\\quad x_3(0) = 0,\\\\\n    &x_1(12)= y_0, \\quad x_2(12)= y_0,\\quad x_3(12) = 0,\\\\\n    &\\text{and control conditions}\\\\\n    &u(t)\\in [0,1]\\quad \\forall\\,t \\in [0,12].\n\\end{align*}\\] Optimization problems of this nature can be solved in python by using the gekko package. Check out the interactive plot or run the plot code yourself online using the binder button (it might take a minute or two to load) to see how the control function changes depending on the starting values. You can also simply take a look at the static version below.\n  \n\n\nCode\nfrom gekko import GEKKO\nm = GEKKO(remote = False)\nn = 100\nT = 12\nm.time = np.linspace(0,T,n)\na = 0.2; b=0.5; y0 = 1\n\nx1 = m.Var(value = a)\nx2 = m.Var(value = b)\nx3 = m.Var(value = (a-y0)**2 + (b-y0)**2)\nu = m.Var(value = 0, lb = -1, ub = 1)\np = np.zeros(n)\np[-1] = T\nfinal = m.Param(value = p)\n\nm.Equation(x1.dt()==x1-x1*x2-0.4*x1*u)\nm.Equation(x2.dt()==-x2+x1*x2-0.2*x1*u)\nm.Equation(x3.dt()==(x1-y0)**2+(x2-y0)**2)\n\nm.Obj(x3)\nm.options.IMODE = 6 # optimal control mode\n\n\n\n\nCode\ndef plot_pp(a,b):\n    m = GEKKO(remote = True)\n    n = 100\n    T = 12\n    m.time = np.linspace(0,T,n)\n    y0 = 1\n\n    x1 = m.Var(value = a)\n    x2 = m.Var(value = b)\n    x3 = m.Var(value = (a-y0)**2 + (b-y0)**2)\n    u = m.Var(value = 0, lb = 0, ub = 1)\n    p = np.zeros(n)\n    p[-1] = T\n\n    m.Equation(x1.dt()==x1-x1*x2-0.4*x1*u)\n    m.Equation(x2.dt()==-x2+x1*x2-0.2*x1*u)\n    m.Equation(x3.dt()==(x1-y0)**2+(x2-y0)**2)\n\n    m.Obj(x3)\n    m.options.IMODE = 6 # optimal control mode\n    \n    m.solve(disp=False)\n    plt.subplot(1,2,1)\n    plt.plot(m.time,x1.value, label = 'Prey')\n    plt.plot(m.time,x2.value, label = 'Predator')\n    plt.xlabel(\"time\")\n    plt.ylabel(\"population\")\n    plt.title(\"Solution to the control problem with $y_0$ =%.1f\" %y0)\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(m.time,u.value, color = \"r\")\n    plt.rcParams[\"figure.figsize\"]=10,5\n    plt.title(\"Control function values\")\n    plt.xlabel(\"time\")\n    plt.ylabel(\"control value\")\n\n\nstyle = {'description_width': 'initial'}\nlayout = Layout(width = \"400px\")\nslid1 = widgets.FloatSlider(description = 'Initial Prey Population $a$',min=0.4, max=0.8, step=0.05, value=0.5,style = style, layout = layout)\nslid2 = widgets.FloatSlider(description = 'Initial Predator Population $b$',min=0.4, max=0.8, step=0.05, value=0.5, style = style, layout = layout)\ninteract(plot_pp, a= slid1 ,b=slid2);\n\n\n\n\n\n\n\nCode\nplot_pp(0.5,0.7)"
  },
  {
    "objectID": "posts/Optimal-Control/Predator_Prey_Intro.html#conclusion",
    "href": "posts/Optimal-Control/Predator_Prey_Intro.html#conclusion",
    "title": "An Introduction to Optimal Control",
    "section": "",
    "text": "In this post we learned a bit about the Lotka-Volterra model and how we can influence it by incorporating a control function. As the control function needs to be chosen in a way that we can stabilize the populations, we chose modify our system further and add some punishment functional. This punishment functional can be minimized using a optimization algorithm that yields an optimal control function."
  },
  {
    "objectID": "posts/Pytorch/Post_02.html",
    "href": "posts/Pytorch/Post_02.html",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02",
    "section": "",
    "text": "In this blog post, I’d like to introduce a common method used for training machine learning models such as the logistic model. This approach is commonly known as gradient descent—a method that, as its name implies, involves minimizing a function by progressively descending along its gradient. In the context of regression, typically a loss function such as the mean squared error is minimized, which in turn yields an optimal fit for a given model.\nMathematically speaking in its most basic form this translates into the following:\nLet \\(\\Omega\\subseteq \\mathbb{R}\\) and consider a function \\(f:\\Omega \\to \\mathbb{R}\\) that is at least one time differentiable in \\(\\Omega\\). Set an initial value \\(x_0\\in\\Omega\\), a step size \\(\\alpha \\geq 0\\), and iterate for \\(n = 0,...,N\\) through the following steps:\n    1. Calculate \\(d_n = -f'(x_n)\\),\n    2. Set \\(x_{n+1} = x_{n} + \\alpha d.\\) After iterating through all steps, return the last value \\(x_N\\).\nThe procedure above ensures that \\(f(x_0) \\geq f(x_1) \\geq ... \\geq f(x_N)\\) for a sufficiently small step size \\(\\alpha\\), since each \\(x_n\\) moves along the negative gradient towards a local minimum.\n\n\n\nLet \\(f:\\mathbb{R}\\to\\mathbb{R}, \\: x\\mapsto (x-2)^2\\) and set \\(x_0 = -1,\\,\\alpha = 0.1, N = 20\\). Then, the following interactive plot visualizes each step of the gradient descent towards the minimum at \\(x=2\\).\n\n#Some packages needed throughout the article\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nN=200\nX = np.linspace(-2,6,N)\ndef f(x):\n    return (x-2)**2\n\ndef gd_1d(epochs ,lr ,f ,x):\n    coord = []\n    for epoch in range(epochs):\n        loss = f(x)\n        coord.append([x.data,loss.data])\n        loss.backward()\n        x.data = x.data - lr * x.grad.data\n        x.grad.data.zero_()\n\n    return np.transpose(np.reshape(coord,(epochs,2)))\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.1\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n#plt.show()\n\n\n\nAs the step size increases, \\(x_n\\) slowly approaches the minimum at \\(x=2\\).\nGenerally, there are quite a few pitfalls when applying gradient descent. Consider the function \\[\\begin{equation*}\nx\\mapsto \\frac{1}{2}*(\\frac{3}{4}*x-1.2)^4-2*(\\frac{3}{4}*x-1)^2+2\n\\end{equation*}\\] which has a global minimum at \\(x \\approx 3.607\\) and is displayed below.\n\n\nAs in the example before, set \\(x_0 = -1,\\,\\alpha = 0.1,\\) and \\(N = 20\\) which results in the following interactive plot.\n\ndef f(x):\n    return 0.5*(0.75*x-1.2)**4-2*(0.75*x-1)**2+2\n\nX = np.linspace(-2,5,N)\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.1\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n\n\n\nIt turns out that the step size is too small, so instead of approaching the global minimum at \\(x \\approx 3.6\\), the algorithm is stuck in the local minimum at \\(x\\approx -0.1\\). This can seemingly easily be fixed by increasing the step size to \\(0.4\\).\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.40\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n\n\n\nUsing a step size of \\(0.4\\) already improves the result. However, for \\(n\\geq 11\\), \\(x_n\\) is no longer approaching the global minimum rather than jumping around it from one side of the curve to the other.\n\n\n\nSo, how can an optimal step size be found? The initial change to a step size of \\(0.4\\) seems quite arbitrary! One way is running a grid search, where gradient descent is performed multiple times with varying step sizes. After iterating through every step size, select the one which yields the best result. For example, we could start with a step size of \\(\\alpha =0.1\\) and work our way up to \\(1.0\\) with increments of \\(0.01\\).\n\nres = np.array([])\nfor lr in np.arange(0.1,1,0.01):\n    x0 = torch.tensor(-1.0,requires_grad=True)\n    epochs = 20\n    coord = gd_1d(epochs,lr,f,x0)\n    res = np.append(res,np.min(coord[1]))\n\nThis approach raises some new challenges, as certain step sizes cause the gradient descent to diverge. Set for example the step size to \\(\\alpha = 0.79\\) and check out what happens.\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.79\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n\n\n\nBy limiting ourselves to the results where \\(x_N\\) is finite we obtain the following result.\n\nopt_lr = np.arange(0.1,1,0.01)[np.argmin(res[~np.isnan(res)])+1]\nx0 = torch.tensor(-1.0,requires_grad=True)\nprint(\"For a step size of {lr:.2f}, the final value for x_N is {res:.3f}\".format(lr = opt_lr,res = gd_1d(epochs,opt_lr,f,x0)[0][-1]))\n\nFor a step size of 0.52, the final value for x_N is 3.613\n\n\n\n\nWhile the final value \\(x_N\\) is already close to the global minimum at \\(x \\approx 3.607\\), this approach is not stable at all. Setting \\(N = 19\\) yields a final result of \\(x_N \\approx 2.491\\), which misses the global minimum by around \\(1.116\\). This phenomenon motivates the last part of this post.\n\n\n\nIn this last paragraph, we discuss the so-called Armijo–Rule. It is a step size selection strategy designed to ensure that in each iteration of the gradient descent, the step size \\(\\alpha\\) is sufficiently large to make progress, and additionally to ensure that a significant decrease in the objective function value is achieved at the same time. By following this rule, we can address all the previous issues at once! The basic idea for finding this optimal step size \\(\\alpha\\) in each of the \\(n=1,...,N\\) steps of the gradient descent is outlined below.\nSet \\(\\beta,\\gamma\\in(0,1)\\) and define an iteration limit \\(M\\) for the following procedure:\nFor each \\(j = 1,...,M\\):\n    1. Check if \\(f(x_n - \\alpha  d_n) \\leq f(x_n) + \\gamma  \\alpha  d_n^2\\).\n    2. If the condition above is not fulfilled, update \\(\\alpha\\) to \\(\\alpha\\beta\\).\n    3. Repeat until 1. is fulfilled or until \\(j=M\\)\nOnce either one of the criteria is fulfilled, perform the next step of gradient descent with the updated \\(\\alpha\\). By iteratively decreasing the step size \\(\\alpha\\), we ensure that the bigger jumps observed before do not occur in a neighborhood of the global minimum.\n\ndef gd_1d_arm(epochs ,lr ,f ,x, gamma, beta, max_iter):\n    coord = []\n    lr_n = lr\n    for epoch in range(epochs):\n        loss = f(x)\n        coord.append([x.data,loss.data])\n        loss.backward()\n        #Armijo-Rule\n        for i in range(max_iter):\n            if f(x - lr_n * x.grad.data) &lt;= f(x) + gamma * lr_n * x.grad.data**2:\n                break\n            lr_n *= beta\n        x.data = x.data - lr_n * x.grad.data\n        x.grad.data.zero_()\n    return np.transpose(np.reshape(coord,(epochs,2)))\n\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 1\ngamma = 0.01\nbeta=0.5\nepochs = 20\ncoord = gd_1d_arm(epochs,lr,f,x0,gamma,beta,max_iter=10)\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n#plt.show()\n\n\n\nAn example of how the Armijo Rule works in detail is the following:\nIn the first step of the gradient descent it holds that \\[\\begin{equation*}\nf(x_0)+\\gamma\\alpha d^2 \\approx 3.45 \\ngeq 6.05 \\approx f(x_0- \\alpha d).\n\\end{equation*}\\]\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nf(x0).backward()\n\nplt.plot(X,f(X),\n         color = \"teal\",\n         label = r\"$f(x)$\")\n\nplt.plot(x0.detach(),f(x0.detach()),\n         marker = 'o',\n         color = 'red',\n         label = r\"$f(x_0)$\")\n\nplt.plot(x0.detach() - lr * x0.grad.data,f(x0.detach() - lr * x0.grad.data),\n         marker = 'o',\n         color = 'green',\n         label = r\"$f(x_0- \\alpha d)$\")\nplt.plot([x0.detach(),x0.detach() - lr * x0.grad.data],[f(x0.detach())+gamma*0*x0.grad.data**2,f(x0.detach())+gamma*lr*x0.grad.data**2],\n         linestyle = 'dashed',\n         color = \"orange\",\n         label = r\"$f(x_0)+\\gamma\\alpha d^2$ \")\nplt.plot([x0.detach()-lr*x0.grad.data]*2,[f(x0.detach())+gamma*lr*x0.grad.data**2,f(x0.detach() - lr * x0.grad.data)],\n         linestyle = 'dotted',\n         color = \"black\")\n\nplt.ylim((-2,10))\nplt.xlim((-2,6))\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x29c23468e80&gt;\n\n\n\n\n\n\n\n\n\nHere, the orange dashed line represents the half line \\(\\alpha \\mapsto f(x_0)+\\gamma\\alpha d^2\\) for \\(\\alpha \\in [0,1]\\). As the inequality is not yet satisfied for \\(\\alpha = 1\\), a new learning rate \\(\\alpha = 1*0.5 = 0.5\\) is applied according to the algorithm. This results in \\[\\begin{equation*}\nf(x_0)+\\gamma\\alpha d^2 \\approx 3.28 \\geq 1.59 \\approx f(x_0- \\alpha d).\n\\end{equation*}\\]\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nf(x0).backward()\n\nlr = lr*beta\n\nplt.plot(X,f(X),\n         color = \"teal\",\n         label = r\"$f(x)$\")\n\nplt.plot(x0.detach(),f(x0.detach()),\n         marker = 'o',\n         color = 'red',\n         label = r\"$f(x_0)$\")\n\nplt.plot(x0.detach() - lr * x0.grad.data,f(x0.detach() - lr * x0.grad.data),\n         marker = 'o',\n         color = 'green',\n         label = r\"$f(x_0- \\alpha d)$\")\nplt.plot([x0.detach(),x0.detach() - lr * x0.grad.data],[f(x0.detach())+gamma*0*x0.grad.data**2,f(x0.detach())+gamma*lr*x0.grad.data**2],\n         linestyle = 'dashed',\n         color = \"orange\",\n         label = r\"$f(x_0)+\\gamma\\alpha d^2$ \")\nplt.plot([x0.detach()-lr*x0.grad.data]*2,[f(x0.detach())+gamma*lr*x0.grad.data**2,f(x0.detach() - lr * x0.grad.data)],\n         linestyle = 'dotted',\n         color = \"black\")\n\nplt.ylim((-2,10))\nplt.xlim((-2,6))\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x29c17a3d640&gt;\n\n\n\n\n\n\n\n\n\nAs this new learning rate satisfies the inequality, it is applied in the step of the gradient descent.\nThe seemingly fruitful approach does not come without a price. By adding more variables, i.e., \\(\\gamma\\), \\(\\beta\\), and the maximum iteration number \\(M\\), fine–tuning the algorithm gets more complicated.\nHowever, in most cases, there is a rule of thumb that works well for setting the initial parameters, which involves choosing \\(\\alpha = 1\\), \\(\\beta = 0.5\\), \\(\\gamma = 0.01\\), and \\(M=10\\) to satisfy this guideline.\n\n\n\nIn this blog post, we introduced the powerful method of gradient descent in one dimension and learned how to implement it using the PyTorch framework. We discussed some common pitfalls of using gradient descent like choosing a step size \\(\\alpha\\) that is either too big or too small. In the last section we briefly introduced the Armijo–Rule which utilized a variable step size for each iteration of the gradient descent."
  },
  {
    "objectID": "posts/Pytorch/Post_02.html#gradient-descent-in-one-dimension",
    "href": "posts/Pytorch/Post_02.html#gradient-descent-in-one-dimension",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02",
    "section": "",
    "text": "In this blog post, I’d like to introduce a common method used for training machine learning models such as the logistic model. This approach is commonly known as gradient descent—a method that, as its name implies, involves minimizing a function by progressively descending along its gradient. In the context of regression, typically a loss function such as the mean squared error is minimized, which in turn yields an optimal fit for a given model.\nMathematically speaking in its most basic form this translates into the following:\nLet \\(\\Omega\\subseteq \\mathbb{R}\\) and consider a function \\(f:\\Omega \\to \\mathbb{R}\\) that is at least one time differentiable in \\(\\Omega\\). Set an initial value \\(x_0\\in\\Omega\\), a step size \\(\\alpha \\geq 0\\), and iterate for \\(n = 0,...,N\\) through the following steps:\n    1. Calculate \\(d_n = -f'(x_n)\\),\n    2. Set \\(x_{n+1} = x_{n} + \\alpha d.\\) After iterating through all steps, return the last value \\(x_N\\).\nThe procedure above ensures that \\(f(x_0) \\geq f(x_1) \\geq ... \\geq f(x_N)\\) for a sufficiently small step size \\(\\alpha\\), since each \\(x_n\\) moves along the negative gradient towards a local minimum."
  },
  {
    "objectID": "posts/Pytorch/Post_02.html#a-first-example",
    "href": "posts/Pytorch/Post_02.html#a-first-example",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02",
    "section": "",
    "text": "Let \\(f:\\mathbb{R}\\to\\mathbb{R}, \\: x\\mapsto (x-2)^2\\) and set \\(x_0 = -1,\\,\\alpha = 0.1, N = 20\\). Then, the following interactive plot visualizes each step of the gradient descent towards the minimum at \\(x=2\\).\n\n#Some packages needed throughout the article\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nN=200\nX = np.linspace(-2,6,N)\ndef f(x):\n    return (x-2)**2\n\ndef gd_1d(epochs ,lr ,f ,x):\n    coord = []\n    for epoch in range(epochs):\n        loss = f(x)\n        coord.append([x.data,loss.data])\n        loss.backward()\n        x.data = x.data - lr * x.grad.data\n        x.grad.data.zero_()\n\n    return np.transpose(np.reshape(coord,(epochs,2)))\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.1\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n#plt.show()\n\n\n\nAs the step size increases, \\(x_n\\) slowly approaches the minimum at \\(x=2\\).\nGenerally, there are quite a few pitfalls when applying gradient descent. Consider the function \\[\\begin{equation*}\nx\\mapsto \\frac{1}{2}*(\\frac{3}{4}*x-1.2)^4-2*(\\frac{3}{4}*x-1)^2+2\n\\end{equation*}\\] which has a global minimum at \\(x \\approx 3.607\\) and is displayed below.\n\n\nAs in the example before, set \\(x_0 = -1,\\,\\alpha = 0.1,\\) and \\(N = 20\\) which results in the following interactive plot.\n\ndef f(x):\n    return 0.5*(0.75*x-1.2)**4-2*(0.75*x-1)**2+2\n\nX = np.linspace(-2,5,N)\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.1\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n\n\n\nIt turns out that the step size is too small, so instead of approaching the global minimum at \\(x \\approx 3.6\\), the algorithm is stuck in the local minimum at \\(x\\approx -0.1\\). This can seemingly easily be fixed by increasing the step size to \\(0.4\\).\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.40\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n\n\n\nUsing a step size of \\(0.4\\) already improves the result. However, for \\(n\\geq 11\\), \\(x_n\\) is no longer approaching the global minimum rather than jumping around it from one side of the curve to the other."
  },
  {
    "objectID": "posts/Pytorch/Post_02.html#improving-the-step-size",
    "href": "posts/Pytorch/Post_02.html#improving-the-step-size",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02",
    "section": "",
    "text": "So, how can an optimal step size be found? The initial change to a step size of \\(0.4\\) seems quite arbitrary! One way is running a grid search, where gradient descent is performed multiple times with varying step sizes. After iterating through every step size, select the one which yields the best result. For example, we could start with a step size of \\(\\alpha =0.1\\) and work our way up to \\(1.0\\) with increments of \\(0.01\\).\n\nres = np.array([])\nfor lr in np.arange(0.1,1,0.01):\n    x0 = torch.tensor(-1.0,requires_grad=True)\n    epochs = 20\n    coord = gd_1d(epochs,lr,f,x0)\n    res = np.append(res,np.min(coord[1]))\n\nThis approach raises some new challenges, as certain step sizes cause the gradient descent to diverge. Set for example the step size to \\(\\alpha = 0.79\\) and check out what happens.\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 0.79\nepochs = 20\ncoord = gd_1d(epochs,lr,f,x0)\n\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n\n\n\nBy limiting ourselves to the results where \\(x_N\\) is finite we obtain the following result.\n\nopt_lr = np.arange(0.1,1,0.01)[np.argmin(res[~np.isnan(res)])+1]\nx0 = torch.tensor(-1.0,requires_grad=True)\nprint(\"For a step size of {lr:.2f}, the final value for x_N is {res:.3f}\".format(lr = opt_lr,res = gd_1d(epochs,opt_lr,f,x0)[0][-1]))\n\nFor a step size of 0.52, the final value for x_N is 3.613\n\n\n\n\nWhile the final value \\(x_N\\) is already close to the global minimum at \\(x \\approx 3.607\\), this approach is not stable at all. Setting \\(N = 19\\) yields a final result of \\(x_N \\approx 2.491\\), which misses the global minimum by around \\(1.116\\). This phenomenon motivates the last part of this post."
  },
  {
    "objectID": "posts/Pytorch/Post_02.html#variable-step-sizes",
    "href": "posts/Pytorch/Post_02.html#variable-step-sizes",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02",
    "section": "",
    "text": "In this last paragraph, we discuss the so-called Armijo–Rule. It is a step size selection strategy designed to ensure that in each iteration of the gradient descent, the step size \\(\\alpha\\) is sufficiently large to make progress, and additionally to ensure that a significant decrease in the objective function value is achieved at the same time. By following this rule, we can address all the previous issues at once! The basic idea for finding this optimal step size \\(\\alpha\\) in each of the \\(n=1,...,N\\) steps of the gradient descent is outlined below.\nSet \\(\\beta,\\gamma\\in(0,1)\\) and define an iteration limit \\(M\\) for the following procedure:\nFor each \\(j = 1,...,M\\):\n    1. Check if \\(f(x_n - \\alpha  d_n) \\leq f(x_n) + \\gamma  \\alpha  d_n^2\\).\n    2. If the condition above is not fulfilled, update \\(\\alpha\\) to \\(\\alpha\\beta\\).\n    3. Repeat until 1. is fulfilled or until \\(j=M\\)\nOnce either one of the criteria is fulfilled, perform the next step of gradient descent with the updated \\(\\alpha\\). By iteratively decreasing the step size \\(\\alpha\\), we ensure that the bigger jumps observed before do not occur in a neighborhood of the global minimum.\n\ndef gd_1d_arm(epochs ,lr ,f ,x, gamma, beta, max_iter):\n    coord = []\n    lr_n = lr\n    for epoch in range(epochs):\n        loss = f(x)\n        coord.append([x.data,loss.data])\n        loss.backward()\n        #Armijo-Rule\n        for i in range(max_iter):\n            if f(x - lr_n * x.grad.data) &lt;= f(x) + gamma * lr_n * x.grad.data**2:\n                break\n            lr_n *= beta\n        x.data = x.data - lr_n * x.grad.data\n        x.grad.data.zero_()\n    return np.transpose(np.reshape(coord,(epochs,2)))\n\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nlr = 1\ngamma = 0.01\nbeta=0.5\nepochs = 20\ncoord = gd_1d_arm(epochs,lr,f,x0,gamma,beta,max_iter=10)\n#Uncomment for a static version\n#plt.plot(X,f(X))\n#plt.plot(coord[0],coord[1],'-or')\n#plt.xlim((-2,6))\n#plt.ylim((-2,10))\n#plt.show()\n\n\n\nAn example of how the Armijo Rule works in detail is the following:\nIn the first step of the gradient descent it holds that \\[\\begin{equation*}\nf(x_0)+\\gamma\\alpha d^2 \\approx 3.45 \\ngeq 6.05 \\approx f(x_0- \\alpha d).\n\\end{equation*}\\]\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nf(x0).backward()\n\nplt.plot(X,f(X),\n         color = \"teal\",\n         label = r\"$f(x)$\")\n\nplt.plot(x0.detach(),f(x0.detach()),\n         marker = 'o',\n         color = 'red',\n         label = r\"$f(x_0)$\")\n\nplt.plot(x0.detach() - lr * x0.grad.data,f(x0.detach() - lr * x0.grad.data),\n         marker = 'o',\n         color = 'green',\n         label = r\"$f(x_0- \\alpha d)$\")\nplt.plot([x0.detach(),x0.detach() - lr * x0.grad.data],[f(x0.detach())+gamma*0*x0.grad.data**2,f(x0.detach())+gamma*lr*x0.grad.data**2],\n         linestyle = 'dashed',\n         color = \"orange\",\n         label = r\"$f(x_0)+\\gamma\\alpha d^2$ \")\nplt.plot([x0.detach()-lr*x0.grad.data]*2,[f(x0.detach())+gamma*lr*x0.grad.data**2,f(x0.detach() - lr * x0.grad.data)],\n         linestyle = 'dotted',\n         color = \"black\")\n\nplt.ylim((-2,10))\nplt.xlim((-2,6))\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x29c23468e80&gt;\n\n\n\n\n\n\n\n\n\nHere, the orange dashed line represents the half line \\(\\alpha \\mapsto f(x_0)+\\gamma\\alpha d^2\\) for \\(\\alpha \\in [0,1]\\). As the inequality is not yet satisfied for \\(\\alpha = 1\\), a new learning rate \\(\\alpha = 1*0.5 = 0.5\\) is applied according to the algorithm. This results in \\[\\begin{equation*}\nf(x_0)+\\gamma\\alpha d^2 \\approx 3.28 \\geq 1.59 \\approx f(x_0- \\alpha d).\n\\end{equation*}\\]\n\nx0 = torch.tensor(-1.0,requires_grad=True)\nf(x0).backward()\n\nlr = lr*beta\n\nplt.plot(X,f(X),\n         color = \"teal\",\n         label = r\"$f(x)$\")\n\nplt.plot(x0.detach(),f(x0.detach()),\n         marker = 'o',\n         color = 'red',\n         label = r\"$f(x_0)$\")\n\nplt.plot(x0.detach() - lr * x0.grad.data,f(x0.detach() - lr * x0.grad.data),\n         marker = 'o',\n         color = 'green',\n         label = r\"$f(x_0- \\alpha d)$\")\nplt.plot([x0.detach(),x0.detach() - lr * x0.grad.data],[f(x0.detach())+gamma*0*x0.grad.data**2,f(x0.detach())+gamma*lr*x0.grad.data**2],\n         linestyle = 'dashed',\n         color = \"orange\",\n         label = r\"$f(x_0)+\\gamma\\alpha d^2$ \")\nplt.plot([x0.detach()-lr*x0.grad.data]*2,[f(x0.detach())+gamma*lr*x0.grad.data**2,f(x0.detach() - lr * x0.grad.data)],\n         linestyle = 'dotted',\n         color = \"black\")\n\nplt.ylim((-2,10))\nplt.xlim((-2,6))\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x29c17a3d640&gt;\n\n\n\n\n\n\n\n\n\nAs this new learning rate satisfies the inequality, it is applied in the step of the gradient descent.\nThe seemingly fruitful approach does not come without a price. By adding more variables, i.e., \\(\\gamma\\), \\(\\beta\\), and the maximum iteration number \\(M\\), fine–tuning the algorithm gets more complicated.\nHowever, in most cases, there is a rule of thumb that works well for setting the initial parameters, which involves choosing \\(\\alpha = 1\\), \\(\\beta = 0.5\\), \\(\\gamma = 0.01\\), and \\(M=10\\) to satisfy this guideline."
  },
  {
    "objectID": "posts/Pytorch/Post_02.html#summary",
    "href": "posts/Pytorch/Post_02.html#summary",
    "title": "A Gentle (Mathematicians) Introduction to PyTorch and Neural Networks Part 02",
    "section": "",
    "text": "In this blog post, we introduced the powerful method of gradient descent in one dimension and learned how to implement it using the PyTorch framework. We discussed some common pitfalls of using gradient descent like choosing a step size \\(\\alpha\\) that is either too big or too small. In the last section we briefly introduced the Armijo–Rule which utilized a variable step size for each iteration of the gradient descent."
  }
]