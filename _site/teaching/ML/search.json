[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Supplementary Material",
    "section": "",
    "text": "Preface\nThis (exercise) manuscript supplements the lecture notes provided for Prof. Dr. Yarema Okhrin’s lecture Machine Learning at the University of Augsburg.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-this-manuscript-is",
    "href": "index.html#what-this-manuscript-is",
    "title": "Machine Learning Supplementary Material",
    "section": "What this manuscript is",
    "text": "What this manuscript is\nThe manuscript intends to provide more context to different areas usually neglected in lecture and exercise sessions. The exercise sessions can especially suffer from an imbalance between repeating the theoretical aspects of the lecture and applying the concepts thoroughly. Moreover, this manuscript is comprehensive, containing every exercise and solution presented in the exercise sessions. The solutions will be more detailed than the ones presented in the in-person sessions, which can help you prepare for the exam.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-this-manuscript-isnt",
    "href": "index.html#what-this-manuscript-isnt",
    "title": "Machine Learning Supplementary Material",
    "section": "What this manuscript isn’t",
    "text": "What this manuscript isn’t\nThe manuscript is not a replacement for the lecture and exercise sessions. This manuscript especially lacks is the interaction between the students and lecturers which is an important aspect of the in-person exercise sessions.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#structure-of-the-manuscript",
    "href": "index.html#structure-of-the-manuscript",
    "title": "Machine Learning Supplementary Material",
    "section": "Structure of the manuscript",
    "text": "Structure of the manuscript\nDepending on the complexity of the topic, each chapter starts with a more or less technical summary and motivation. Following these summaries there will be examples that feature functions and concepts needed for the exercises. The exercises and solutions can be found subsequent to these examples.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_prerequisites.html",
    "href": "01_prerequisites.html",
    "title": "1  Important R concepts",
    "section": "",
    "text": "1.1 Setting up R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#setting-up-r",
    "href": "01_prerequisites.html#setting-up-r",
    "title": "1  Important R concepts",
    "section": "",
    "text": "1.1.1 Installing R, RStudio, and getting started with Quarto\nBefore starting the revision, we need to ensure that R and RStudio are installed. The installation process for both R and RStudio is straightforward and user-friendly. While R (the programming language) comes with a preinstalled graphical user interface, we will use the integrated development environment RStudio instead, as it looks more appealing and provides some features RGui lacks. It is important to note that in order to get RStudio to work, R needs to be installed first.\n\nR (for Windows) can be downloaded here.\nRStudio can be downloaded here.\n\nAfter successfully installing R and RStudio, starting the latter should open a window that somewhat looks like the following (cf. RStudio User Guide).\n\n\n\n\n\nThe Source pane displays a .R file named ggplot2.R. While .R files are the standard file format for R scripts used for programming in R, we will use Quarto documents (files ending with .qmd). Quarto labels itself as the\n\nnext-generation version of R Markdown,\n\nmeaning that a Quarto document allows\n\nweaving together narrative text and code to produce elegantly formatted output as documents, web pages, books, and more.\n\nQuarto is preinstalled in RStudio, so creating such documents is relatively simple.\n\nclick on New File -&gt; Quarto Document... in the File tab \nOnce the New Quarto Document window opens, you can modify the title and specify the output format. For the sake of simplicity, we will use the HTML output format. However, you could also choose PDF if you have a LaTeX installation on your device. Clicking on the create button will create a new Quarto Document. \nThe source pane now displays a sample Quarto document that can be modified. You might have to install rmarkdown (cf. mark 1). The Quarto document can then be modified by clicking on the respective sections. R Code cells can be executed by clicking on the green arrow (cf. mark 2). To insert new R code cells between paragraphs, click on the Insert tab and select Executable Cell -&gt; R (cf. mark 3).\n\n\n\n\n\n\nThis should be enough to get you started with Quarto Documents. For further reading, I recommend the Quarto Guide.\n\n\n\n\n\n\nTip\n\n\n\n\nWhile solving the (programming) exercises, you can create a new paragraph using # for a new chapter to make your document more readable. Additionally, you can simply create a section using ##.\nWriting down some details on how you approached the programming exercises in a paragraph above or below can help you understand your approach when repeating the exercises later.\n\n\n\n\n\n1.1.2 Working directories and projects\nAfter opening RStudio, execute the getwd() command in the console pane, which returns the current working directory. The working directory displays the directory of the R process. For example, if the return value of the getwd() command is C:\\Users\\lachlinu\\Desktop\\ML, then R can access any file in the ML directory. One way to change the working directory is using the setwd() command, which changes the current working directory. Manually changing the directory in every .qmd document might become tedious after a while, so a more practical alternative is setting up a project. RStudio projects allow the creation of an individual working directory for multiple contexts. For example, you might use R not only for solving Machine Learning exercises but also for your master’s thesis. Then, setting up two different projects will help you organize working directories and workspaces for each project individually. To set up a project for this course\n\nGo to the File tab and select New Project....\n\n\n\n\n\nChoose Existing Directory and navigate to the directory in which you want to create the project in and click the Create Project button.\n\n\n\n\n\nYou can now open the project by double clicking on the icon which should open a new RStudio window.\n\n\n\n\n\n\nOnce the project is opened, running the getwd() command in the console pane returns its path. Any file in this directory can be directly accessed without specifying the preceding path.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#help-my-code-doesnt-do-what-i-expect-it-to-do",
    "href": "01_prerequisites.html#help-my-code-doesnt-do-what-i-expect-it-to-do",
    "title": "1  Important R concepts",
    "section": "1.2 Help, my code doesn’t do what I expect it to do!",
    "text": "1.2 Help, my code doesn’t do what I expect it to do!\nDebugging, also known as finding out why code does not behave as expected, plays a substantial role in programming. Even after years of practice, occasional bugs will occur. There are several more or less effective approaches to resolve problems that might occur in the context of this course, with debugging being a key focus.\n\nA simple Google search can do wonders. Most questions that arise in the context of this lecture have probably been asked on boards like Stack Overflow. Alternatively, the search results might contain websites like DataCamp or GeeksforGeeks, which will most likely answer your question as well.\nUsing a large language model like ChatGPT. When it comes to debugging or coding questions in general, large language models are helpful. Enter your question as a prompt and the answer will likely help you. However, when using less popular libraries, the answers might contain hallucinations that make it much more difficult to resolve your problem.\nThe internal help function, while it might be considered old-school, is a highly effective troubleshooting approach. It can provide valuable insights when a function doesn’t behave as expected. If a function doesn’t behave as expected, typing ?function_name in the console pane opens the respective help page. The Arguments section of the help page explains the different input parameters of a function. The Value section describes what the function intends to return. Examples of how to use a function are provided in the last section of the help.\nIf each of the steps above fails, you can also ask questions via mail. When reporting a problem via mail, it’s crucial to provide some context and the steps you’ve tried to solve it yourself. This information is invaluable in understanding the issue and providing an effective solution. Also, as part of the learning process, try solving the problems first since that is one of the most essential skill sets to develop.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#working-with-datasets",
    "href": "01_prerequisites.html#working-with-datasets",
    "title": "1  Important R concepts",
    "section": "1.3 Working with datasets",
    "text": "1.3 Working with datasets\nIn the context of machine learning, data builds the foundation. Whether you want to predict the weather, future stock prices, or the base rent of a potential rental apartment, without high-quality data, even the most advanced models fail. However, the reality is that data we gather from the web, servers, or spreadsheets is often far from pristine. For example, missing values could be encoded as NA (Not Available), NaN (Not a Number), NULL, or simply by an empty string \" \". That is why knowing your way around basic data manipulation is essential.\n\n1.3.1 Importing data\nTo manipulate data, we first need to import it. R has quite a few preinstalled data sets; however, I prefer data sets that are either more complex, related to everyday life, or just more fun to explore. This course will provide most of the data in .csv or .txt files. Before we can start manipulating data, it’s essential to import it correctly. This ensures that the data is in the right format for further analysis.\nConsider the Netflix Movies and TV Shows data set, which can be downloaded from the data science community website Kaggle or directly below.\n\nDownload Netflix Data\n\nOnce you have downloaded the data and placed it in your current working directory, you can import it using the read.csv command:\n\ndata_netflix &lt;- read.csv(\"netflix_titles.csv\")\n\n\n\n\n\n\n\nPro Tip\n\n\n\nTo maintain structure in your project folder, it is advisable to create a separate directory for the data and import it from there. For example, if the project directory contains a data directory with the netflix_title.csv file inside, it can be imported using\n\ndata_netflix &lt;- read.csv(\"data/netflix_titles.csv\")\n\n\n\n\n\n1.3.2 Essential functions and libraries\nOne of the most versatile and essential collection of libraries in the context of data science with R is the {tidyverse} library, which includes\n\n{ggplot} for creating beautiful graphics,\n{dplyr} for data manipulation,\n{stringr} for working with strings, and\n{tibble} for storing data effectively.\n\nAn excellent in-depth introduction to the tidyverse called R for Data Science is freely available online if that piques your interest. This introduction focuses on a few core functions that will be useful throughout the course. As every other library, {tidyverse} can be attached using the library function once it has been installed:\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nOnce the library has been added, every function contained is available. For example, the glimpse function can be used on the data_netflix data set to get a short overview of the data types and contents:\n\nglimpse(data_netflix)\n\nRows: 8,807\nColumns: 12\n$ show_id      &lt;chr&gt; \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s1…\n$ type         &lt;chr&gt; \"Movie\", \"TV Show\", \"TV Show\", \"TV Show\", \"TV Show\", \"TV …\n$ title        &lt;chr&gt; \"Dick Johnson Is Dead\", \"Blood & Water\", \"Ganglands\", \"Ja…\n$ director     &lt;chr&gt; \"Kirsten Johnson\", \"\", \"Julien Leclercq\", \"\", \"\", \"Mike F…\n$ cast         &lt;chr&gt; \"\", \"Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Mola…\n$ country      &lt;chr&gt; \"United States\", \"South Africa\", \"\", \"\", \"India\", \"\", \"\",…\n$ date_added   &lt;chr&gt; \"September 25, 2021\", \"September 24, 2021\", \"September 24…\n$ release_year &lt;int&gt; 2020, 2021, 2021, 2021, 2021, 2021, 2021, 1993, 2021, 202…\n$ rating       &lt;chr&gt; \"PG-13\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"PG…\n$ duration     &lt;chr&gt; \"90 min\", \"2 Seasons\", \"1 Season\", \"1 Season\", \"2 Seasons…\n$ listed_in    &lt;chr&gt; \"Documentaries\", \"International TV Shows, TV Dramas, TV M…\n$ description  &lt;chr&gt; \"As her father nears the end of his life, filmmaker Kirst…\n\n\nRows: 8,807 means that the data set has 8,807 entries, and Columns: 12 means that the data set has 12 variables, respectively. The first column presents the variable names, their data types, and some initial values, providing a clear structure to the data set. We can already see that except for one variable (release_year), every other variable is of type chr, which stands for character or string.\n\n1.3.2.1 Filtering, grouping, and summarizing data sets\nFunctions frequently encountered while working with data are filter, group_by, and summarise. Let’s say we want to find out, according to the data set, how many movies and series were released in each year following 2010. Now, if we were to tackle this problem without the {tidyverse} framework, our code might look a little something like this:\n\nnetflix_filtered &lt;- data_netflix[data_netflix$release_year &gt; 2010, ]\nresult &lt;- aggregate(rep(1, nrow(netflix_filtered)), \n                    by = list(netflix_filtered$release_year), \n                    FUN = sum)\ncolnames(result) &lt;- c(\"release_year\", \"n\")\nresult\n\n   release_year    n\n1          2011  185\n2          2012  237\n3          2013  288\n4          2014  352\n5          2015  560\n6          2016  902\n7          2017 1032\n8          2018 1147\n9          2019 1030\n10         2020  953\n11         2021  592\n\n\nor this:\n\nnetflix_filtered &lt;- data_netflix[data_netflix$release_year &gt; 2010, ]\nresult &lt;- as.data.frame(table(netflix_filtered$release_year))\ncolnames(result) &lt;- c(\"release_year\", \"n\")\nresult\n\n   release_year    n\n1          2011  185\n2          2012  237\n3          2013  288\n4          2014  352\n5          2015  560\n6          2016  902\n7          2017 1032\n8          2018 1147\n9          2019 1030\n10         2020  953\n11         2021  592\n\n\nThe first code cell seems much more complicated than the second, yet it returns the same result. However, things can be simplified even more using the {dplyr} library that is contained in the {tidyverse}:\n\nnetflix_filtered &lt;- data_netflix %&gt;%\n  filter(release_year&gt;2010) %&gt;%\n  group_by(release_year) %&gt;%\n  summarise(n= n())\n\nLet us break down the code snippet above:\n\nIn line 1 we use the pipe operator %&gt;%. It is part of the {magrittr} package and forwards an object into a function of call expression. Figuratively, a pipe does precisely what is expected: channel an object from one and to another. In this case, the pipe operator %&gt;% passes the data_netflix data set into the filter function.\nIn line 2 the filter function selects a subset of a data set that satisfies a given condition. Here, the condition is that the movie or series’ release year should be after 2010, which is indicated by the &gt; condition.\n\n\n\n\n\n\nNote\n\n\n\nWithout the pipe operator, the first and second line can be merged into\n\nfilter(data_netflix,release_year&gt;2010)\n\nhowever, concatenating multiple functions causes the code to be unreadable and should thus be avoided.\n\n\nResults of the filtering procedure are then passed to the group_by function via the pipe operator again. The group_by function converts the underlying data set into a grouped one where operations can be performed group-wise. In the third line of the code cell, the group_by function is applied to the release_year variable, meaning that the data set now contains a group for every release year.\nThis can be seen as a pre-processing step for the summarise function applied in the following line. The summarise function creates a new data set based on the functions passed as arguments. These functions are applied to every group created by the previous step. In the example above, the function applied is n(), which returns the group size. Thus, setting n=n() as the argument creates a new column named n, which contains the number of samples within each group.\n\n\n\n\n1.3.3 Mutating data sets\nBesides filtering, grouping, and summarizing, another important concept is mutating the data, i.e., modifying the content of the data set.\nThe mutate function either creates new columns or modifies existing columns based on the passed column names and functions that are passed. It is helpful for modifying data and their types, creating new variables based on existing ones, and removing unwanted variables. In the example below, the mutate function is used to modify the variable date_added, create a new variable called is_show and delete the variable type.\n\ndata_netflix &lt;- data_netflix %&gt;% \n  mutate(date_added = mdy(date_added),\n         is_show = if_else(type==\"TV Show\",TRUE,FALSE),\n         type = NULL\n         )\n\n\nIn the first line of the code cell, the data set data_netflix is specified to be overwritten by its mutated version. Overwriting a data set is achieved by reassigning the data_netlifx object to the output of the pipe concatenation of the following code lines.\nThe original data_netflix data set is passed into the mutate function in the second line. Here, the variable date_written is overwritten by the output of the mdy function with argument date_added. The mdy function is a function in the {lubridate} library that transforms dates stored in strings to date objects that are easier to handle. Note that we can directly pass column names into functions as we have previously passed the data set into the mutate function using the %&gt;% operator.\nIn the third line, a new variable is_show is created, which takes the value TRUE, if the type of an entry in the data set is \"TV Show\" and FALSE if it is not. The if_else function achieves this.\nSetting the type variable to NULL effectively removes it from the data set.\n\n\n\n\n\n\n\nNote\n\n\n\nAssigning values in functions is achieved by using the = symbol. Assigning new variables outside of functions can also be done with the = symbol, but it is rarely used and except for some pathological cases there is no difference. However, most R users prefer assigning environment variables using &lt;- which does not work in function calls.\n\n\n\n\n\n\n\n\nPro Tip\n\n\n\nIn the previous code cell a line break was added after the %&gt;% and each argument in the mutate function for readability purposes. The code also works without adding the line breaks, but it can get messy fast:\n\ndata_netflix &lt;- data_netflix %&gt;% mutate(date_added = mdy(date_added), is_show = if_else(type==\"TV Show\",TRUE,FALSE), type = NULL)\n\n\n\n\n\n1.3.4 Factor Variables\nAn important data type that can handle both ordinal (data with some notion of order) and nominal data are so-called factor variables.\nConsider the following toy data set containing seven people with corresponding age groups and eye colors.\n\n\n# A tibble: 7 × 3\n  names   age_groups eye_color\n  &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;    \n1 Alice   18-25      Blue     \n2 Bob     &lt;18        Brown    \n3 Charlie 26-35      Green    \n4 Diana   36-45      Hazel    \n5 Eve     18-25      Brown    \n6 Frank   60+        Blue     \n7 Grace   26-35      Green    \n\n\nSince the variable age_group only specifies a range of ages, it does not make sense to encode them as integers rather than ordinal variables. The’ mutate’ function can encode age groups as ordinal variables. This involves setting the age_groups variable to a factor with levels and labels. Levels specify the order of the values, and labels can be used to rename these categories.\n\ndata_example &lt;- data_example %&gt;%\n  mutate( \n    age_groups = factor(\n      age_groups,\n      levels = c(\"&lt;18\", \"18-25\", \"26-35\", \"36-45\", \"60+\"),\n      labels = c(\"child\",\"adult\",\"adult\",\"adult\",\"senior\"),\n      ordered = TRUE\n    )\n  )\n\n\nSimilar to the previous example, we should specify that we overwrite the data_example data set with a mutated version.\nThe mutate function is applied to the age_groups variable.\nSetting age_groups = factor(age_groups, ...) converts the age_groups column into a (so far unordered) factor, allowing for specific levels (categories) and labels.\nlevels = c(\"&lt;18\", \"18-25\",...) specifies the predefined levels for the age groups.\nordered=TRUE specifies that the age groups are ordered according to the specified levels.\nLast but not least, labels = c(\"child\", \"adult\", ...) specifies the labels that replace the numeric age groups. For instance, &lt;18 is labeled as \"child\", the ranges 18-25, 26-35, and 36-45 are labeled as \"adult\", and 60+ is labeled as \"senior\".\n\nSimilarly, the variable eye_color can also be converted to a nominal factor variable:\n\ndata_example &lt;- data_example %&gt;%\n  mutate(\n    eye_color = factor(eye_color)\n  )\n\nTo confirm that the variable age_group is indeed ordered, calling the feature shows the ordered levels:\n\ndata_example$age_groups\n\n[1] adult  child  adult  adult  adult  senior adult \nLevels: child &lt; adult &lt; senior",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#visualizing-data-with-ggplot",
    "href": "01_prerequisites.html#visualizing-data-with-ggplot",
    "title": "1  Important R concepts",
    "section": "1.4 Visualizing data with ggplot",
    "text": "1.4 Visualizing data with ggplot\nAnother critical aspect of data science and machine learning is graphical storytelling. Describing an algorithm strictly using mathematical notation or exploring a data set using descriptive and inductive statistics alone can make it challenging to understand the message. While R offers some base functions for creating graphics, this course primarily uses the library {ggplot2}. A comprehensive introduction to {ggplot2} can be found in Hadley Wickham’s book Elegant Graphics for Data Analysis. A short summary can be found below.\nFor the following example, we will use the netflix_filtered data set (see Section 1.3.2.1)\nA graphic created with {ggplot2} consists of the following three base components:\n\nThe data itself.\n\nggplot(data = netflix_filtered)\n\n\n\n\n\n\n\n\nNote, that the plot does not show any axis, ticks, and variables.\nA set of aesthetics mappings that describe how variables in the data are mapped to visual properties.\n\nggplot(aes(x=release_year, y=n), data = netflix_filtered)\n\n\n\n\n\n\n\n\nUsing the aes function, we have specified that the release year should be mapped to the \\(x\\)-axis, and \\(n\\) to the \\(y\\)-axis.\nLastly, the geom-layer (component) describes how each observation in the data set is represented.\n\nggplot(aes(x=release_year, y=n), data = netflix_filtered)+\n  geom_col()+\n  geom_point()+\n  geom_line()\n\n\n\n\n\n\n\n\nCompared to the previous two code cells, a lot is going on here. So, let us break it down.\n\nThe plus at the end of line 1 is used to add another layer.\ngeom_col adds a column chart to the canvas, creating columns starting at 0 and ending at \\(n\\). Then, + indicates that another layer is added.\ngeom_point represents the data as points on the plane, i.e., an \\(x\\) and \\(y\\)-coordinate. The + indicates that yet another layer is added afterward.\nLastly, the geom_line function adds a line connecting each data point with the one following.\n\n\n\n\n\n\n\nPro Tips\n\n\n\n\nAs before, the data set can also directly be piped into the ggplot function:\n\nnetflix_filtered %&gt;%\nggplot(aes(x=release_year, y=n))+\n geom_col()+\n geom_point()+\n geom_line()\n\nBy changing the order of the layers, you can specify which layer should be added first and last. In this example, since geom_col was added first and every other layer is placed on top of the column plot.\n\n\n\n\nThere are a lot more functions and settings that can be applied to each function. A selection of those is discussed in the exercises.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#exercises",
    "href": "01_prerequisites.html#exercises",
    "title": "1  Important R concepts",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\nThroughout the exercises, we will work with the Credit Card Customers data set that can either be downloaded using the provided link or the button below.\n\nDownload BankChurners\n\nThe data set consists of 10,127 entries that represent individual customers of a bank including but not limited to their age, salary, credit card limit, and credit card category.\n\n1.5.1 Statistical Data Exploration and Manipulation\nWe will start by getting a feeling for the data and performing some basic data manipulation steps.\n\nExercise 1.1 Import the data set and use the glimpse function to generate a summary of the data set.\n\n\nExercise 1.2 Assume that the data set has been imported and saved as an object called credit_info. Explain the following code snippet both syntactically and semantically. Hint: Use the help function for any function you do not know.\n\ncredit_info %&gt;%\n  select_if(is.character) %&gt;%\n  sapply(table)\n\n$Attrition_Flag\n\nAttrited Customer Existing Customer \n             1627              8500 \n\n$Gender\n\n   F    M \n5358 4769 \n\n$Education_Level\n\n      College     Doctorate      Graduate   High School Post-Graduate \n         1013           451          3128          2013           516 \n   Uneducated       Unknown \n         1487          1519 \n\n$Marital_Status\n\nDivorced  Married   Single  Unknown \n     748     4687     3943      749 \n\n$Income_Category\n\n       $120K +    $40K - $60K    $60K - $80K   $80K - $120K Less than $40K \n           727           1790           1402           1535           3561 \n       Unknown \n          1112 \n\n$Card_Category\n\n    Blue     Gold Platinum   Silver \n    9436      116       20      555 \n\n\n\n\nExercise 1.3 Overwrite the variables Income_Category and Education_Level into ordered factors. When setting the levels for each group, set \"Unknown\" as the lowest level. Use this cleaned data set for the remaining exercises.\n\n\nExercise 1.4 Group the data set by income category and find out each group’s mean and median credit limit.\n\n\nExercise 1.5 Which income group has the highest mean credit limit?\n\n\nExercise 1.6 Use the following code snippet to modify the data set by incorporating it into the mutate function. The snippet converts all \"Unknown\" values contained in character or factor columns into NA values, which are easier to handle.\n\nacross(where(~ is.character(.) | is.factor(.)),\n       ~na_if(.,\"Unknown\"))\n\n\n\nExercise 1.7 Apply the na.omit() function to the data set to remove all samples in the data set that contain NA values. How many samples have been removed in total?\n\nSometimes, we only want to infer results for specific subgroups. The Blue Credit Card is the most common type of credit card. Gaining insights for this particular group allows us to retrieve information that might be useful in later analyses.\n\nExercise 1.8 Find out how many customers have a Blue credit card.\n\n\nExercise 1.9 Create a new data set credit_info_blue containing all customers that hold a Blue credit card.\n\n\nExercise 1.10 Find the number of female customers holding the Blue Card who are, at most, 40 years old and have a credit limit above 10,000 USD.\n\n\n\n1.5.2 Visual Data Exploration\n\nExercise 1.11 We now want to explore some of the demographics in our data set. Create a histogram for the age of the customers using the geom_histogram function. Note that only one variable is required for the aesthetics to create a histogram.\n\n\nExercise 1.12 Using the default parameters in the geom_histogram function, the message “stat_bin() using bins = 30. Pick better value with binwidth.” is displayed. Modify the code so that each age gets its own bin.\n\n\nExercise 1.13 Now that the histogram looks more organized, we want to add more information. For example, by setting the fill option to Gender, we can create two overlapping histograms showing the number of male and female customers within each age group.\n\n\nExercise 1.14 Instead of visualizing the Gender as in the plot above, we now want to analyze the continuous variable Credit_Limit. Therefore, instead of a histogram, use the geom_density function that plots an estimate of the underlying probability density.\n\n\nExercise 1.15 The histograms and density plots only provide limited insight into the demographics and customer status as it is relatively complex to figure out the proportions of each group. To take this one step further, consider the following histogram, which shows the Education_Level within every bin.\n\nggplot(data = credit_info_clean, aes(Customer_Age, fill = Education_Level))+\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\n\nWe can use the geom_histogram function and the facet_wrap function, which generates a subplot for each group. Apply the facet_wrap function to create a subplot for each education level.\n\n\n\n1.5.3 Loss functions\nIn future exercises, different loss functions will be deployed to measure how far some regression results deviate from actual values. This exercise, therefore, briefly discusses the advantages and disadvantages of some loss functions and introduces them in R.\nData-wise, we will consider the credit_info dataset and a simple linear model that is used to predict each customer’s credit limit.\nThe following Code snippet reads the unmodified data, removes the features Total_Revolving_Bal and Avg_Open_To_Buy and trains a linear model with target variable Credit_Limit on all the remaining features. It’s important to note that the model is intentionally kept simple for demonstrative purposes, making it easier for you to grasp and apply the concepts.\nCopy the snippet into your own notebook and run it. Hint: You might have to change the path in the read.csv function to your specified data path (Exercise 2.1) and install the libraries that are attached.\n\nlibrary(tidymodels)\nlibrary(yardstick)\n\ncredit_info &lt;- read.csv(\"data/BankChurners.csv\")\n\nmodel_linear_data &lt;- credit_info %&gt;%\n  select(-c(Total_Revolving_Bal,Avg_Open_To_Buy))\n\nmodel_linear_res &lt;- linear_reg() %&gt;%\n  fit(Credit_Limit ~., data = model_linear_data) %&gt;%\n  augment(model_linear_data)\n\nThe object model_linear_res now contains our model’s original data set and predictions. Do not worry if you do not understand every line in the snippet above. We will consider training models in future exercises more thoroughly.\n\n1.5.3.1 MAE Loss\nThe first loss function we explore is the Mean Absolute Error (MAE) loss defined as\n\\[\\begin{equation*}\n  \\mathrm{MAE} := \\mathrm{MAE}(y,\\hat{y}):=\\frac{1}{n}\\sum_{i=1}^n |y_i-\\hat{y_i}|,\n\\end{equation*}\\]\nwhere \\(y=(y_1,...,y_n)\\) are target values and \\(\\hat{y}=(\\hat{y_1},...,\\hat{y_n})\\) are estimates of the target values.\n\nExercise 1.16 Briefly explain how the MAE loss can be interpreted regarding the target features scale.\n\n\nExercise 1.17 The mae loss is a function in the {yardstick} library. If not already done, install the {yardstick} library and read the help function of the mae function. Then, apply it tot the model_linear_res data set and interpret the result.\n\n\n\n1.5.3.2 (R)MSE\nAnother widely used loss function is the (Root)MeanSquareError. It is defined as\n\\[\\begin{align*}\n  \\mathrm{RMSE} &:= \\mathrm{RMSE}(y,\\hat{y}) := \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2}\\\\\n  \\mathrm{MSE} &:= \\mathrm{MSE}(y,\\hat{y}) := \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2\n\\end{align*}\\]\n\nExercise 1.18 Repeat the exercise Exercise 1.16 and Exercise 1.17 for the RMSE and MSE.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#solutions",
    "href": "01_prerequisites.html#solutions",
    "title": "1  Important R concepts",
    "section": "1.6 Solutions",
    "text": "1.6 Solutions\n\nSolution 1.1 (Exercise 2.1). \n\ncredit_info &lt;- read.csv(\"data/BankChurners.csv\")\n\n\n\nSolution 1.2 (Exercise 2.2). \n\ncredit_info %&gt;%\n  select_if(is.character) %&gt;%\n  sapply(table)\n\n$Attrition_Flag\n\nAttrited Customer Existing Customer \n             1627              8500 \n\n$Gender\n\n   F    M \n5358 4769 \n\n$Education_Level\n\n      College     Doctorate      Graduate   High School Post-Graduate \n         1013           451          3128          2013           516 \n   Uneducated       Unknown \n         1487          1519 \n\n$Marital_Status\n\nDivorced  Married   Single  Unknown \n     748     4687     3943      749 \n\n$Income_Category\n\n       $120K +    $40K - $60K    $60K - $80K   $80K - $120K Less than $40K \n           727           1790           1402           1535           3561 \n       Unknown \n          1112 \n\n$Card_Category\n\n    Blue     Gold Platinum   Silver \n    9436      116       20      555 \n\n\n\nIn the first line, the data set credit_info is passed to the following line.\nThe credit_info data set is passed into the select_if function that selects columns of the data set based on some condition passed in the arguments. In this case, the condition is the is.character function, that checks, whether a column is of type chr. The results are then piped into the following line.\nIn the third line, the selected columns are passed into the sapply function, that applies a given function column wise to a data set and returns the resulting data set. Here, the table function is applied generating a contingency table of the counts for each column.\n\n\n\nSolution 1.3 (Exercise 1.3). \n\ncredit_info_clean &lt;-credit_info %&gt;%\n  mutate(Income_Category = factor(Income_Category,\n                                  levels = c(\"Unknown\",\"Less than $40K\",\n                                            \"$40K - $60K\",\"$60K - $80K\",\n                                            \"$80K - $120K\",\"$120K +\"),\n                                  ordered = TRUE),\n         Education_Level = factor(Education_Level,\n                                  levels = c(\"Unknown\",\"Uneducated\",\n                                             \"High School\",\"College\",\n                                             \"Graduate\", \"Post-Graduate\",\n                                             \"Doctorate\")\n                                  )\n         )\n\n\n\nSolution 1.4 (Exercise 1.4). \n\ncredit_info_clean %&gt;%\n  group_by(Income_Category) %&gt;%\n  summarise(\n    meanlim = mean(Credit_Limit),\n    medlim = median(Credit_Limit)\n  )\n\n# A tibble: 6 × 3\n  Income_Category meanlim medlim\n  &lt;ord&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n1 Unknown           9517.   6380\n2 Less than $40K    3754.   2766\n3 $40K - $60K       5462.   3682\n4 $60K - $80K      10759.   7660\n5 $80K - $120K     15810.  12830\n6 $120K +          19717.  18442\n\n\n\n\nSolution 1.5 (Exercise 1.5). \n\ncredit_info_clean %&gt;%\n  group_by(Income_Category) %&gt;%\n  summarise(\n    mean_group = mean(Credit_Limit)\n  )\n\n# A tibble: 6 × 2\n  Income_Category mean_group\n  &lt;ord&gt;                &lt;dbl&gt;\n1 Unknown              9517.\n2 Less than $40K       3754.\n3 $40K - $60K          5462.\n4 $60K - $80K         10759.\n5 $80K - $120K        15810.\n6 $120K +             19717.\n\n\nUnsurprisingly, the highest income category also has the highest mean credit limit (19,717 USD).\n\n\nSolution 1.6 (Exercise 1.6). \n\ncredit_info_clean &lt;- credit_info_clean %&gt;%\n  mutate(across(\n    where(~ is.character(.) | is.factor(.)),\n    ~ na_if(., \"Unknown\")\n  ))\n\n\n\nSolution 1.7 (Exercise 1.7). \n\nnrow_old &lt;- nrow(credit_info_clean)\n\ncredit_info_clean &lt;- credit_info_clean %&gt;%\n  na.omit()\n\nglue::glue(\"{nrow_old-nrow(credit_info_clean)} samples were removed.\")\n\n3046 samples were removed.\n\n\n\n\nSolution 1.8 (Exercise 1.8). \n\ncredit_info_clean %&gt;%\n  group_by(Card_Category) %&gt;%\n  summarise(n=n())\n\n# A tibble: 4 × 2\n  Card_Category     n\n  &lt;chr&gt;         &lt;int&gt;\n1 Blue           6598\n2 Gold             81\n3 Platinum         11\n4 Silver          391\n\n\n\n\nSolution 1.9 (Exercise 1.9). \n\ncredit_info_blue &lt;- credit_info_clean %&gt;%\n  filter(Card_Category == \"Blue\")\n\n\n\nSolution 1.10 (Exercise 1.10). \n\ncredit_info_blue %&gt;%\n  filter(Gender == \"F\" &\n           Customer_Age &lt;= 40 &\n           Credit_Limit &gt; 10000) %&gt;%\n  count()\n\n  n\n1 7\n\n\n\n\nSolution 1.11 (Exercise 1.11). \n\nggplot(data = credit_info_clean, aes(Customer_Age))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nSolution 1.12 (Exercise 1.12). \n\nggplot(data = credit_info_clean, aes(Customer_Age))+\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\n\n\n\nSolution 1.13 (Exercise 1.13). \n\nggplot(data = credit_info_clean, aes(Customer_Age, fill = Gender))+\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\n\n\n\nSolution 1.14 (Exercise 1.14). \n\nggplot(data = credit_info_clean, aes(Credit_Limit))+\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nSolution 1.15 (Exercise 1.15). \n\nggplot(data = credit_info_clean,\n       aes(Customer_Age, fill = Education_Level)\n       )+\n  geom_histogram(binwidth = 1) +\n  facet_wrap(\"Education_Level\")\n\n\n\n\n\n\n\n\n\n\nSolution 1.16 (Exercise 1.16). The Mean Absolute Error (MAE) loss can be interpreted in terms of the scale of the target features because it directly measures the average absolute difference between predicted and actual target values. Thus, if the target variable is on a large scale (e.g., thousands), MAE will also be large. Conversely, for small target values, the MAE will be correspondingly smaller. This makes MAE sensitive to the scale of the target features, and it is essential to normalize or scale data if different features or targets are on very different scales to ensure the MAE provides meaningful comparisons across models or data sets.\n\n\nSolution 1.17 (Exercise 1.17). The model_linear_res data set contains the .pred column, where predictions of the linear model are saved. We can use the predictions and the outcome variable Credit_Limit to calculate the MAE.\n\nmodel_linear_res %&gt;% mae(.pred,Credit_Limit)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard       4114.\n\n\nAn MAE of 4114 indicates that on average, the predicted credit limit of a customer deviates 4114 USD.\n\n\nSolution 1.18 (Exercise 1.18). \n\nSimilar to the MAE loss, the RMSE can be interpreted in terms of the scale of the target features. It also measures the average difference between the observed and predicted values, but its unique feature is that it emphasizes outliers more. Greater distances are weighted more heavily due to the square term, thereby enhancing prediction accuracy.\n\nmodel_linear_res %&gt;% yardstick::rmse(.pred,Credit_Limit)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       5628.\n\n\nAn RMSE of 5628 indicates that, on average, a customer’s predicted credit limit deviates 5628 USD.\nAs for the MSE, the error units are expressed as squared terms. Therefore, the scales can not be interpreted directly. MSE is usually deployed in practice since it has some nice properties like differentiability at \\(0\\), which the MAE lacks. Moreover, MSE is easier to compute, thanks to the absence of a square root, which reduces computational time.\n\nmodel_linear_rmse &lt;- model_linear_res %&gt;% rmse(.pred,Credit_Limit) %&gt;%\n  pluck(\".estimate\")\nmodel_linear_rmse^2\n\n[1] 31676421",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "01_prerequisites.html#session-info",
    "href": "01_prerequisites.html#session-info",
    "title": "1  Important R concepts",
    "section": "1.7 Session Info",
    "text": "1.7 Session Info\nThe sessionInfo() function captures detailed information about the current R session, including the version of R and loaded packages. This is useful for ensuring reproducibility of analyses and troubleshooting code, as it provides a snapshot of the environment in which the code was executed.\n\nsessionInfo()\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.utf8  LC_CTYPE=German_Germany.utf8   \n[3] LC_MONETARY=German_Germany.utf8 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] yardstick_1.2.0    workflowsets_1.0.1 workflows_1.1.3    tune_1.1.2        \n [5] rsample_1.2.0      recipes_1.0.8      parsnip_1.1.1      modeldata_1.2.0   \n [9] infer_1.0.5        dials_1.2.0        scales_1.3.0       broom_1.0.5       \n[13] tidymodels_1.1.1   lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0     \n[17] dplyr_1.1.2        purrr_1.0.2        readr_2.1.4        tidyr_1.3.0       \n[21] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] foreach_1.5.2       jsonlite_1.8.8      splines_4.2.3      \n [4] prodlim_2023.08.28  GPfit_1.0-8         yaml_2.3.8         \n [7] globals_0.16.2      ipred_0.9-14        pillar_1.9.0       \n[10] backports_1.4.1     lattice_0.20-45     glue_1.6.2         \n[13] digest_0.6.31       hardhat_1.3.0       colorspace_2.1-0   \n[16] htmltools_0.5.5     Matrix_1.6-0        timeDate_4022.108  \n[19] pkgconfig_2.0.3     lhs_1.1.6           DiceDesign_1.9     \n[22] listenv_0.9.0       gower_1.0.1         lava_1.7.2.1       \n[25] tzdb_0.4.0          timechange_0.2.0    generics_0.1.3     \n[28] farver_2.1.1        furrr_0.3.1         withr_3.0.0        \n[31] nnet_7.3-18         cli_3.6.1           crayon_1.5.2       \n[34] survival_3.5-3      magrittr_2.0.3      evaluate_0.20      \n[37] fansi_1.0.4         future_1.33.0       parallelly_1.36.0  \n[40] MASS_7.3-58.2       class_7.3-21        tools_4.2.3        \n[43] data.table_1.14.8   hms_1.1.3           lifecycle_1.0.4    \n[46] munsell_0.5.1       compiler_4.2.3      rlang_1.1.1        \n[49] grid_4.2.3          iterators_1.0.14    rstudioapi_0.15.0  \n[52] htmlwidgets_1.6.2   labeling_0.4.3      rmarkdown_2.21     \n[55] gtable_0.3.5        codetools_0.2-19    R6_2.5.1           \n[58] knitr_1.43          fastmap_1.1.1       future.apply_1.11.0\n[61] utf8_1.2.3          stringi_1.7.12      parallel_4.2.3     \n[64] Rcpp_1.0.10         vctrs_0.6.3         rpart_4.1.19       \n[67] tidyselect_1.2.0    xfun_0.39",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Important R concepts</span>"
    ]
  },
  {
    "objectID": "02_linear_models.html",
    "href": "02_linear_models.html",
    "title": "2  Linear Models",
    "section": "",
    "text": "2.1 Overview\nIn this exercise session, we will review linear regression and polynomial regression. We will also learn how to efficiently split our data into training and test data, how to perform cross-validation, and why that is important. Before we dive into the details, we will discuss developing statistical models in R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "02_linear_models.html#good-practices-for-applied-machine-learning",
    "href": "02_linear_models.html#good-practices-for-applied-machine-learning",
    "title": "2  Linear Models",
    "section": "2.2 Good practices for applied Machine Learning",
    "text": "2.2 Good practices for applied Machine Learning\nIn previous courses, we mainly focused on fitting a certain model to a given dataset. However, this process could be described as model specification rather than model development. So, what is the difference between specifying and building a model?\n\n2.2.1 Developing a model (What we have done so far!):\n\nThe given dataset has been cleaned, transformed, and manipulated using various packages and libraries.\nResampling methods (like the ones we consider today) have been applied, but training the model on each subset or newly generated dataset is usually performed using a for-loop or similar methods. Loops should mostly be avoided in programming languages like R since they can be slow compared to optimized methods specifically written for higher performance.\nSimilar to applying resampling methods, hyperparameter tuning is usually performed in the same fashion.\n\nIn summary, we have only specified the model we want to train and used a somewhat arbitrary and inconsistent approach for everything else.\nOne of the most significant issues we face, however, is when switching the model. The approach we have been using so far emphasizes working with one selected model that we wish to keep using after data preprocessing.\n\n\n2.2.2 Developing a model (What we want to do moving forward!):\nThe main difference between the old and new approaches is leveraging the advantages of the {tidyverse} and {tidymodels} frameworks. These frameworks allow for consistently preprocessing the data, setting model specifications, and performing steps like resampling and hyperparameter tuning simultaneously.\nAnother huge advantage is that we can swiftly switch between different ML models by following this procedure. For example, applying a random forest algorithm and switching to a neural network approach for the same data is only a matter of changing a few lines of code, as we will see in later exercises.\nSo, where is the catch? At first, the process might seem complicated or even “overkill” for the models we use. However, as the lecture progresses, our models will also (at least sometimes) become increasingly sophisticated. We want to get used to this new process as early as possible, as it will be useful once we consider more sophisticated models.\nThe biggest takeaways are:\n\nConsistency: Independent of what the dataset or desired model looks like, we can (almost) always use the same procedure when building a model.\nEffectiveness: Once we get used to this new approach, we can develop our models more effectively.\nSafety: Developing an ML model has many pitfalls and potholes on the way, and by design, {tidymodels} helps us to avoid those.\n\nWe will introduce and explore some of the concepts above in this session’s exercises and dive deeper in later sessions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "02_linear_models.html#introduction-to-model-development-with-tidymodels",
    "href": "02_linear_models.html#introduction-to-model-development-with-tidymodels",
    "title": "2  Linear Models",
    "section": "2.3 Introduction to model development with {tidymodels}",
    "text": "2.3 Introduction to model development with {tidymodels}\nThis section briefly introduces the most important concepts when working with the {tidymodels} framework.\nThe data set for this introduction is called “Wine Quality White,” and it contains roughly 5,000 different white wines tested for their physicochemical properties, such as citric acid, pH value, and density. After assessing these properties, experts rated the wine quality and assigned a score between \\(0\\) and \\(10\\), where \\(0\\) is the lowest, and \\(10\\) is the highest score a wine can achieve.\nThe data set can be downloaded directly from the UC Irvine Machine Learning Repository or by clicking the button below.\n\nDownload Wine Data\n\n\n2.3.1 Data Exploration\nSince the data set is relatively nice in that we do not have to do much cleaning, we will keep this section relatively short.\n\nlibrary(\"tidyverse\")\nlibrary(\"tidymodels\")\nlibrary(\"ggtext\")\n\n\ndata_wine &lt;- read.csv(\"data/winequality-white.csv\")\ndata_wine %&gt;% glimpse()\n\nRows: 4,898\nColumns: 12\n$ fixed.acidity        &lt;dbl&gt; 7.0, 6.3, 8.1, 7.2, 7.2, 8.1, 6.2, 7.0, 6.3, 8.1,…\n$ volatile.acidity     &lt;dbl&gt; 0.27, 0.30, 0.28, 0.23, 0.23, 0.28, 0.32, 0.27, 0…\n$ citric.acid          &lt;dbl&gt; 0.36, 0.34, 0.40, 0.32, 0.32, 0.40, 0.16, 0.36, 0…\n$ residual.sugar       &lt;dbl&gt; 20.70, 1.60, 6.90, 8.50, 8.50, 6.90, 7.00, 20.70,…\n$ chlorides            &lt;dbl&gt; 0.045, 0.049, 0.050, 0.058, 0.058, 0.050, 0.045, …\n$ free.sulfur.dioxide  &lt;dbl&gt; 45, 14, 30, 47, 47, 30, 30, 45, 14, 28, 11, 17, 1…\n$ total.sulfur.dioxide &lt;dbl&gt; 170, 132, 97, 186, 186, 97, 136, 170, 132, 129, 6…\n$ density              &lt;dbl&gt; 1.0010, 0.9940, 0.9951, 0.9956, 0.9956, 0.9951, 0…\n$ pH                   &lt;dbl&gt; 3.00, 3.30, 3.26, 3.19, 3.19, 3.26, 3.18, 3.00, 3…\n$ sulphates            &lt;dbl&gt; 0.45, 0.49, 0.44, 0.40, 0.40, 0.44, 0.47, 0.45, 0…\n$ alcohol              &lt;dbl&gt; 8.8, 9.5, 10.1, 9.9, 9.9, 10.1, 9.6, 8.8, 9.5, 11…\n$ quality              &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 7, 6…\n\n\nExcept for the quality variable, every other variable is of type double.\n\n\n2.3.2 Training a simple linear model\nFor this example we build a linear model to predict the alcohol content of the wines. Recall the model equation \\[\\begin{equation}\n  y = \\beta_0 + \\beta_1 x_1 + ... + \\beta_n x_n + \\varepsilon,\n\\end{equation}\\]\nwhere \\(x_1,...,x_n\\in\\mathbb{R}^k\\) denotes \\(n\\) different features with \\(k\\) samples, \\(\\varepsilon \\sim \\mathcal{N}(0,1)\\) a \\(k\\)-dimensional error term and \\(\\beta_0,...,\\beta_n\\) the \\(n+1\\) model parameters. In our example, \\(y\\) denotes the variable alcohol, \\(k= 4898\\), and \\(n = 11\\).\nThe {parsnip} packages which is part of {tidymodels} contains the function linear_reg which creates a linear model when called.\n\nlm_mod &lt;- linear_reg()\nlm_mod\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nOnly calling the function name does not help much when trying to model the alcohol contents of the wine, since we haven’t specified the input variables, output variable, and data used for the regression.\nTo add these, we can use the %&gt;% pipe operator and fit function. As discussed in the previous exercise, the pipe operator passes the output of one operation in the other. Therefore, passing the lm_mod object into the fit function, specifies that the fit function fits a linear model. Fitting in that context refers to estimating the parameters \\(\\beta_0,...,\\beta_n\\). Besides the model specification, arguments for the fit function contain the formula which specifies the independent and dependent variables and the data argument which specifies the data that is used for training the model.\nThe formula in the code cell below specifies that we want to regress alcohol on every other variable indicated by the . after ~. ~ (tilde) is used to separate the left- and right-hand sides in the model formula.\nAs data we simply pass the whole data_wine data set.\n\nlm_mod &lt;- linear_reg() %&gt;% fit(\n formula = alcohol ~.,\n data = data_wine\n)\nlm_mod\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = alcohol ~ ., data = data)\n\nCoefficients:\n         (Intercept)         fixed.acidity      volatile.acidity  \n           6.719e+02             5.099e-01             9.636e-01  \n         citric.acid        residual.sugar             chlorides  \n           3.658e-01             2.341e-01            -1.832e-01  \n free.sulfur.dioxide  total.sulfur.dioxide               density  \n          -3.665e-03             6.579e-04            -6.793e+02  \n                  pH             sulphates               quality  \n           2.383e+00             9.669e-01             6.663e-02  \n\n\nThe return value is a parsnip model object that prints the model coefficients \\(\\beta_0,...,\\beta_n\\) when called.\nInstead of fitting the linear model on all parameters using ., we can also specify the relationship between the independent variables using arithmetic notation:\n\nlm_mod &lt;- linear_reg() %&gt;% fit(\n formula = alcohol ~ fixed.acidity+volatile.acidity+citric.acid+\n   residual.sugar+chlorides+free.sulfur.dioxide+\n   total.sulfur.dioxide+density+pH+\n   sulphates+quality,\n data = data_wine\n)\n\nNote, that this notation does not fall under best practices of model development as it is more advisable to create a separate data set for training and fit the model on every variable contained using the . notation.\n\n\n2.3.3 Evaluating a model\n\n2.3.3.1 Creating a summary of the model parameters\nUsing the tidy function on the fitted model returns an overview of the model parameters including \\(p\\)-values and the \\(t\\)-statistic.\n\nlm_mod %&gt;% tidy()\n\n# A tibble: 12 × 5\n   term                    estimate std.error statistic  p.value\n   &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)           672.        5.56       121.    0       \n 2 fixed.acidity           0.510     0.00986     51.7   0       \n 3 volatile.acidity        0.964     0.0672      14.3   1.00e-45\n 4 citric.acid             0.366     0.0560       6.54  6.88e-11\n 5 residual.sugar          0.234     0.00296     79.1   0       \n 6 chlorides              -0.183     0.321       -0.571 5.68e- 1\n 7 free.sulfur.dioxide    -0.00366   0.000494    -7.42  1.33e-13\n 8 total.sulfur.dioxide    0.000658  0.000222     2.97  3.01e- 3\n 9 density              -679.        5.70      -119.    0       \n10 pH                      2.38      0.0519      45.9   0       \n11 sulphates               0.967     0.0575      16.8   1.02e-61\n12 quality                 0.0666    0.00834      7.99  1.70e-15\n\n\nRecall that the statistic column refers to the \\(t\\)-statistic which corresponds to the following hypotheses for any \\(\\hat{\\beta}_i,\\, i=1,...,12\\): \\[\\begin{equation*}\nH_0:\\, \\hat{\\beta}_i= 0\\qquad \\mathrm{vs.}\\qquad H_1:\\, \\hat{\\beta}_i \\neq 0.\n\\end{equation*}\\] If the \\(p\\)–value regarding this test is low, we can confidently reject the null hypothesis.\nSimilar to the tidy function, the summary function can be called on the fit attribute of the model, which also returns a summary which contains a few more details, such as the \\(F\\)-statistic, \\(R^2\\), and residual standard error.\n\nlm_mod$fit %&gt;% summary()\n\n\nCall:\nstats::lm(formula = alcohol ~ fixed.acidity + volatile.acidity + \n    citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + \n    total.sulfur.dioxide + density + pH + sulphates + quality, \n    data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3343 -0.2553 -0.0255  0.2214 15.7789 \n\nCoefficients:\n                       Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)           6.719e+02  5.563e+00  120.790  &lt; 2e-16 ***\nfixed.acidity         5.099e-01  9.855e-03   51.745  &lt; 2e-16 ***\nvolatile.acidity      9.636e-01  6.718e-02   14.342  &lt; 2e-16 ***\ncitric.acid           3.658e-01  5.596e-02    6.538 6.88e-11 ***\nresidual.sugar        2.341e-01  2.960e-03   79.112  &lt; 2e-16 ***\nchlorides            -1.832e-01  3.207e-01   -0.571  0.56785    \nfree.sulfur.dioxide  -3.665e-03  4.936e-04   -7.425 1.33e-13 ***\ntotal.sulfur.dioxide  6.579e-04  2.217e-04    2.968  0.00301 ** \ndensity              -6.793e+02  5.696e+00 -119.259  &lt; 2e-16 ***\npH                    2.383e+00  5.191e-02   45.916  &lt; 2e-16 ***\nsulphates             9.669e-01  5.751e-02   16.814  &lt; 2e-16 ***\nquality               6.663e-02  8.341e-03    7.988 1.70e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4409 on 4886 degrees of freedom\nMultiple R-squared:  0.8719,    Adjusted R-squared:  0.8716 \nF-statistic:  3024 on 11 and 4886 DF,  p-value: &lt; 2.2e-16\n\n\nTo extract these statistics in tidy fashion, the {yardsticks} library (see Exercise Session 01) can help.\n\n\n2.3.3.2 Using metric sets and glance\nInstead of using the summary function on the fit attribute to extract certain metrics, we can also use the metric_set function. First, define a metric set by passing different metrics such as rsq, rmse, and mae into the metric_set function. Then, pass the predictions of the model into this newly defined metric set which returns the specified metrics.\n\nmulti_metric &lt;- metric_set(rsq,rmse,mae)\n\nlm_mod %&gt;%\n  augment(data_wine) %&gt;%\n  multi_metric(.pred,alcohol)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.872\n2 rmse    standard       0.440\n3 mae     standard       0.294\n\n\nA general metric set can be created using the glance function which returns a comprehensive list of metrics for the underlying model.\n\nglance(lm_mod)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.872         0.872 0.441     3024.       0    11 -2933. 5892. 5976.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\n2.3.4 Training and test split\nSplitting the data into three different subsets, called training, validation, and testing data, is a crucial aspect in Machine Learning.\n\n\n\n\n\n\nFigure 2.1\n\n\n\nThe basic idea is to train the model on the training data, validate the results on the validation data, and finally test the performance on the testing data that has previously not been observed.\nWithout this separation the model might become prone to overfitting meaning that the model does not perform well on previously unseen data.\nThe general procedure for training and testing a model is depicted in the following figure.\n\n\n\n\n\n\nFigure 2.2: Based on this Google Developers Figure\n\n\n\nHere, the training and validation data set are used in the training procedure and the testing data set in the testing procedure.\n\n\n\n\n\n\nNote\n\n\n\nThe reevaluation during training only makes sense when changing parameters can lead to an improvement. For a simple linear regression this is not the case, since once the model parameters \\(\\beta_0,...,\\beta_n\\) are estimated, they are optimal (cf. Gauss-Markov theorem).\n\n\nA simple training and test split with \\(80\\%\\) training data and \\(20\\%\\) test data can be generated with the initial_split, training, and testing function. Before splitting the data (which is done randomly) we can set a seed. Setting a seed allows us to reproduce the outcome of our code, even when randomness is involved.\n\nset.seed(123)\ntt_split&lt;-initial_split(data_wine, 0.8)\ndata_train &lt;- tt_split %&gt;% training() \ndata_test &lt;- tt_split %&gt;% testing()\n\nTraining the linear model on the training data and evaluating it on the test data then yields\n\nlm_mod &lt;- linear_reg() %&gt;%\n  fit(\n   formula = alcohol ~.,\n   data = data_train\n  )\n\nlm_mod %&gt;%\n  augment(data_test) %&gt;%\n  multi_metric(.pred,alcohol)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.887\n2 rmse    standard       0.408\n3 mae     standard       0.307\n\n\n\n\n2.3.5 Cross validation\nA popular approach we will use in most exercises extends the procedure described in Figure Figure 2.1 and Figure Figure 2.2. Instead of using a single training and validation data set, we create multiple instances of training and validation data by randomly assigning a data point to the training or validation set. More formally, \\(v\\)-fold cross validation randomly splits the training and validation data into \\(v\\) equally sized subsets. In each iteration, one of these subsets is set aside to be the validation data, while the other \\(v-1\\) subsets are used for training. The figure below depicts how that process works for v = 5.\n\n\n\n5-fold Cross Validation\n\n\nA part of the whole data set is left as testing data. The blue boxes in the lower part of the figure contain the validation (sub)sets for each split while the training data is contained in the remaining (sub)sets.\n\n2.3.5.1 Creating a cross validation set in R\nCross validation in R can be performed using the {resample} library that is also part of the {tidymodels} framework.\nThe vfold_cv function creates a nested data frame, meaning that each entry in the data frame contains another data frame. v denotes the number of created folds and data_train specifies that the folds are created from the data_train data set.\n\nset.seed(123)\nfolds &lt;- vfold_cv(data_train, v = 5)\n\nNote, that since the folds are also created stochastically, setting a seed ensures that the results are reproducible. We can access split \\(i\\) in a fold using the $split attribute and double brackets with the respective index. Note, that each split consists of a training and validation set that can each be accessed using the analysis and assessment function respectively.\n\nfolds$splits[[1]] %&gt;% \n  analysis() %&gt;%\n  glimpse()\n\nRows: 3,134\nColumns: 12\n$ fixed.acidity        &lt;dbl&gt; 8.3, 7.7, 5.7, 7.2, 9.3, 6.6, 6.6, 9.0, 6.5, 7.2,…\n$ volatile.acidity     &lt;dbl&gt; 0.25, 0.28, 0.26, 0.24, 0.34, 0.15, 0.17, 0.22, 0…\n$ citric.acid          &lt;dbl&gt; 0.33, 0.58, 0.24, 0.29, 0.49, 0.32, 0.26, 0.49, 0…\n$ residual.sugar       &lt;dbl&gt; 2.5, 12.1, 17.8, 2.2, 7.3, 6.0, 7.4, 10.4, 1.4, 5…\n$ chlorides            &lt;dbl&gt; 0.053, 0.046, 0.059, 0.037, 0.052, 0.033, 0.052, …\n$ free.sulfur.dioxide  &lt;dbl&gt; 12, 60, 23, 37, 30, 59, 45, 52, 14, 14, 44, 37, 2…\n$ total.sulfur.dioxide &lt;dbl&gt; 72, 177, 124, 102, 146, 128, 128, 195, 99, 125, 1…\n$ density              &lt;dbl&gt; 0.99404, 0.99830, 0.99773, 0.99200, 0.99800, 0.99…\n$ pH                   &lt;dbl&gt; 2.89, 3.08, 3.30, 3.27, 3.17, 3.19, 3.16, 3.31, 3…\n$ sulphates            &lt;dbl&gt; 0.48, 0.46, 0.50, 0.64, 0.61, 0.71, 0.37, 0.44, 0…\n$ alcohol              &lt;dbl&gt; 9.5, 8.9, 10.1, 11.0, 10.2, 12.1, 10.0, 10.2, 10.…\n$ quality              &lt;int&gt; 5, 5, 5, 7, 5, 8, 6, 6, 6, 5, 5, 5, 5, 6, 7, 6, 7…\n\nfolds$splits[[1]] %&gt;%\n  assessment() %&gt;%\n  glimpse()\n\nRows: 784\nColumns: 12\n$ fixed.acidity        &lt;dbl&gt; 6.2, 5.9, 6.7, 6.0, 8.6, 6.9, 8.0, 7.2, 6.7, 5.9,…\n$ volatile.acidity     &lt;dbl&gt; 0.28, 0.32, 0.18, 0.29, 0.33, 0.21, 0.14, 0.19, 0…\n$ citric.acid          &lt;dbl&gt; 0.45, 0.39, 0.28, 0.25, 0.34, 0.24, 0.49, 0.31, 0…\n$ residual.sugar       &lt;dbl&gt; 7.50, 3.30, 10.20, 1.40, 11.80, 1.80, 1.50, 6.30,…\n$ chlorides            &lt;dbl&gt; 0.045, 0.114, 0.039, 0.033, 0.059, 0.021, 0.035, …\n$ free.sulfur.dioxide  &lt;dbl&gt; 46, 24, 29, 30, 42, 17, 42, 17, 32, 26, 50, 11, 1…\n$ total.sulfur.dioxide &lt;dbl&gt; 203, 140, 115, 114, 240, 80, 120, 103, 111, 114, …\n$ density              &lt;dbl&gt; 0.99573, 0.99340, 0.99469, 0.98794, 0.99882, 0.98…\n$ pH                   &lt;dbl&gt; 3.26, 3.09, 3.11, 3.08, 3.17, 3.15, 3.26, 3.15, 3…\n$ sulphates            &lt;dbl&gt; 0.46, 0.45, 0.45, 0.43, 0.52, 0.46, 0.40, 0.52, 0…\n$ alcohol              &lt;dbl&gt; 9.2, 9.2, 10.9, 13.2, 10.0, 12.3, 10.6, 11.4, 11.…\n$ quality              &lt;int&gt; 6, 6, 7, 6, 6, 7, 7, 7, 7, 6, 6, 4, 5, 5, 7, 8, 6…\n\n\n\n\n2.3.5.2 Training a model using cross validation\nTo train the linear model on each split, we can use the fit_resamples function. Training the model on each fold is the as simple as training he model without resamples: We simply pass the model specification, formula, and additionally the cross validation object into the fit_resamples formula. Additionally, we can also pass the metric set multi_metric to specify which metrics we want to use for model evaluation.\n\nlm_mod_resampling &lt;- linear_reg()\nlm_mod_resampling_res &lt;- fit_resamples(lm_mod_resampling,\n                            alcohol ~.,\n                            folds,\n                            metrics = multi_metric)\n\nThe return value of the fit_resamples function is a data frame containing \\(5\\) linear models (since we specified v=5 when creating the folds object).\n\nlm_mod_resampling_res\n\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits             id    .metrics         .notes          \n  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [3134/784]&gt; Fold1 &lt;tibble [3 × 4]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [3134/784]&gt; Fold2 &lt;tibble [3 × 4]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [3134/784]&gt; Fold3 &lt;tibble [3 × 4]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [3135/783]&gt; Fold4 &lt;tibble [3 × 4]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [3135/783]&gt; Fold5 &lt;tibble [3 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nWe are mainly interested in the cross validation error (CV-RMSE) defined as\n\\[\\begin{equation*}\n  \\mathrm{CV-RMSE} = \\frac{1}{v}\\sum_{i=1}^v \\mathrm{RMSE}_i,\n\\end{equation*}\\]\nwhere \\(\\mathrm{RMSE}_i\\) stands for the RMSE of the \\(i\\)-th. hold-out sample.\nWe can collect this metric by applying the collect_metrics function:\n\nlm_mod_resampling_res %&gt;% collect_metrics()\n\n# A tibble: 3 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   0.300     5 0.00460 Preprocessor1_Model1\n2 rmse    standard   0.451     5 0.0710  Preprocessor1_Model1\n3 rsq     standard   0.866     5 0.0414  Preprocessor1_Model1\n\n\nThe third column mean depicts the mean rmse and rsq across all the splits. Comparing the CV-RMSE (\\(0.451\\)) to the true out of sample (OOS) RMSE of the test set (\\(0.408\\)) reveals that the performance of the linear model seems stable, meaning that it is not prone to overfitting. Furthermore, the CV-RMSE seems to overestimate the true OOS RMSE, since \\(0.451&gt;0.408\\). Using this information we can make prediction about the alcohol contents of a wine with the estimated model parameters on the training data set.\n\n\n\n2.3.6 Polynomial regression and the bias variance trade off\nPolynomial regression is a special case of multiple linear regression where the model is still linear in its coefficients but the dependent variable \\(y\\) is modeled as polynomial in \\(x\\). For an \\(n\\)-th degree polynomial model the model equation is therefore given by\n\\[\\begin{equation*}\n  y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ... + \\beta_n x^n.\n\\end{equation*}\\]\n\n\n\n\n\n\nNote\n\n\n\nFor this specific model we only use one independent variable \\(x\\) instead of \\(n\\) different independent variables \\(x_1\\),…,\\(x_n\\).\n\n\nSay, we want to model the alcohol contents of wine with a MLR model using the wine density as the only predictor.\nConsider the following synthetic dataset consisting of \\(12\\) observations.\n\nset.seed(123)\ndata_synth &lt;- tibble(\n  x = seq(0,1,1/11),\n  y = x+rnorm(12,0,0.1)\n)\n\nsplit_synth &lt;- initial_split(data_synth,0.8)\ndata_train_synth &lt;- split_synth %&gt;% training()\ndata_test_synth &lt;- split_synth %&gt;% testing()\n\ndata_synth\n\n# A tibble: 12 × 2\n        x       y\n    &lt;dbl&gt;   &lt;dbl&gt;\n 1 0      -0.0560\n 2 0.0909  0.0679\n 3 0.182   0.338 \n 4 0.273   0.280 \n 5 0.364   0.377 \n 6 0.455   0.626 \n 7 0.545   0.592 \n 8 0.636   0.510 \n 9 0.727   0.659 \n10 0.818   0.774 \n11 0.909   1.03  \n12 1       1.04  \n\n\nFrom the figure below, it is immediately evident, that a polynomial model perfectly fits the training data, but severely fails to estimate the rightmost point of the testing data. While the linear model does not fit the training data\n\n\n\n\n\n\n\n\n\nTo verify this, we can also compare the training and test error for different metrics of each model.\n\nlm_poly_mod &lt;- linear_reg() %&gt;% \n  fit(formula = y ~ poly(x, 8),\n      data = data_train_synth\n      )\n\nlm_lin_mod &lt;- linear_reg() %&gt;% \n  fit(formula = y ~ x,\n      data = data_train_synth\n      )\n\nVisualizing the difference in train and test error then yields\n\n\n\n\n\n\n\n\n\nThe example above demonstrates the phenomenon of bias-variance tradeoff. A low variance and high bias can be observed in the linear model, since there are only few (two) model parameters and a small discrepancy between training and test error. The polynomial model exhibits a large discrepancy between training and test error and since there are many (nine) parameters, indicating that it has a high variance but low bias.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "02_linear_models.html#exercises",
    "href": "02_linear_models.html#exercises",
    "title": "2  Linear Models",
    "section": "2.4 Exercises",
    "text": "2.4 Exercises\nThroughout the exercises, we will work with a subset of the Apartment rental offers in Germany data set that can be downloaded using the button below. It contains 239 unique rental listings for flats in Augsburg which were sourced at three different dates in 2018 and 2019 and contains 28 different variables.\n\nDownload AugsburgRental\n\n\nExercise 2.1 Instead of focusing on a comprehensive data cleaning and manipulation process, we will simply use the two variables livingSpace measuring the area of living in \\(m^2\\) of a listing and baseRent in EUR, representing the monthly base rent.\nImport the data and visualize the relationship between the two variables livingSpace and baseRent with a scatter plot. Rename the axis of the plot such that they display the words base rent and living space (seperated by a whitespace).\n\n\nExercise 2.2 Without conducting a thorough outlier analysis, remove every listing that either costs more than \\(2500\\) EUR or is bigger than \\(200\\: m^2\\).\n\n\nExercise 2.3 Create a training (\\(80\\%\\)) and test data set using the filtered data. Use set.seed(2) to generate reproducible results.\n\n\nExercise 2.4 Train a simple linear model on the training data.\n\n\nExercise 2.5 Generate a model summary and interpret the coefficients. Is the independent variable statistically significant?\n\n\nExercise 2.6 Evaluate the model on the test data by considering the adjusted \\(R^2\\) and MAE. On average, how far off is the estimated base rent?\n\n\nExercise 2.7 Create a \\(10\\)-fold cross validation split of the training data using the same seed as before and retrain the simple linear model. Compare the cross validation MAE to the OOS MAE and interpret the result.\n\n\nExercise 2.8 Repeat Exercises Exercise 2.6 and Exercise 2.8 for a polynomial model of degree 20. Compare the test and cross-validation MAE of the linear model with the polynomial model.\n\n\nExercise 2.9 Create a scatter plot of the training data and insert both fitted curves using the geom_smooth function.\n\n\nExercise 2.10 Assume we have fitted a simple linear model \\[\\begin{equation*}\n  \\hat{y} = \\hat{\\beta_0}+\\hat{\\beta_1}x.\n\\end{equation*}\\]\nFor \\(\\hat\\beta_1\\) the \\(t\\)-statistic has a \\(p\\)-value of \\(1e-16\\) (\\(=1\\cdot 10^{-16}\\)). Describe the null hypothesis of the underlying test and explain what concnulision can be drawn based on this \\(p\\)-value.\n\n\nExercise 2.11 Assume we have a data set with \\(k = 400\\) containing a single independent variable \\(x\\) and a real valued dependent variable \\(y\\). We fit a simple regression model and a polynomial regression with degree \\(5\\) on \\(75\\%\\) of the data and leave the remaining \\(25\\%\\) for testing .\n\nAssume that the true relationship between \\(x\\) and \\(y\\) is linear. Consider the training RMSE for the linear regression, and also the training RMSE for the polynomial regression. Choose the most appropriate answer and justify your choice.\n1.1 The polynomial model has more flexibility due to the additional terms, so it will fit the data better than the linear model, resulting in a lower training RMSE.\n1.2 The linear model is simpler and less prone to overfitting, so it will produce a lower training RMSE compared to the polynomial model.\n1.3 Since both models are trying to explain the same data, their training RMSE should be approximately the same.\n1.4 Without knowing the true underlying relationship between the predictor and response, we cannot definitively predict the behavior of the training RMSE for either model.\nRepeat the previous exercise but instead of the training RMSE, consider the test RMSE.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "02_linear_models.html#solutions",
    "href": "02_linear_models.html#solutions",
    "title": "2  Linear Models",
    "section": "2.5 Solutions",
    "text": "2.5 Solutions\n\nSolution 2.1 (Exercise 2.1). The data set can be imported using the read_csv function.\n\ndata_aux &lt;- read_csv(\"data/rent_aux.csv\")\n\nUsing the ggplot function, we can create a simple scatter plot. The labs function allows to define new axis labels by specifying the axis and assigning the names to the respective axis. \\(x\\) corresponds to the horizontal axis and \\(y\\) to the vertical axis.\n\ndata_aux %&gt;% \n  ggplot(aes(x = livingSpace, y = baseRent)) +\n  geom_point() +\n  labs(\n    x = \"living space\",\n    y = \"base rent\"\n  )\n\n\n\n\n\n\n\n\n\n\nSolution 2.2 (Exercise 2.2). To select all listings with base rent lower than \\(2500\\) EUR and living space less than \\(200\\) sqm, we can use the filter function and overwrite the old data set.\n\ndata_aux &lt;- data_aux %&gt;%\n  filter(baseRent &lt;= 2500, livingSpace &lt;= 200)\n\n\n\nSolution 2.3 (Exercise 2.3). By setting set.seed(2) we can make sure that the following results are reproducible. Similar to Section 2.3.4, we can define a split object using the initial_split function and select the training and test portion using the training and testing functions respectively.\n\nset.seed(2)\nsplit &lt;-initial_split(data_aux,0.8)\ndata_train &lt;- split %&gt;% training(split)\ndata_test &lt;- split %&gt;% testing(split)\n\n\n\nSolution 2.4 (Exercise 2.4). \n\nlm_mod &lt;- linear_reg() %&gt;%\n  fit(baseRent ~ livingSpace, data_train)\n\n\n\nSolution 2.5 (Exercise 2.5). A simple model summary can be created by passing the trained model into the tidy function.\n\nlm_mod %&gt;% tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     87.3    25.2        3.46 6.58e- 4\n2 livingSpace     10.4     0.322     32.2  5.49e-79\n\n\nThe estimated parameter \\(\\hat{\\beta_1} = 10.4\\) indicates that according to the linear model, we expect the base rent to rise \\(10.4\\) EUR for every additional square meter of living space.\n\n\nSolution 2.6 (Exercise 2.6). We can calculate the adjusted \\(R^2\\) and \\(MAE\\) using the metric_set function.\n\nmulti_metric&lt;- metric_set(rsq,mae)\nlm_mod %&gt;%\n  augment(data_test) %&gt;%\n  multi_metric(.pred,baseRent)\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.883\n2 mae     standard     108.   \n\n\nMAE\\(=108\\) indicates that on average our estimated base rent is off by \\(108\\) EUR.\n\n\nSolution 2.8 (Exercise 2.8). \n\nset.seed(2)\nfolds &lt;- vfold_cv(data_train)\n\nlm_mod_resampling_res &lt;- linear_reg() %&gt;% \n  fit_resamples(baseRent ~ livingSpace,\n                folds,\n                metrics = multi_metric)\n\nlm_mod_resampling_res %&gt;% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   116.       10  5.12   Preprocessor1_Model1\n2 rsq     standard     0.869    10  0.0153 Preprocessor1_Model1\n\n\nThe cross-validation MAE of \\(116\\) EUR compared to the test MAE of \\(108\\) EUR indicates that the cross-validation error is overestimating the true test error. This is in fact favorable, since it is preferable to have a pessimistic bias towards an estimated error. In other words, overestimating an error is always better than underestimating an error.\n\n\nSolution 2.8 (Exercise 2.8). \n\nlm_poly_mod &lt;- linear_reg() %&gt;% fit(\n  formula = baseRent ~ poly(livingSpace, 20), \n  data = data_train\n)\n\nlm_poly_mod %&gt;%\n  augment(data_test) %&gt;%\n  multi_metric(.pred,baseRent)\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.349\n2 mae     standard     153.   \n\nlm_poly_mod_resampling_res &lt;- linear_reg() %&gt;% \n  fit_resamples(baseRent ~ poly(livingSpace,20),\n                folds,\n                metrics = multi_metric)\n\nlm_poly_mod_resampling_res %&gt;% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   1541.       10 1205.     Preprocessor1_Model1\n2 rsq     standard      0.624    10    0.0937 Preprocessor1_Model1\n\n\nCompared to the simple linear model, the polynomial model performs a lot worse on the test data as it severely ovefits on the training data. The CV MAE of \\(1541\\) compared to the test MAE of \\(153\\) is another redflag we should consider when evaluating model performance.\n\n\nSolution 2.9 (Exercise 2.9). We can directly pipe the training data data_train into the ggplot function to create the plot. The color argument in the geom_point function changes the color of the points and the size argument toggles the point sizes in the figure. When using geom_smooth have to express the formula in terms of x and y instead of using livingSpace and baseRent. Setting se=FALSE removes the confidence band of the estimated lines. color = \"black\", linetype=2, and linewidth=1.5 specifies the visual characteristics of the line. As with the previous plot, we can also change the axis labels using labs.\n\ndata_train %&gt;% ggplot(aes(x=livingSpace,y=baseRent))+\n  geom_point(color=\"#f07167\",\n             size = 2)+\n  geom_smooth(formula = y ~ poly(x, 20),\n              method = \"lm\",\n              color = \"black\",\n              se = FALSE,\n              linetype= 2,\n              linewidth = 1.5)+\n  geom_smooth(formula = y ~ x,\n              method = \"lm\",\n              color = \"black\",\n              se = FALSE,\n              linetype= 5,\n              linewidth = 1.5)+\n  labs(x=\"Living space in sqm\",\n       y=\"base rent in EUR\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nSolution 2.10 (Exercise 2.10). A \\(p\\)-value of \\(1e-16\\) (\\(=1\\cdot 10^{-16}\\)) indicates that we can reject the null hypotheses \\(H_0: \\beta_1 = 0\\) to the significance level $1-(10^{-16}).\n\n\nSolution 2.11 (Exercise 2.11). \n\nSince the polynomial model has more flexibility due to the additional terms, it will likely fit the training data better than the linear model, resulting in a lower training RMSE.\nThe linear model is simpler and less prone to overfitting, so it will likely produce a lower test RMSE compared to the polynomial model.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  }
]