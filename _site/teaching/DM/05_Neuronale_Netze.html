<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Neuronale Netze – Data Mining Übungsmaterial</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04_Regressions_Baeume.html" rel="prev">
<script src="site_libs/cookie-consent/cookie-consent.js"></script>
<link href="site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-K9CJ1KN8ZH"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-K9CJ1KN8ZH', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"express",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<script>

  MathJax = {

    tex: {

      tags: 'ams'  // should be 'ams', 'none', or 'all'

    }

  };

</script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./05_Neuronale_Netze.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Neuronale Netze</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Mining Übungsmaterial</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vorwort</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Einfuehrung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">(Kurz)Einführung in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Lineare_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Lineare Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Wichtige_Konzepte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Weiterführende Konzepte des Dataminings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Regressions_Baeume.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regressionsbäume</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Neuronale_Netze.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Neuronale Netze</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#einführung" id="toc-einführung" class="nav-link active" data-scroll-target="#einführung"><span class="header-section-number">5.1</span> Einführung</a>
  <ul>
  <li><a href="#anwendung-von-neuronalen-netzen-in-der-regression" id="toc-anwendung-von-neuronalen-netzen-in-der-regression" class="nav-link" data-scroll-target="#anwendung-von-neuronalen-netzen-in-der-regression"><span class="header-section-number">5.1.1</span> Anwendung von Neuronalen Netzen in der Regression</a></li>
  <li><a href="#aufbau-eines-neuronalen-netzes" id="toc-aufbau-eines-neuronalen-netzes" class="nav-link" data-scroll-target="#aufbau-eines-neuronalen-netzes"><span class="header-section-number">5.1.2</span> Aufbau eines Neuronalen Netzes</a></li>
  </ul></li>
  <li><a href="#anpassen-der-modellparameter" id="toc-anpassen-der-modellparameter" class="nav-link" data-scroll-target="#anpassen-der-modellparameter"><span class="header-section-number">5.2</span> Anpassen der Modellparameter</a>
  <ul>
  <li><a href="#regularisierung-von-neuronalen-netzen" id="toc-regularisierung-von-neuronalen-netzen" class="nav-link" data-scroll-target="#regularisierung-von-neuronalen-netzen"><span class="header-section-number">5.2.1</span> Regularisierung von Neuronalen Netzen</a></li>
  </ul></li>
  <li><a href="#neuronale-netze-in-r" id="toc-neuronale-netze-in-r" class="nav-link" data-scroll-target="#neuronale-netze-in-r"><span class="header-section-number">5.3</span> Neuronale Netze in R</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Neuronale Netze</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="einführung" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="einführung"><span class="header-section-number">5.1</span> Einführung</h2>
<p>In dieser Übung werden wir einige theoretische und praktische Aspekte neuronaler Netze betrachten. Neuronale Netze sind inzwischen die am häufigsten verwendeten Modelle in der Forschung und Industrie des Data Minings, da sie vielseitig und leistungsfähig bei der Anwendung in Klassifizierungs- und Regressionsaufgaben sind. Das Training neuronaler Netze erfordert allerdings nicht nur eine große Datenmenge, um zufriedenstellende Ergebnisse zu erzielen, sondern kann je nach Anzahl der Merkmale und Stichproben auch viel Zeit in Anspruch nehmen.</p>
<p>Neuronale Netze werden häufig mit der Funktionsweise des menschlichen Gehirns verglichen, auch wenn dieser Zusammenhang selbst bei den einfachsten Konzepten an seine Grenzen stößt (vgl. <a href="https://www.quantamagazine.org/ai-is-nothing-like-a-brain-and-thats-ok-20250430/">Quanta Magazin: AI is nothing like a brain and that’s okay</a>). Auch wenn neuronale Netze bereits seit den 1940er Jahren existieren, wurde deren Anwendung wie zum Beispiel in Large Language Models (ChatGPT, LeChat,…) erst in den vergangen Jahren für die breite Gesellschaft zugänglich. Damit wir moderne Architekturen wie Transformer verstehen können, auf denen zum Beispiel auch Large Language Models basieren, dürfen wir die Grundlagen, gelegt durch einfache neuronale Netze, nicht vernachlässigen.</p>
<section id="anwendung-von-neuronalen-netzen-in-der-regression" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="anwendung-von-neuronalen-netzen-in-der-regression"><span class="header-section-number">5.1.1</span> Anwendung von Neuronalen Netzen in der Regression</h3>
<p>Neuronale Netze werden in ihrer einfach Form, wie wir sie in dieser Veranstaltung behandeln, vor allem für Regressions- und Klassifikationsaufgaben verwendet. Wir befinden uns also bei diesen Anwendungsfällen im Bereich des Supervised Learnings, da wir die Zielvariable kennen.</p>
<p>Bei einer Regressionsaufgabe ist wie immer das Ziel eine Funktion <span class="math inline">\(f:\mathbb{R}^J\to\mathbb{R}\)</span> zu finden, welche den bestmöglichen Zusammenhang <span class="math inline">\(y = f(x)+\varepsilon\)</span> erklärt. Im Falle eines Neuronalen Netzes beschreiben wir die Funktion <span class="math inline">\(f\)</span> allgemein druch Weights (Gewichten) und Biases (Konstanten) welche den Rückgabewert beeinflussen.</p>
<!-- 
Neuronale Netze gehören allgemein zur Klasse der nichtlinearen Regressionsfunktionen was durch eine nichtlineare Aktivierungsfunktion $\sigma$ gesteuert wird. 

-->
</section>
<section id="aufbau-eines-neuronalen-netzes" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="aufbau-eines-neuronalen-netzes"><span class="header-section-number">5.1.2</span> Aufbau eines Neuronalen Netzes</h3>
<p>Im folgenden Abschnitt werden wir die grundlegende Idee eines einfachen neuronalen Netzes sequentiell erweitern, bis wir bei sogenannten <em>Feed-Forward Deep Neural Networks</em> (FFDNN) angekommen sind.</p>
<p>Feed-Forward Neuronale Netze (FFNN) bestehen aus Neuronen welche in einer festen Reihenfolge angeordnet sind und Daten <em>vorwärts</em> verarbeiten.</p>
<p>So können wir ein FFNN bestehend aus einem einzelnen Neuron grafisch wie folgt darstellen:</p>
<div id="fig-NN01" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-NN01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="pictures\NN_Single.svg" id="fig-NN01" class="img-fluid quarto-figure quarto-figure-center anchored figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-NN01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1
</figcaption>
</figure>
</div>
<p>Hierbei steht</p>
<ul>
<li><span class="math inline">\(I_1\)</span> für den Input</li>
<li><span class="math inline">\(B_1\)</span> für den Bias (Konstante)</li>
<li><span class="math inline">\(O_1\)</span> für den Output</li>
<li><span class="math inline">\(\omega_{I_1,O_1},\: \omega_{B_1,O_1}\)</span> für den Wert des Gewichts und des Bias</li>
<li><span class="math inline">\(\sigma\)</span> für eine Aktivierungsfunktion.</li>
</ul>
<p>Die Pfeile in der obigen Grafik deuten die Richtung des Informationsflusses an. Der Input <span class="math inline">\(I_1\)</span> wird durch den Parameter <span class="math inline">\(\omega_{I_1,O_1}\)</span> Gewichtet. Neben dem Input wird ein konstanter Term (Bias) <span class="math inline">\(\omega_{B_1,O_1}\)</span> dem gewichteten Input hinzugefügt. Die beiden Terme werden durch die Summation aggregiert und anschließend durch eine (nicht-) lineare Aktivierungsfunktion transformiert. Diese Transformation der aggregierten Summation ist dann der Output des Modells.</p>
<p>Mathematisch lässt sich dieses einfache FFNN also durch</p>
<p><span class="math display">\[\begin{equation*}
f(x) = \sigma(\omega_{I_1,O_1}\cdot x + \omega_{B_1,O_1})
\end{equation*}\]</span></p>
<p>beschreiben.</p>
<p>Beispiele für Aktivierungsfunktionen sind:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 53%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Aktivierungsfunktion</th>
<th>Mathematische Definition</th>
<th>Bildbereich</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sigmoid</td>
<td><span class="math inline">\(\sigma(x) = \frac{1}{1 + e^{-x}}\)</span></td>
<td><span class="math inline">\((0, 1)\)</span></td>
</tr>
<tr class="even">
<td>Tanh</td>
<td><span class="math inline">\(\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}\)</span></td>
<td><span class="math inline">\((-1, 1)\)</span></td>
</tr>
<tr class="odd">
<td>ReLU</td>
<td><span class="math inline">\(\text{ReLU}(x) = \max(0, x)\)</span></td>
<td><span class="math inline">\([0, \infty)\)</span></td>
</tr>
<tr class="even">
<td>Leaky ReLU</td>
<td><span class="math inline">\(\text{LeakyReLU}(x) = \max(\alpha x, x)\)</span></td>
<td><span class="math inline">\((-\infty, \infty),\: (\alpha &gt; 0)\)</span></td>
</tr>
</tbody>
</table>
<div id="exm-NN01" class="theorem example">
<p><span class="theorem-title"><strong>Beispiel 5.1</strong></span> Wir können in R ein einfaches FFNN wie folgt darstellen. Die Notation ist hierbei konsistent mit der aus <a href="#fig-NN01" class="quarto-xref">Figure&nbsp;<span>5.1</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>ReLU <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">max</span>(x,<span class="dv">0</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>i1 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>w_i1o1 <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>w_b1o1 <span class="ot">&lt;-</span> <span class="fl">2.5</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>(o1 <span class="ot">&lt;-</span> <span class="fu">ReLU</span>(w_i1o1<span class="sc">*</span>i1<span class="sc">+</span>w_b1o1<span class="sc">*</span>b1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>w_i1o1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">1.5</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>w_b1o1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">2.5</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>(o1 <span class="ot">&lt;-</span> <span class="fu">ReLU</span>(w_i1o1<span class="sc">*</span>i1<span class="sc">+</span>w_b1o1<span class="sc">*</span>b1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
</div>
<p>Wir können die Idee aus <a href="#fig-NN01" class="quarto-xref">Figure&nbsp;<span>5.1</span></a> leicht erweitern, indem wir einzelne Neuronen aneinander ketten. So wird der Output <span class="math inline">\(O\)</span> des ersten Neurons als Input <span class="math inline">\(I\)</span> des nächsten Neurons verwendet. Diese Verkettungen können beliebig oft wiederholt werden, was dann einem tiefen Neuronalen Netz entspricht. Wir nennnen dann die Glieder dieser Verkettung einzelne Layer.</p>
<div id="fig-NNK1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-NNK1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="pictures/NN_Sparse.svg" id="fig-NNK1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-NNK1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.2
</figcaption>
</figure>
</div>
<p><a href="#fig-NNK1" class="quarto-xref">Figure&nbsp;<span>5.2</span></a> zeigt exemplarisch ein FFNN mit <span class="math inline">\(K\)</span> <em>hidden Layern</em>. <em>hidden Layer</em> sind jene Neuronen in der Verkettung welche zwischen der Input- und Outputschicht liegen.</p>
<div id="exm-NN03" class="theorem example">
<p><span class="theorem-title"><strong>Beispiel 5.2</strong></span> Modellierung eines FFNN mit einer Hidden Layer.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Input</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>i1 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Bias</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>b2 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>b3 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Weight und Bias fuer die erste Layer (Input)</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>w_i1h11 <span class="ot">&lt;-</span> <span class="fl">1.1</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>w_b1h11 <span class="ot">&lt;-</span> <span class="fl">2.1</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Weight und Bias fuer die zweite Layer (Hidden)</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>w_h11h21 <span class="ot">&lt;-</span> <span class="fl">1.2</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>w_b1h21 <span class="ot">&lt;-</span> <span class="fl">2.2</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Weight und Bias fuer die dritte Layer (Output)</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>w_h21o1 <span class="ot">&lt;-</span> <span class="fl">1.3</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>w_b2o1 <span class="ot">&lt;-</span> <span class="fl">2.3</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Berechnung des Ouputs der ersten Layer</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>h11 <span class="ot">&lt;-</span> <span class="fu">ReLU</span>(w_i1h11<span class="sc">*</span>i1<span class="sc">+</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>           w_b1h11<span class="sc">*</span>b1)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Berechnung des Ouputs der zweiten Layer</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>h21 <span class="ot">&lt;-</span> <span class="fu">ReLU</span>(w_h11h21<span class="sc">*</span>h11<span class="sc">+</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>           w_b1h21<span class="sc">*</span>b2)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Berechnung des Ouputs der finalen Layer</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>(o1 <span class="ot">&lt;-</span> <span class="fu">ReLU</span>(w_h21o1<span class="sc">*</span>h21<span class="sc">+</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>           w_b2o1<span class="sc">*</span>b3)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 11.868</code></pre>
</div>
</div>
</div>
<p>Die bisher betrachteten Architekturen bestanden lediglich aus einem Input und die Verkettungen der Neuronen waren ebenso eindimensional. Mehrdimensionale Inputs können ganz einfach durch das Hinzufügen von weiteren Inputneuronen modelliert werden, wobei jeder Input <span class="math inline">\(I_1,...,I_J\)</span> entsprechend ein eigenes Gewicht erhält und diese in der ersten Schicht aggregiert werden:</p>
<p><span class="math display">\[\begin{equation*}
H_{1,1} = \sigma\left(B_1\cdot \omega_{B_1,H_{1,1}}+\sum_{j=1}^{J}\omega_{I_j,H_{1,1}}\cdot I_j\right)
\end{equation*}\]</span></p>
<p>Allerdings gehen in den daurauffolgenden Schichten womöglich viele Informationen durch diese einfache Aggregation verlorgen. Wir können in den verschiedenen Schichten eines FFNN mehrere Neuronen auch übereinander darstellen und durch zusätzliche Gewichte mit den Neuronen aus der vorherigen Schicht verknüpfen. Den allgemeinen Fall können wir dann wie in der folgenden Grafik aufgezeigt darstellen. <em>Hinweis: In diesem Modell ist der Output <span class="math inline">\(N_{K+1}\)</span>-dimensional. Bei den Regressionsproblemen welche wir betrachten ist der Output allerdings immer eindimensional.</em></p>
<div id="fig-NNFull" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-NNFull-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="pictures/NN_Full.svg" id="fig-NNFull" class="img-fluid quarto-figure quarto-figure-center anchored figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-NNFull-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.3
</figcaption>
</figure>
</div>
<p>Das oben dargestellte FFNN besteht also aus <span class="math inline">\(J\)</span> Inputneuronen, <span class="math inline">\(K\)</span> Hidden Layern welche die Dimensionen <span class="math inline">\(N_1,...,N_K\)</span> besitzen und einer Output Layer der Dimension <span class="math inline">\(N_{K+1}\)</span>. Beginnend bei der Input Layer, jedes Neuron kommuniziert über ein Gewicht mit jedem Neuron der ersten Hiddenlayer. Durch die Vielzahl an Verbindungen zwischen den einzelnen Schichten können wir somit auch sehr komplizierte Zusammenhänge gut modellieren. Neben der Verwendung von mehreren Schichten und vielen Neuronen wirkt sich allerdings vor allem die Aktivierungsfunktion auf das Ergebnis aus. Falls eine lineare Aktivierungsfunktion zwischen den einzelnen Schichten vorliegt, dann zerfällt das FFNN in eine multiple lineare Regression.</p>
<p>Ein Version des Modells wie das in <a href="#fig-NNFull" class="quarto-xref">Figure&nbsp;<span>5.3</span></a> dargestellt könnnen wir in R wie folgt modellieren:</p>
<div id="exm-DNNFull" class="theorem example">
<p><span class="theorem-title"><strong>Beispiel 5.3</strong></span> Gegeben sei folgende Netzarchitektur:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/NN_Full_Example2.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Dann können wir diese in R durch folgende Funktion beschreiben:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>nn <span class="ot">&lt;-</span> <span class="cf">function</span>(x,w1,w2,w3){</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  h1 <span class="ot">&lt;-</span> <span class="fu">pmax</span>(w1<span class="sc">*</span>x<span class="sc">+</span>b1,<span class="dv">0</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  h2 <span class="ot">&lt;-</span> <span class="fu">pmax</span>(w2<span class="sc">%*%</span>h1<span class="sc">+</span>b2,<span class="dv">0</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  (o <span class="ot">&lt;-</span> <span class="fu">pmax</span>(w3<span class="sc">%*%</span>h2<span class="sc">+</span>b3,<span class="dv">0</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Der <code>%*%</code> Operator steht hierbei für Matrixmultiplikation.</p>
<ol type="1">
<li>In der ersten Schicht wird der eindimensionale Input mit einem Vektor <code>w1</code> multipliziert. Da die erste Hidden Layer aus drei Neuronen besteht ist dieser Gewichtsvektor deshalb ein Element in <span class="math inline">\(\mathbb{R}^3\)</span> auf dieses Produkt wird ein Bias Vektor der gleichen Dimesnion addiert. Anschließend wird die <code>pmax()</code> Funktion auf den resultierenden Vektor angewendet. Diese gibt einen Vektor der gleichen Dimension aus, wobei jedes Element das Maximum aus dem linken und rechten Argument enthält (dies entspricht der <code>ReLu</code> Aktivierungsfunktion). Der Rückgabewert der ersten Hidden Layer ist demnach ein Vektor der in <span class="math inline">\(\mathbb{R}^3\)</span>.</li>
<li>Damit im zweiten Schritt jedes Neuron der ersten Hidden Layer mit den Neuronen der zweiten Hidden Layer verbinden können, müssen wir die Dimension der Gewichte entsprechend anpassen. Somit verwenden wir für die Verknüpfung des ersten Neurons mit allen Neuronen der zweiten Hidden Layer einen Vektor in <span class="math inline">\(\mathbb{R}^4\)</span>. Ebenso verwenden wir für die Verbindungen der verbleibenden zwei Neuronen einen Vektor der selben Dimension. Diese drei Vektoren können wir dann in einer Matrix <code>w2</code><span class="math inline">\(\in\mathbb{R}^{4\times 3}\)</span> speichern. Die MAtrix <code>w2</code> wird dann also an die ersten Hidden Layer multipliziert und ähnlich wie im ersten Schritt mit einem Bias Vektor addiert, bevor das komponentnenweise Maximum zwischen dem resultierenden Vektor und <span class="math inline">\(0\)</span> zurückgegeben wird.</li>
<li>Im letzten Schritt wird das Vorgehen final wiederholt, jedoch ist der Output eindimensional weshalb die Gewichte nun wieder in einem Vektor aus <span class="math inline">\(\mathbb{R}^{1\times 4}\)</span> (Zeilenvektor statt Spaltenvektor) gespeichert werden können. Der Bias <span class="math inline">\(B_3\)</span> ist dann ebenso nur noch eindimensional.</li>
</ol>
<p>Konkret könnten die Gewichtsmatrizen zum Beispiel wie folgt aussehen:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">3</span>),</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">12</span>),</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>w3 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">4</span>),</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">ncol =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Beachte: Die Gewichtsmatrizen enthalten Realisationen einr Standardnormalverteilung, weshalb aus Gründen der Reproduzierbarkeit ein <code>seed</code> gesetzt wurde.</em></p>
<p>Um nun Vorhersagewerte für einen bestimmten Wertebereich zu erhalten, können wir zuerst einen Vektor <code>x</code> erstellen und diesen anschließend zusätzlich zu den Gewichten in die Funktion <code>nn</code> übergeben.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span><span class="fu">lapply</span>(x, nn, w1,w2,w3) <span class="sc">%&gt;%</span> <span class="fu">unlist</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wir können das Ergebnis auch einfach grafisch darstellen:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(x,y) <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y)) <span class="sc">+</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">col=</span> <span class="st">"navyblue"</span>, <span class="at">linewidth =</span> <span class="fl">1.5</span>)<span class="sc">+</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Neuronale_Netze_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<p>Wie in <a href="#exm-DNNFull" class="quarto-xref">Example&nbsp;<span>5.3</span></a> demonstriert, können wir durch Neuronale Netze stark nichtlineare Funktionen modellieren.</p>
</section>
</section>
<section id="anpassen-der-modellparameter" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="anpassen-der-modellparameter"><span class="header-section-number">5.2</span> Anpassen der Modellparameter</h2>
<p>Wir können die Anzahl der Parameter eines Neuronalen Netzes durch die Formel</p>
<p><span class="math display">\[\begin{equation*}
(J+1)N_1\cdot\left(\prod_{k=1}^{K} (N_k+1)\cdot N_{k+1}\right)
\end{equation*}\]</span></p>
<p>berechnen. Hierbei steht der Index <span class="math inline">\(k = 1,...,K\)</span> für die verschiedenen Hidden Layer des FFNN. Somit beschreiben wir mit <span class="math inline">\(J\)</span> die Anzahl der Input Neuronen, <span class="math inline">\(N_k\)</span>, <span class="math inline">\(k=1,...,K\)</span> die Anzahl der Neuronen in den Hidden Layern und mit <span class="math inline">\(N_{K+1}\)</span> die Anzahl der Output Neuronen. Die Addition mit <code>1</code> steht in den entsprechenden Layern für den Biasterm, da dieser ebenso mit jedem Neuron der nächsten Layer verbunden ist. Die Anzahl der Parameter steigt also nicht linear, sondern polynomiell.</p>
<p>Falls wir alle Parameter eines FFNN durch ein Objekt <span class="math inline">\(W\)</span> beschreiben und das FFNN in Abhängigkeit der Parameter als <span class="math inline">\(f_W\)</span> definieren, dann können wir auch bei diesem Modell das Optimierungsproblem</p>
<p><span class="math display">\[\begin{equation*}
  \min_{W} (f_W(x)-y)^2
\end{equation*}\]</span></p>
<p>lösen.</p>
<p>Aufgrund der Nichtlinearität und hohen Anzahl der Parameter ist eine direkte Optimierung mithilfe der partiellen Ableitungen nicht möglich. Stattdessen verwenden man beim trainieren, also beim Anpassen der Modellparameter, verschiedene Versionen des Gradientenabstiegs.</p>
<p>In der einfachsten Form ist der Gradientenabstieg durch die Formel</p>
<p><span class="math display">\[\begin{equation*}
  W_{n+1} = W_n - \eta \frac{\partial}{\partial W} \text{MSE}_W
\end{equation*}\]</span></p>
<p>gegeben. Die Idee hierbei ist vereinfacht gesagt dem steilsten Abstieg zu folgen mit dem Ziel in einem (globalen) Minimum zu landen. Wie groß die Schritte dieses Abstiegs sind, können wir durch den Parameter <span class="math inline">\(\eta\)</span> steuern. Der einfache Gradientanbstieg hat hat allerdings folgende Nachteile:</p>
<ol type="1">
<li>Bei großen Datenmenge ist das Berechnen der Gradienten sehr zeitaufwendig.</li>
<li>Auch in hohen Dimensionen kann es passieren, dass der MSE in lokales Minimum fällt und diesem nicht mehr entkommt.</li>
</ol>
<p>Um diese beiden Probleme zu lösen, verwenden wir verschiedene Versionen des Stochastic Gradient Descent. Beim Stochastic Gradient Descent wird deshalb nur eine zufällig ausgewählte Teilmenge der Daten verwendet, um den MSE zu berechnen und die Parameter anzupassen. Das häufigere Updaten kann dazu führen, dass aus lokalen Minima ausgebrochen wird und zusätzlich dadurch, dass nur ein Teil der Daten in jedem Schritt verwendet wird, auch der Aufwand bei der Berechnung verringert wird.</p>
<p>Das Bilden der Partiellen Ableitungen bezüglich der Netzwerkparameter kann ebenso sehr aufwendig werden, da ein tiefes Neuronales Netz eine vielfach verschachtelte Funktion ist. Allerdings kann hierbei die Kettenregel verwendet werden, was den Prozess beschleunigen kann. Für die tatsächliche Berechnung der Gradienten wird der <em>Backpropagation</em> Algorithmus verwendet, welcher neben der Kettenregel auch noch weitere Effizienzmechanismen verwendet. Die Idee ist hierbei, dass die Gewichte in einer Layer <span class="math inline">\(k\)</span> lediglich durch den Effekt auf die Neuronen in der <span class="math inline">\(k+1\)</span> Layer den MSE beeinflussen. Deshalb müssen wir nur die Gradienten der Layer <span class="math inline">\(k,k-1,...,1\)</span> berechnen. Dieses Vorgehen mitigiert eine ineffiziente Berechnung der Gradienten durch das Vermeiden von wiederholten Berechnungen der Gradienten in den Layern <span class="math inline">\(k+1,...,K\)</span> welche nicht durch die Gewichte in Layer <span class="math inline">\(k\)</span> beeinflusst werden.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="regularisierung-von-neuronalen-netzen" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="regularisierung-von-neuronalen-netzen"><span class="header-section-number">5.2.1</span> Regularisierung von Neuronalen Netzen</h3>
</section>
</section>
<section id="neuronale-netze-in-r" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="neuronale-netze-in-r"><span class="header-section-number">5.3</span> Neuronale Netze in R</h2>
<p>Das Training von neuronalen Netzwerken innerhalb des <code>{tidymodels}</code>-Frameworks können wir durch die <code>{brulee}</code>-Library durchführen.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brulee)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ähnlich wie bei allen zuvor trainierten Modellen müssen wir hierbei lediglich eine Architektur spezifizieren und das Modell dann mithilfe der <code>fit</code>-Funktion trainieren.</p>
<p>Interessant im Kontext dieser Übung sind hierbei die folgenden Parameter:</p>
<ul>
<li><code>epochs</code>: Eine Ganzzahl, die die Anzahl der Trainingsdurchläufe angibt.</li>
<li><code>hidden_units</code>: Kann entweder eine Ganzzahl oder ein Vektor aus Ganzzahlen sein. Eine einzelne Zahl bedeutet, dass nur eine versteckte Schicht verwendet wird, während ein Vektor durch seine Länge die Anzahl der Schichten und durch seine Werte die Anzahl der Neuronen pro Schicht angibt.</li>
<li><code>learn_rate</code>: Eine positive Zahl, die die Schrittweite für den Optimierungsalgorithmus angibt.</li>
</ul>
<p>Für die Demonstration des Modells verwenden wir wieder den <code>palmerpenguins::penguins</code> Datensatz. Das Ziel ist dabei wie gehabt, das Gewicht eines Pinguins durch die anderen Merkmale vorherzusagen.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>data_penguin <span class="ot">&lt;-</span> palmerpenguins<span class="sc">::</span>penguins</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Im Verleich zu den anderen Modellen müssen wir die Daten vor dem fitten des Modells transformieren. Die <code>{fastDummies}</code> Library können wir verwenden, um die nominalen, bzw. ordinalen Feature zu Dummy-Variablen transformieren. Wir postulieren außerdem, dass die Variable <code>year</code> keinen Einfluss auf die Zielvariable <code>body_mass_g</code> hat. Da die <code>fastDummies::dummy_cols()</code> Funktion die nominalen Feauture im Dataset beibehält entfernen wir nach der Transformation alle nicht-nominalen Feature. Zuletzt wenden wir mithilfe der <code>mutate_at()</code> Funktion die <code>scale()</code> Funktion auf alle Spalten außer <code>body_mass_g</code> an. Durch die Anwendung der <code>scale()</code> Funktion erreichen wir, dass jedes Feature Mean <code>0</code> und Standardabweichung <code>1</code> besitzt.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastDummies)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>data_penguin_transformed <span class="ot">&lt;-</span> data_penguin <span class="sc">%&gt;%</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>()<span class="sc">%&gt;%</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dummy_cols</span>() <span class="sc">%&gt;%</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>year) <span class="sc">%&gt;%</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_if</span>(is.numeric) <span class="sc">%&gt;%</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_at</span>(<span class="fu">vars</span>(<span class="sc">-</span><span class="st">"body_mass_g"</span>),scale)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nachdem wir die zugrundeliegenden Daten transformiert haben, können wir mithilfe der <code>mlp()</code> Funktion ein DNN spezifizieren.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>nnet_spec <span class="ot">&lt;-</span> <span class="fu">mlp</span>(<span class="at">epochs =</span> <span class="dv">200</span>,</span>
<span id="cb14-2"><a href="#cb14-2"></a>                 <span class="at">hidden_units =</span> <span class="fu">c</span>(<span class="dv">64</span>,<span class="dv">32</span>),</span>
<span id="cb14-3"><a href="#cb14-3"></a>                 <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb14-4"><a href="#cb14-4"></a>                 <span class="at">activation =</span> <span class="fu">c</span>(<span class="st">"relu"</span>,<span class="st">"relu"</span>),</span>
<span id="cb14-5"><a href="#cb14-5"></a>                 <span class="at">mode =</span> <span class="st">"regression"</span></span>
<span id="cb14-6"><a href="#cb14-6"></a>                 ) <span class="sc">%&gt;%</span> </span>
<span id="cb14-7"><a href="#cb14-7"></a>  <span class="fu">set_engine</span>(<span class="at">engine =</span> <span class="st">"brulee"</span>,</span>
<span id="cb14-8"><a href="#cb14-8"></a>             <span class="at">verbose =</span> <span class="cn">FALSE</span>,</span>
<span id="cb14-9"><a href="#cb14-9"></a>             <span class="at">optimizer =</span> <span class="st">"SGD"</span>,</span>
<span id="cb14-10"><a href="#cb14-10"></a>             <span class="at">stop_iter =</span> <span class="dv">15</span></span>
<span id="cb14-11"><a href="#cb14-11"></a>             ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Die Spezifikation setzt sich hierbei aus zwei Teilen zusammen:</p>
<ol type="1">
<li>In den Zeilen <code>1</code>-<code>6</code> wird ein allgemeines MLP definiert.
<ul>
<li>Das Training stoppt nach maximal <code>200</code> Epochen.</li>
<li>Die Architektur besteht aus der Input Layer, zwei Hidden Layer mit jeweils <code>64</code> und <code>32</code> Neuronen und der Output Layer.</li>
<li>Die Learning Rate des Gradientenabstiegs (<span class="math inline">\(\eta\)</span>) wird auf <code>0.01</code> gesetzt.</li>
<li>Die Aktrivierungsfunktionen der hidden Layer setzen wir auf <code>"relu"</code>.</li>
<li>Den Modus setzen wir auf <code>"regression"</code>.</li>
</ul></li>
<li>Nachdem die <code>{brulee}</code> unabhängigen Parameter definiert wurden, passen wir in den Zeilen <code>7</code>-<code>11</code> noch weitere Parameter an, welche spezifisch für Neuronale Netze gelten die mithilfe der <code>{brulee}</code> Library trainiert werden.
<ul>
<li>Mithilfe von <code>engine = "brulee"</code> spezifizieren wir, dass wir ein Neuronales Netz basierend auf der <code>brulee</code> Library trainieren wollen.</li>
<li>Das Argument <code>verbose</code> spezifiziert, ob wir während dem Training den Fortschritt sehen wollen. Für das Experimentieren daheim würde ich das empfehlen - Hier im Skript würde das zu viel Platz einnehmen.</li>
<li>Den Optimierungsalgorithmus setzen wir auf <code>"SGD"</code> was für Stochastic Gradient Descent steht.</li>
<li>Das Argument <code>stop_iter=15</code> spezifiziert, dass das Training beendet wird, falls nach 15 Epochen keine Reduktion des Fehlers festgestellt wird.</li>
</ul></li>
</ol>
<p>Beim Trainieren der Modellparameter ist durch das Verwenden des <code>"SGD"</code> Randomness involviert, weshalb wir ein Seed setzen sollten, um Reproduzierbarkeit zu gewährleisten.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>nnet_res <span class="ot">&lt;-</span> nnet_spec <span class="sc">%&gt;%</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> data_penguin_transformed,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">formula =</span> body_mass_g <span class="sc">~</span>.</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wir können dann analog zu der MLR und den Baummodellen das Neuronale Netz mithilfe der <code>fit()</code> Funktion trainieren. Der <code>fit</code> Funktion müssen wir wie gewohnt die Argumente <code>data</code> und <code>formula</code> übergeben, welche die Daten und die Formel für das Fitten spezifizieren.</p>
<p>Nachdem wir das Neuronale Netz trainiert haben können wir zum Beispiel mithilfe der <code>autoplot()</code> Funktion den Trainingsprozess evaluieren.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>nnet_res <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()<span class="sc">+</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Neuronale_Netze_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Auf der <span class="math inline">\(y\)</span> Achse wird hierbei die OOS Güte auf Basis eines Validierungssets berechnet. Dieses Validierungsset wurde automatisch durch die Modellspezifikation generiert. Durch das Argument <code>validation</code> könnten wir in der <code>set_engine()</code> Funktion manuell anapssen. Falls wir also beispielsweise</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>  ... <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    ... ,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation =</span> <span class="fl">0.2</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>übergeben, dann werden <span class="math inline">\(20\%\)</span> der übergebenen Daten als Validierungsset verwendet.</p>
<p>Wir sehen also, dass der Validierungsfehler zu Beginn des Trainings relativ schnell abflacht und sich nach ca. 75 Epochen stabilisiert.</p>
<p>Die grüne, gestrichelte Linie am rechten Ende der Grafik zeigt, für welche Iteration die Gewichte letztendlich verwendet wurden. Dadurch, dass die Linie ganz am rechten Rand ist können wir zum Beispiel feststellen, dass das <code>stop_iter</code> Kriterium hier nicht gegriffen hat.</p>
<p>Evlauieren können wir das FFDNN analog zu den bisherigen Modellen:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>nnet_res <span class="sc">%&gt;%</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(data_penguin_transformed) <span class="sc">%&gt;%</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rmse</span>(.pred,body_mass_g)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 rmse    standard        285.</code></pre>
</div>
</div>
<p>Durch das Übergeben des trainierten Modells in die <code>augment()</code> Funktion zusammen mit den transformierten Daten erhalten wir ein neues Dataset, welches neben den transformierten Trainingsdaten auch noch die Predictions <code>.pred</code> und Residuen <code>.resid</code> enthält. Mithilfe der Spalten <code>.pred</code> und <code>body_mass_g</code> können wir dann zum Beispiel die Metrik <code>rmse</code> berechnen.</p>
<p><strong>Wichtig: Wir berechnen hier lediglich die In-Sample Güte des Modells. Es ist also zu erwarten, dass diese bereits sehr gut ist.</strong></p>
<!--
## Übungsaufgaben

## Lösungen

-->


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Für eine tiefgreifende Erklärung kann ich <a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">Grant Sandersons</a> Video(s) zu Backpropagation empfehlen.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04_Regressions_Baeume.html" class="pagination-link" aria-label="Regressionsbäume">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regressionsbäume</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>