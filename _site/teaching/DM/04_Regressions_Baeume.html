<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Regressionsbäume – Data Mining Übungsmaterial</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03_Wichtige_Konzepte.html" rel="prev">
<script src="site_libs/cookie-consent/cookie-consent.js"></script>
<link href="site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-K9CJ1KN8ZH"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-K9CJ1KN8ZH', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"express",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<script>

  MathJax = {

    tex: {

      tags: 'ams'  // should be 'ams', 'none', or 'all'

    }

  };

</script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04_Regressions_Baeume.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regressionsbäume</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Mining Übungsmaterial</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vorwort</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Einfuehrung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">(Kurz)Einführung in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Lineare_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Lineare Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Wichtige_Konzepte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Weiterführende Konzepte des Dataminings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Regressions_Baeume.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regressionsbäume</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#grundidee" id="toc-grundidee" class="nav-link active" data-scroll-target="#grundidee"><span class="header-section-number">4.1</span> Grundidee</a>
  <ul>
  <li><a href="#darstellung-von-bäumen-und-vorhersagen" id="toc-darstellung-von-bäumen-und-vorhersagen" class="nav-link" data-scroll-target="#darstellung-von-bäumen-und-vorhersagen"><span class="header-section-number">4.1.1</span> Darstellung von Bäumen und Vorhersagen</a>
  <ul class="collapse">
  <li><a href="#baumdiagramme" id="toc-baumdiagramme" class="nav-link" data-scroll-target="#baumdiagramme"><span class="header-section-number">4.1.1.1</span> Baumdiagramme</a></li>
  <li><a href="#aufteilung-des-featurespace" id="toc-aufteilung-des-featurespace" class="nav-link" data-scroll-target="#aufteilung-des-featurespace"><span class="header-section-number">4.1.1.2</span> Aufteilung des Featurespace</a></li>
  </ul></li>
  <li><a href="#vorteile-gegenüber-linearen-modellen" id="toc-vorteile-gegenüber-linearen-modellen" class="nav-link" data-scroll-target="#vorteile-gegenüber-linearen-modellen"><span class="header-section-number">4.1.2</span> Vorteile gegenüber linearen Modellen</a></li>
  </ul></li>
  <li><a href="#sec-tdgreedy" id="toc-sec-tdgreedy" class="nav-link" data-scroll-target="#sec-tdgreedy"><span class="header-section-number">4.2</span> Top-Down-Greedy</a>
  <ul>
  <li><a href="#rekursive-und-greedy-eigenschaft-des-algorithmus" id="toc-rekursive-und-greedy-eigenschaft-des-algorithmus" class="nav-link" data-scroll-target="#rekursive-und-greedy-eigenschaft-des-algorithmus"><span class="header-section-number">4.2.1</span> Rekursive und Greedy Eigenschaft des Algorithmus</a></li>
  <li><a href="#sec-stoppingcriteria" id="toc-sec-stoppingcriteria" class="nav-link" data-scroll-target="#sec-stoppingcriteria"><span class="header-section-number">4.2.2</span> Stoppkriterien</a>
  <ul class="collapse">
  <li><a href="#mindestanzahl-an-beobachtungen-min_n" id="toc-mindestanzahl-an-beobachtungen-min_n" class="nav-link" data-scroll-target="#mindestanzahl-an-beobachtungen-min_n"><span class="header-section-number">4.2.2.1</span> Mindestanzahl an Beobachtungen <code>min_n</code></a></li>
  <li><a href="#baumtiefe-tree_depth" id="toc-baumtiefe-tree_depth" class="nav-link" data-scroll-target="#baumtiefe-tree_depth"><span class="header-section-number">4.2.2.2</span> Baumtiefe <code>tree_depth</code></a></li>
  <li><a href="#sec-improvement" id="toc-sec-improvement" class="nav-link" data-scroll-target="#sec-improvement"><span class="header-section-number">4.2.2.3</span> Reduktion des Fehlers (<code>cost_complexity</code>)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#wichtigkeit-der-variablen-in-baummodellen" id="toc-wichtigkeit-der-variablen-in-baummodellen" class="nav-link" data-scroll-target="#wichtigkeit-der-variablen-in-baummodellen"><span class="header-section-number">4.3</span> Wichtigkeit der Variablen in Baummodellen</a></li>
  <li><a href="#regressionsbäume-in-r" id="toc-regressionsbäume-in-r" class="nav-link" data-scroll-target="#regressionsbäume-in-r"><span class="header-section-number">4.4</span> Regressionsbäume in R</a>
  <ul>
  <li><a href="#sec-paramestimate" id="toc-sec-paramestimate" class="nav-link" data-scroll-target="#sec-paramestimate"><span class="header-section-number">4.4.1</span> Schätzung der Parameter</a></li>
  <li><a href="#darstellung-des-baums" id="toc-darstellung-des-baums" class="nav-link" data-scroll-target="#darstellung-des-baums"><span class="header-section-number">4.4.2</span> Darstellung des Baums</a></li>
  <li><a href="#berechnung-der-improvement-werte" id="toc-berechnung-der-improvement-werte" class="nav-link" data-scroll-target="#berechnung-der-improvement-werte"><span class="header-section-number">4.4.3</span> Berechnung der Improvement Werte</a></li>
  </ul></li>
  <li><a href="#sec-erweiterungen" id="toc-sec-erweiterungen" class="nav-link" data-scroll-target="#sec-erweiterungen"><span class="header-section-number">4.5</span> Erweiterungen</a>
  <ul>
  <li><a href="#erstellung-eines-bootstrap-datasets." id="toc-erstellung-eines-bootstrap-datasets." class="nav-link" data-scroll-target="#erstellung-eines-bootstrap-datasets."><span class="header-section-number">4.5.1</span> Erstellung eines Bootstrap Datasets.</a></li>
  <li><a href="#trainieren-der-baummodelle-und-aggregation" id="toc-trainieren-der-baummodelle-und-aggregation" class="nav-link" data-scroll-target="#trainieren-der-baummodelle-und-aggregation"><span class="header-section-number">4.5.2</span> Trainieren der Baummodelle und Aggregation</a></li>
  <li><a href="#random-forests-in-r" id="toc-random-forests-in-r" class="nav-link" data-scroll-target="#random-forests-in-r"><span class="header-section-number">4.5.3</span> Random Forests in R</a></li>
  </ul></li>
  <li><a href="#übungsaufgaben" id="toc-übungsaufgaben" class="nav-link" data-scroll-target="#übungsaufgaben"><span class="header-section-number">4.6</span> Übungsaufgaben</a>
  <ul>
  <li><a href="#theorieaufgaben" id="toc-theorieaufgaben" class="nav-link" data-scroll-target="#theorieaufgaben"><span class="header-section-number">4.6.1</span> Theorieaufgaben</a></li>
  <li><a href="#r-aufgaben" id="toc-r-aufgaben" class="nav-link" data-scroll-target="#r-aufgaben"><span class="header-section-number">4.6.2</span> R Aufgaben</a>
  <ul class="collapse">
  <li><a href="#modellvergleiche" id="toc-modellvergleiche" class="nav-link" data-scroll-target="#modellvergleiche"><span class="header-section-number">4.6.2.1</span> Modellvergleiche</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#lösungen" id="toc-lösungen" class="nav-link" data-scroll-target="#lösungen"><span class="header-section-number">4.7</span> Lösungen</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regressionsbäume</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In diesem Kapitel setzen wir uns mit Baummodellen in einem Regressionskontext auseinander. Baummodelle bilden die Grundlage für viele weitere Modelle, welche aufgrund ihrer Fähigkeit Zusammenhänge sehr gut zu modellieren oft genurzr weren. Mit einer dieser Erweiterungen setzen wir uns in <a href="#sec-erweiterungen" class="quarto-xref"><span>Section 4.5</span></a> auseinander.<br>
Der Hauprfokus dieses Kapitels liegt allerdings darauf, die Grundidee des Modells und des Algorithmus zu verstehen der für das Schätzen von Regressionsbäumen verwendet wird.</p>
<section id="grundidee" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="grundidee"><span class="header-section-number">4.1</span> Grundidee</h2>
<p>Regressionsbäume sind Teil der <em>Classification and Regression Tree</em> (CART) Familie. Regressions und Klassifikationsbäume werden auch Entscheidungsbäume genannt, da die Vorhersagen durch (binär: ‘Ja’/‘Nein’) Entscheidungen berechnet werden.</p>
<section id="darstellung-von-bäumen-und-vorhersagen" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="darstellung-von-bäumen-und-vorhersagen"><span class="header-section-number">4.1.1</span> Darstellung von Bäumen und Vorhersagen</h3>
<p>In diesem Unterkapitel diskutieren wir zwei Möglichkeiten um Entscheidungsbäume darzustellen.</p>
<section id="baumdiagramme" class="level4" data-number="4.1.1.1">
<h4 data-number="4.1.1.1" class="anchored" data-anchor-id="baumdiagramme"><span class="header-section-number">4.1.1.1</span> Baumdiagramme</h4>
<p>Die grafischen Bestandteile bei der Darstellung eines Entscheidungsbaums als Baumdiagramm sind <em>Knoten</em> (nodes) und <em>Kanten</em>. Bei den Knoten unterscheiden wir vor allem zwischen dem <em>Wurzelknoten</em> (root node) und <em>Blattknoten</em>. Der Wurzelknkoten steht hierbei immer ganz oben im Diagramm und die Blattknoten am Ende der jeweiligen Entscheidungspfade. Knoten welche zwischen dem Wurzel und den Blattknoten stehen nennen wir auch Entscheidungsknoten. (Beachte, dass auch der Wurzelknoten ein Entscheidungsknoten ist!) In einem Entscheidungsknoten prüfen wir eine aufgestellte Bedingung und bewegen uns auf Basis der Entscheidung entsprechend entlang der Kanten. Bei numerischen Features ist sind die Bedingungen in Form eines Größenvergleichs gegeben. Es wird also überprüft, ob das Feature eines Datenpunktes größer(-gleich) oder kleiner als ein Schwellenwert ist. Ähnlich wie beim Dummy-Encoding bei einer linearen Regression wird bei nominalen Merkmalen lediglich geprüft, ob die Ausprägung der Variable mit dem Entscheidungswert übereinstimmt oder nicht. Diesen Vorgang wiederholen wir bis ein Blattknoten erreicht wird, in welchem die Vorhersagen stehen.</p>
<p>Folgende Grafik zeigt eine Beispielhafte Darstellung eines solchen Entscheidungsbaums.</p>
<div id="fig-Lorem" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Lorem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="pictures/Tree_diagram.svg" id="fig-Lorem" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-Lorem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1
</figcaption>
</figure>
</div>
<p>Das in <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> dargestellte Baumdiagramm wurde auf Basis eines Datensatzes erzeugt, welcher die beiden Variablen <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> enthält. In jedem Entscheidungsknoten wird das Entscheidungskriterium durch einen Sehwellenwert (Splittingpoint) <span class="math inline">\(t_i,i=1,...,6\)</span> ausgedrückt. Falls in einem binären Entscheidungsbaum also <span class="math inline">\(6\)</span> Splittingpoints gegeben sind, dann existieren <span class="math inline">\(6+1 = 7\)</span> Blattknoten. Da der oberste Knoten (Wurzeknoten) auch ein Entscheidungsknoten ist, hat dieser teilweise die gleiche Farbe wie die anderen Entscheidungsknoten, ist aufgrund seiner Wurzeleigenschaft aber nochmal gesondert zu betrachten.</p>
<p>Wir prüfen also im ersten Schritt ob die Variable <span class="math inline">\(X_2\)</span> kleiner oder gleich <span class="math inline">\(t_1\)</span> ist. Falls das der Fall ist, bewegen wir uns entlang der linken Kante und ansonsten entlang der rechten Kante zum nächsten Entscheidungsknoten. Angenommen <span class="math inline">\(X_2\leq t_1\)</span>, dann bewegen wir uns zum nächsten Knoten in welchem wir die Bedingung <span class="math inline">\(X_1\leq t_2\)</span> prüfen. Falls diese Bedingung ebenso erfüllt ist, landen wir im Blattknoten mit dem Wert <span class="math inline">\(R_1\)</span>. Der Wert <span class="math inline">\(R_1\)</span> ist dann die vorhersage für den entsprechenden Datenpunkt. Wie die Werte <span class="math inline">\(R_k, k=1,...,6\)</span> berechnet werden untersuchen wir in <a href="#sec-tdgreedy" class="quarto-xref"><span>Section 4.2</span></a>.</p>
</section>
<section id="aufteilung-des-featurespace" class="level4" data-number="4.1.1.2">
<h4 data-number="4.1.1.2" class="anchored" data-anchor-id="aufteilung-des-featurespace"><span class="header-section-number">4.1.1.2</span> Aufteilung des Featurespace</h4>
<p>Äquivalent zur Darstellung eines Diagramms können wir, zumindest bei ein- oder zweidimensionalen Datensätzen, einen Entscheidungsbaum auch im <em>Featurespace</em> darstellen. Mit Featurespace meinen wir hier den Raum, welcher durch die Ausprägungen aufgespannt wird. Existieren wie in <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> zum Beispiel zwei Feature <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>, dann können wir die Splittingpoints und Blattknoten in einem Kooerdinatensystem darstellen:</p>
<div id="fig-featurespace" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-featurespace-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="pictures/Feature_Space.svg" id="fig-featurespace" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-featurespace-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2
</figcaption>
</figure>
</div>
<p>Beachte dass die Darstellungen in <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> und <a href="#fig-featurespace" class="quarto-xref">Figure&nbsp;<span>4.2</span></a> äquivalent sind. Wir können also jeweils die eine Darstellung in die andere überführen. Um beispielsweise in den Blattknoten <span class="math inline">\(R_6\)</span> aus <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> zu erreichen müssen wir in <a href="#fig-featurespace" class="quarto-xref">Figure&nbsp;<span>4.2</span></a> die gleichen Bedingungen prüfen:</p>
<ol type="1">
<li><span class="math inline">\(X_2\leq t_1\)</span> ist bei <span class="math inline">\(R_6\)</span> nicht erfüllt und deshalb <span class="math inline">\(X_2&gt;t_1\)</span>. Wir befinden uns also oberhalb der horizontalen Linie durch den Punkt <span class="math inline">\(t_1\)</span>.</li>
<li><span class="math inline">\(X_1\leq t_4\)</span> ist bei <span class="math inline">\(R_6\)</span> ebenso nicht erfüllt, weshalb <span class="math inline">\(X_1&gt;t_4\)</span> gilt.</li>
<li><span class="math inline">\(X_1\leq t_5\)</span> ist bei <span class="math inline">\(R_6\)</span> ebenso nicht erfüllt, weshalb <span class="math inline">\(X_1&gt;t_5\)</span> gilt.</li>
<li><span class="math inline">\(X_2\leq t_6\)</span> ist bei <span class="math inline">\(R_6\)</span> ebesno nicht erfüllt, weshalb <span class="math inline">\(X_2&gt;t_6\)</span> gilt.</li>
</ol>
<p>Zusammengefasst muss für ein Datenpunkt <span class="math inline">\((x_1,x_2)\)</span> also <span class="math inline">\(x_2&gt;t_6\)</span> und <span class="math inline">\(x_1&gt;t_5\)</span> gelten, damit der Datenpunkt in den Blattknoten <span class="math inline">\(R_6\)</span> fällt.</p>
</section>
</section>
<section id="vorteile-gegenüber-linearen-modellen" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="vorteile-gegenüber-linearen-modellen"><span class="header-section-number">4.1.2</span> Vorteile gegenüber linearen Modellen</h3>
<p>Bäume gehören aufgrund ihrer Struktur zu nichtlinearen Modellen. Falls die unterliegenden Daten also nicht der Linearitätsannahme unterliegen, können wir also bei einem <em>guten</em> Baum erwarten, dass dieser die Zusammenhänge in den Daten besser beschreibt.</p>
<p>Betrachte hierfür folgendes syntetisches Beispiel, welches diesen Effekt illustriert:</p>
<div id="exm-tree_quad" class="theorem example">
<p><span class="theorem-title"><strong>Beispiel 4.1</strong></span> Der Datensatz <code>data_exm</code> besteht aus zwei Spalten <code>x</code> und <code>y</code>, wobei <code>x</code> Werte zwischen <span class="math inline">\(0\)</span> und <span class="math inline">\(10\)</span> annimmt und <span class="math inline">\(y\)</span> durch die Formel <span class="math display">\[y = f(x)+\varepsilon=\sin(x)+\varepsilon \]</span></p>
<p>(mit <span class="math inline">\(\varepsilon \sim \mathcal{N}(0,1)\)</span>) berechnet wird. <code>y</code> soll hierbei die abhängige und <code>x</code> die unabhängige Variable darstellen und das Ziel ist deshalb <code>y</code> durch <code>x</code> zu approximieren.</p>
<p>Die folgende Grafik zeigt eine Realisation dieser Simulation:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p>Falls wir nun versuchen den Zusammenhang zwischen <code>y</code> und <code>x</code> mithilfe eines einfachen linearen Modells zu modellieren, so erhalten wir die Regressionsgerade welche in der folgenden Grafik dargestellt ist.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p>Offensichtlich eignet sich die einfache lineare Regression nicht um den Zusammenhang zwischen <code>y</code> und <code>x</code> zu modellieren. Wir können allerdings den Zusammenhang ebenso durch einen Regressionsbaum modellieren, welcher im Featurespace wie folgt dargestellt werden kann.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p>Beachte, dass unser Featurespace in diesem Beispiel nur eindimensional ist, weshalb das resultierende Baummodell keine Flächen (wie in <a href="#fig-featurespace" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>), sondern Geraden enthält. Die rote Linie beschreibt hierbei die durch das Baummodell geschätzten Werte <span class="math inline">\(\hat{y}\)</span> für ein gegebenes <span class="math inline">\(x\)</span>. Das Baummodell modelliert den Einfluss von <code>x</code> auf <code>y</code> also vergleichsweise gut, obwohl die Daten keinen linearen Zusammenhang besitzen!</p>
</div>
<p>Zusammengefasst spiegelt sich der erste Vorteil von Baummodellen gegenüber linearen Modellen also in der Fähigkeit wieder auch nichtlineare Zusammenhänge zu modellieren.</p>
<p>Einen weiteren Vorteil können wir bei der Betrachtung von <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> erkennen: Bei Baummodellen ist sehr leicht erkennbar, auf Basis welcher Variablen und Schwellenwerten die Vorhersagen getroffen werden. Selbst wenn das Modell aus einer Vielzahl von Variablen besteht kann man durch die Darstellung eines Baumdiagramms effizient den Wert berechnen, welcher durch das Modell vorhergesagt wird.</p>
</section>
</section>
<section id="sec-tdgreedy" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-tdgreedy"><span class="header-section-number">4.2</span> Top-Down-Greedy</h2>
<p>Bisher haben wir zwar verschiedene Darstellung der Regressionsbäume betrachtet und herausgefunden wie wir bei den verschiedenen Darstellungen Vorhersagewerte ablesen können, allerdings nicht wie die Schwellwerte und Splittingvariablen bestimmt werden.</p>
<p>Der Algorithmus welcher hierfür verwendet wird ist der sogenannte <em>Top-Down-Greedy</em> oder <em>Recursive-Binary-Splitting</em> Algorithmus. Um den Algorithmus zu erklären orientieren wir uns primär an der Darstellung aus <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a>.</p>
<p>Die Idee des Algorithmus ist, dass wir in jedem Schritt den Feature Space <em>bestmöglich</em> zweiteilen um eine verbesserte Vorhersage im Vergleich zur ungeteilten Version erhalten. Formal lässt sich der Algorithmus wie folgt darstellen:</p>
<ol type="1">
<li><p><strong>Initialisierung</strong>:<br>
Beginne mit dem gesamten Trainingsdatensatz <span class="math display">\[D = \{(x_k,y_k):x_k\in\mathbb{R}^J,\: y_k\in\mathbb{R},\: k = 1,...,K\}\]</span> in der Wurzel des Baums.</p></li>
<li><p><strong>Spaltensuche </strong>:<br>
Für jedes Feature <span class="math inline">\(X_j\)</span> und jeden potenziellen<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Schwellenwert <span class="math inline">\(s\)</span>:</p>
<ol type="i">
<li><p>Teile die Daten in zwei Regionen: <span class="math display">\[\begin{align*}
  R_1(j, s) &amp;= \{ x \in D \mid x_j \leq s \}\\
  R_2(j, s) &amp;= \{ x \in D \mid x_j &gt; s \}
\end{align*}\]</span></p></li>
<li><p>Berechne den MSE, welcher durch diese Aufteilung entsteht:</p>
<p><span class="math display">\[\begin{equation*}
  \text{MSE}(j, s) = \frac{1}{|R_1|}\sum_{i: x_i \in R_1(j, s)} (y_i - \bar{y}_{R_1})^2 + \frac{1}{|R_2|}\sum_{i: x_i \in R_2(j, s)} (y_i - \bar{y}_{R_2})^2
\end{equation*}\]</span><br>
wobei <span class="math inline">\(\bar{y}_{R_1}\)</span> der durschnittliche Wert aller Datenpunkte <span class="math inline">\(y\)</span> ist, welche in <span class="math inline">\(R_1\)</span> liegen und <span class="math inline">\(\bar{y}_{R_2}\)</span> der durschnittliche Wert aller Datenpunkte <span class="math inline">\(y\)</span>, welche in <span class="math inline">\(R_2\)</span> liegen.</p></li>
</ol></li>
<li><p><strong>Wahl des besten Schwellenwerts </strong>:<br>
Wähle das Paar <span class="math inline">\((j^{*},s^{*})\)</span>, welches den MSE minimiert.</p></li>
<li><p><strong>Rekursives Aufteilen</strong>:</p>
<ol type="i">
<li>Erzeuge zwei neue Knoten für <span class="math inline">\(R_1(j^{*}, s^{*})\)</span> und <span class="math inline">\(R_2(j^{*}, s^{*})\)</span>.</li>
<li>Wiederhole Schritte 2–4 rekursiv für jeden dieser Knoten.</li>
</ol></li>
<li><p><strong>Stopkriterium prüfen</strong>:<br>
Beende die Aufteilung, wenn eines der folgenden Kriterien erfüllt ist:</p>
<ol type="i">
<li>Die Region enthält weniger als eine vorher festgelegte Mindestanzahl an Beobachtungen.</li>
<li>Eine vorher festgelegte maximale Baumtiefe wurde erreicht.</li>
<li>Die Reduktion des Fehlers liegt unter einem vorher festgelegten Schwellenwert.</li>
</ol></li>
<li><p><strong>Terminalknoten-Wert setzen</strong>:<br>
Weise jedem Blattknoten den Mittelwert der Zielvariablen <span class="math inline">\(\bar{y}_{R_i}\:,i=1,...,I\)</span> der enthaltenen Datenpunkte zu.</p></li>
</ol>
<section id="rekursive-und-greedy-eigenschaft-des-algorithmus" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="rekursive-und-greedy-eigenschaft-des-algorithmus"><span class="header-section-number">4.2.1</span> Rekursive und Greedy Eigenschaft des Algorithmus</h3>
<p>Der <em>rekursvive</em> Charakter des Algorithmus ist hierbei in Schritt 4. zu erkennen, da nach jedem Aufteilen des Datensatzes in zwei Teildatensätze diese Teildatensätze nach dem gleichen Prinzip wieder aufgeteilt werden.</p>
<p>Der <em>greedy</em> Charakter des Algorithmus ist in Schritt 3. wiederzufinden. Da wir in jeder Iteration jenen Split wählen, welcher den MSE in diesem Schritt minimiert ist gewährleistet, dass wir in jeder Iteration den bestmöglichen Split bilden. Dieses Vorgehen kann aber unter Umständen zu einem nicht optimalen Baum führen: Angnommen wir wollen eine Region <span class="math inline">\(R_i\)</span> in zwei Teilregionen <span class="math inline">\(R_{i,1}\)</span> und <span class="math inline">\(R_{i,2}\)</span> aufteilen und wählen hierfür das optimale Paar <span class="math inline">\((j^*,s^*)\)</span>. Dann existiert keine weitere Kombination <span class="math inline">\((\tilde{j},\tilde{s})\)</span>, so dass <span class="math inline">\(\text{MSE}(\tilde{j}, \tilde{s})&lt; \text{MSE}(j^*, s^*)\)</span>. Falls wir also <span class="math inline">\(R_i\)</span> bezüglich dem Paar <span class="math inline">\((j^*, s^*)\)</span> in <span class="math inline">\(R_{i,1}\)</span> und <span class="math inline">\(R_{i,2}\)</span> aufteilen und daraufhin <span class="math inline">\(R_{i,1}\)</span> optimal in <span class="math inline">\(R_{i+1,1}\)</span> und <span class="math inline">\(R_{i+1,2}\)</span> aufteilen, dann kann es sein, dass unter der Verwendung von <span class="math inline">\((\tilde{j},\tilde{s})\)</span> aus der letzten Iteration ein Split <span class="math inline">\(R_{\tilde{i}+1,1}\)</span> und <span class="math inline">\(R_{\tilde{i}+1,2}\)</span> entstehen hätte können, für den<br>
<span class="math display">\[\begin{equation*}
\text{MSE}_{\tilde{i}+1}(j, s) &lt; \text{MSE}_{i+1}(j, s)
\end{equation*}\]</span> gilt.</p>
</section>
<section id="sec-stoppingcriteria" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-stoppingcriteria"><span class="header-section-number">4.2.2</span> Stoppkriterien</h3>
<p>Im 5. Schritt des Top-Down-Greedy Algorithmus haben wir veschiedene Kriterien genannt, welche zum Stoppen des Algorithmus führen können. Wir wollen in diesem Abschnitt die Stopp-Kriterien ein wenig genauer definieren und untersuchen.</p>
<section id="mindestanzahl-an-beobachtungen-min_n" class="level4" data-number="4.2.2.1">
<h4 data-number="4.2.2.1" class="anchored" data-anchor-id="mindestanzahl-an-beobachtungen-min_n"><span class="header-section-number">4.2.2.1</span> Mindestanzahl an Beobachtungen <code>min_n</code></h4>
<p>Das Kriterium zur Mindestanzahl an Beobachtungen prüft vor jedem weiteren Aufteilen des Featurespace, ob in den durch das Aufteilen resultierenden Teildatensätzen eine Mindestanzahl an Beobachtungen liegt. Ziel dieses Kriteriums ist es zu vermeiden, dass sich das Baummodell zu stark an die Trainingsdaten anpasst. Die vorhersagen <span class="math inline">\(\hat{y}\)</span> werden durch das Bilden des Durchschnitts in einer der Blattregionen <span class="math inline">\(R_i\)</span> generiert:</p>
<p><span class="math display">\[
\frac{1}{|R_i|}\sum_{x_k\in R_i}y_k
\]</span> Falls also in <span class="math inline">\(R_i\)</span> nur eine Observation vorhanden ist, kann das zu einer starken Verzerrung bei einer Evaluation mithilfe von Testdaten führen.</p>
<p>Wir bezeichnen nun mit <code>min_n</code> die Anzahl an Datenpunkten, welche mindestens in einem Teilgebiet liegen müssen so dass dieses geteilt wird. <code>min_n</code> muss also mindestens den Wert <code>2</code> besitzen. Nun stellt sich natürlich die Frage, welchen Wert wir für <code>min_n</code> beim Schätzen eines Regressionsbaumes festlegen sollen. Natürlich lässt sich diese Frage wie immer <a href="pictures/pikachu-shocked-face-stunned.gif">nicht eindeutig</a> beantworten. Wir werden später sehen, dass R diesen Wert erstmal selbst bestimmt, wir diesen alternativ aber auch übergeben können. Im Rahmen dieser Verasntaltung geben wir uns aber damit zufrieden, welchen Wert R für optimal hält.</p>
</section>
<section id="baumtiefe-tree_depth" class="level4" data-number="4.2.2.2">
<h4 data-number="4.2.2.2" class="anchored" data-anchor-id="baumtiefe-tree_depth"><span class="header-section-number">4.2.2.2</span> Baumtiefe <code>tree_depth</code></h4>
<p>Der Parameter <code>tree_depth</code> kann ebenso zum Stoppen des Algorithmus führen: Damit der Baum nicht unkontrolliert wächst (bzw. an Tiefe gewinnt), stoppen wir den Algorithmus sobald der Baum eine bestimmte Tiefe besitzt. Nun müssen wir noch definieren, was mit <em>tiefe</em> überhaupt gemeint ist.</p>
<ol type="1">
<li>Die Länge eines Pfades zwischen dem Wurzelknoten und einem beliebigen anderen Knoten <span class="math inline">\(K_n\)</span> ist durch die Anzahl der Kanten definiert, an welchen wir entlang gehen müssen, um den Knoten <span class="math inline">\(K_i\)</span> zu erreichen.</li>
<li>Die Tiefe eines Baumes ist dann definiert durch den längsten Pfad vom Wurzelknoten zu einem anderen Knoten.</li>
</ol>
<p>So hat der Baum in <a href="#fig-Lorem" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> zum Beispiel die Tiefe <code>4</code>, da wir entlang der rechten Seite des Baumes vier Kanten entlang gehen müssen, um entweder beim Konten mit dem Wert <span class="math inline">\(R_6\)</span> oder <span class="math inline">\(R_7\)</span> zu landen. <em>Beachte: Der längste Pfad muss also nicht eindeutig sein!</em></p>
</section>
<section id="sec-improvement" class="level4" data-number="4.2.2.3">
<h4 data-number="4.2.2.3" class="anchored" data-anchor-id="sec-improvement"><span class="header-section-number">4.2.2.3</span> Reduktion des Fehlers (<code>cost_complexity</code>)</h4>
<p>Ein weiteres wichtiges Stoppkriterium ist das Stoppen durch fehlende Reduzierung des Fehlers. Betrachte hierfür folgenden Ausschnitt aus einem beliebigen Regressionsbaum:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/Branch.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Wir können für jeden der drei Knoten den MSE durch die Formel</p>
<p><span class="math display">\[
  \text{MSE}_K = \frac{1}{|K|}\sum_{x_i\in K} (\bar{y}_K-\hat{y_i})^2
\]</span> berechnen, wobei <span class="math inline">\(K\)</span> für den entsprechenden Knoten <span class="math inline">\(K_{\text{Eltern}},K_{\text{Kind}_1},K_{\text{Kind}_2}\)</span> steht.</p>
<p>Wir sind nun an der relativen Reduzierung des Fehlers durch den Split des Eltern Knotens in zwei Kind Knoten interessiert. Diese Änderung lässt sich mithilfe der <span class="math inline">\(\text{MSE}\)</span> Terme durch folgende Formel beschreiben:</p>
<p><span class="math display">\[\begin{align}\label{eq:improvement}
  &amp; \frac{|K_{\text{Eltern}}|\cdot\text{MSE}_{K_{\text{Eltern}}} -(|K_{\text{Kind}_1}|\cdot\text{MSE}_{K_{\text{Kind}_1}}+|K_{\text{Kind}_2}|\cdot\text{MSE}_{K_{\text{Kind}_2}})}{|K_{\text{Eltern}}|\cdot\text{MSE}_{K_{\text{Eltern}}}}\\
  &amp;\qquad = 1-\frac{|K_{\text{Kind}_1}|\cdot\text{MSE}_{K_{\text{Kind}_1}}+|K_{\text{Kind}_2}|\cdot\text{MSE}_{K_{\text{Kind}_2}}}{|K_{\text{Eltern}}|\cdot\text{MSE}_{K_{\text{Eltern}}}}\nonumber
\end{align}\]</span></p>
<p>Wir nennen <span class="math inline">\(\eqref{eq:improvement}\)</span> auch den <em>Improvement</em> Wert. Der Quotient beschreibt hierbei wie groß der Anteil der Kind-Fehler im Vergleich Eltern-Fehler ist. Da die Summe der Teilfehler (<span class="math inline">\(|K_{\text{Kind}_1}|\cdot\text{MSE}_{K_{\text{Kind}_1}}+|K_{\text{Kind}_2}|\cdot\text{MSE}_{K_{\text{Kind}_2}}\)</span>) immer kleiner gleich dem Fehler des Elternknoten ist (<span class="math inline">\(|K_{\text{Eltern}}|\cdot\text{MSE}_{K_{\text{Eltern}}}\)</span>) ist der Quotient somit immer kleiner oder gleich <span class="math inline">\(1\)</span>. Falls der Zähler einen (im Vergleich zum Nenner) kleinen Wert annimmt, dann erreichen wir durch das Aufsplitten des Elternknotens eine große Verbesserung der Modellperformance. Der Improvement Wert kann somit Werte zwischen <span class="math inline">\(0\)</span> und <span class="math inline">\(1\)</span> annehmen, wobei ein Improvement Wert von <span class="math inline">\(1\)</span> impliziert, dass der Quotient den Wert <span class="math inline">\(0\)</span> besitzt und damit auch die beiden <span class="math inline">\(\text{MSE}\)</span> der Kind Knoten den Wert <span class="math inline">\(0\)</span> annehmen. Falls der Improvment Wert sehr klein ist, bedeutet das im Umkehrschluss, dass durch das Splitten des Eltern Knotens keine große Verringerung des Fehlers erreicht wird.</p>
<p>Wir können nun für den Improvement Wert wie er in <span class="math inline">\(\eqref{eq:improvement}\)</span> definiert ist, einen Schwellenwert <code>cost_complexity</code> festlegen. Falls der Improvement Wert für einen Knoten kleiner ist als der Schwellenwert <code>cost_complexity</code> wird dieser Knoten nicht weiter geteilt. Sobald der Schwellenwert für alle Knoten unterschritten ist, bricht dann der Algorithmus ab.</p>
</section>
</section>
</section>
<section id="wichtigkeit-der-variablen-in-baummodellen" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="wichtigkeit-der-variablen-in-baummodellen"><span class="header-section-number">4.3</span> Wichtigkeit der Variablen in Baummodellen</h2>
<p>Im Vergleich zu linearen Modellen können wir die <em>Koeffizienten</em> der Regressionsbäume nicht mehr direkt interpretieren. Es gibt allerdings verschiedene Ansätze welche sowohl die Einflussnahme, als auch die Interpretation der verschiedenen Variablen im Modell ermöglicht.</p>
<ol type="1">
<li><p>Eine Idee wäre zu zählen, wie oft eine Variable zum Aufteilen des Feature Space verwendet wurde. Allerdings ist diese Idee ohne eine zusätzliche Gewichtung zu ungenau, da das wiederholte Verwenden einer Variable den Einfluss auf die Modellgüte nur unzureichend Beschreibt.</p>
<div id="exm-improvementfallacy" class="theorem example">
<p><span class="theorem-title"><strong>Beispiel 4.2</strong></span> Angenommen Variable <span class="math inline">\(X_j\)</span> wird im ersten Split verwendet was zu einem Improvement Wert sehr hohen Improvement Wert führt. Nun wird die Variable <span class="math inline">\(X_j\)</span> für keinen weiteren Split verwendet. Falls dann eine Variable <span class="math inline">\(X_{\tilde{j}}\)</span> mit <span class="math inline">\(\tilde{j}\neq j\)</span> existiert, welche in mehr als einem Split verwendet wird, aber der der durch den Improvment Wert gemessene Einfluss insgesamt kleiner ist als jener der Variable <span class="math inline">\(X_j\)</span>, dann würde ohne eine Gewichtung die Variable <span class="math inline">\(X_{\tilde{j}}\)</span> trotzdem als wichtiger gelten.</p>
</div>
<p>Wir sollten also neben der absoluten Anzahl der Variablenverwendung diese auch mit dem Improvement Wert des entsprechenden Splits kombinieren. Die mathematischen Details würden an dieser Stelle den Rahmen der Veranstaltung überschreiten, allerdings ist die oben beschriebene Idee wichtig zu verstehen.<br>
</p></li>
<li><p>Um die marginalen Effekte zu prüfen können wir ebensowenig die (lineare) Änderung wie bei einer linearen Regression in Betracht ziehen. Die Grundlegende Idee bei Bäumen ist aber ähnlich: Um den Marginalen Einfluss einer Variable <span class="math inline">\(X_j\)</span> zu messen, fixiere alle anderen Variablen, variiere die Variable <span class="math inline">\(X_j\)</span> zwischen dem kleinsten und größten beobachteten Wert im Datensatz und betrachte den Einfluss dieser Variation auf der Zielvariable. Die fixierten Werte der verbleibenden Variable sollten hierbei als der Durchschnitt (bei Numerischen Variablen), oder der Modus (bei nominalen Variablen) gewählt werden.</p></li>
</ol>
</section>
<section id="regressionsbäume-in-r" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="regressionsbäume-in-r"><span class="header-section-number">4.4</span> Regressionsbäume in R</h2>
<p>Nachdem wir uns in den den vorherigen Abschnitten mit der Theorie und Darstellung von Entscheidungsbäumen auseinandergesetzt haben, wollen wir in diesem Abschnitt lernen wie man mit Entscheidungsbäumen in R umgeht.</p>
<p>Hierfür betrachten wir wieder den <code>penguins</code> Datensatz aus den vorherigen Übungen:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>data_penguin <span class="ot">&lt;-</span> palmerpenguins<span class="sc">::</span>penguins </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="sec-paramestimate" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="sec-paramestimate"><span class="header-section-number">4.4.1</span> Schätzung der Parameter</h3>
<p>Ziel ist es die Variable <code>body_mass_g</code> mit einem Regressionsbaum zu modellieren. Wir können hierfür die <code>decision_tree()</code> Funktion der <code>{tidymodels}</code> Bibliothek verwenden:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>tree_spec_penguins <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>(<span class="at">mode =</span> <span class="st">"regression"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Änlich wie bei der linearen Regression können wir durch die <code>decision_tree()</code> Funktion einen Entscheidungsbaum spezifizieren. Da Entscheidungsbäume sowohl für Klassifikations- als auch für Regressionsaufgaben verwendet werden können, müssen wir mithilfe des <code>mode</code> Arguments spezifizieren, für welche Art von Problem wir den Entscheidungsbaum verwenden wollen. Das Aufrufen des <code>tree_spec_penguins</code> Objekts zeigt dann die Spezifikation des Entscheidungsbaums:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>tree_spec_penguins</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Decision Tree Model Specification (regression)

Computational engine: rpart </code></pre>
</div>
</div>
<p>Um die Parameter des Baumes zu schätzen, verwenden wir wie auch bei der linearen Regression die <code>fit()</code> Funktion:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>tree_fit_penguins <span class="ot">&lt;-</span> tree_spec_penguins <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> data_penguin,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">formula =</span> body_mass_g <span class="sc">~</span>.</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Der Rückgabewert der <code>fit()</code> Funktion ist ein Decision Tree Objekt welches neben der ursprünglichen Spezifikation nun auch ein <code>fit</code> Attribut enthält. Dieses <code>fit</code> Attribut enthält Informationen über die Variablen und Schwellenwerte, welche in den jeweiligen Splits verwendet wurden. Durch das Aufrufen der <code>extract_fit_engine()</code> Funktion können wir diese Informationen extrahieren:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>tree_fit_penguins <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>n=342 (2 Beobachtungen als fehlend gelöscht)

node), split, n, deviance, yval
      * denotes terminal node

1) root 342 219307700 4201.754  
  2) species=Adelie,Chinstrap 219  41488530 3710.731  
    4) sex=female 109   8586055 3420.642 *
    5) sex=male 110  14640890 3998.182 *
  3) species=Gentoo 123  31004250 5076.016  
    6) sex=female 61   4853135 4670.492 *
    7) sex=male 62   6250000 5475.000 *</code></pre>
</div>
</div>
<p>In der ersten Zeile des Outputs wird angezeigt, wie viele Datenpunkte zum Schätzen der Baumparameter verwendet wurden:</p>
<div class="cell" data-out.lines="[1,2]">
<div class="cell-output cell-output-stdout">
<pre><code>n=342 (2 Beobachtungen als fehlend gelöscht)

...</code></pre>
</div>
</div>
<p>Da in zwei Beobachtungen fehlende Werte vorhanden sind, hat die <code>fit</code> Funktion diese entfernt und die Parameter auf Basis der verbleibenden <code>342</code> Beobachtungen geschätzt.</p>
<p>In der nächsten Zeile ist eine Legende gegeben, welche Informationen über den darauffolgenden Output enthält:</p>
<div class="cell" data-out.lines="[3,4]">
<div class="cell-output cell-output-stdout">
<pre><code>...

node), split, n, deviance, yval
      * denotes terminal node
...</code></pre>
</div>
</div>
<ul>
<li>In der ersten Spalte (<code>node)</code>) ist die Knotennummer gegeben. Der Knoten mit der Nummer <code>1)</code> steht hierbei für den Wurzelknoten.</li>
<li>In der zweiten Spalte (<code>split</code>) ist die Splittingvariable <span class="math inline">\(X_j\)</span> gegeben.</li>
<li>In der dritten Spalte (<code>n</code>) ist die Anzahl der Observationen in dem entsprechenden Knoten aufgeführt.</li>
<li>In der vierten Spalte (<code>deviance</code>) ist die quadrierte Abweichung der Observationen im Knoten von den tatsächlichen Werten im Knoten aufgeführt. Diese berechnet sich durch <span class="math inline">\(\text{deviance} = \text{MSE}\cdot n\)</span>.</li>
<li>In der fünften Spalte (<code>yval</code>) ist der Schätzwert <span class="math inline">\(\hat{y}\)</span> des entsprechenden Knoten gegeben.</li>
<li>In der letzten Spalte (<code>* denotes terminal node</code>) einer Zeile steht ein <code>*</code>, falls es sich in der entsprechenden Zeile um einen Blattknoten handelt.</li>
</ul>
<div class="cell" data-out.lines="[6,7,8,9,10,11,12]">
<div class="cell-output cell-output-stdout">
<pre><code>...

1) root 342 219307700 4201.754  
  2) species=Adelie,Chinstrap 219  41488530 3710.731  
    4) sex=female 109   8586055 3420.642 *
    5) sex=male 110  14640890 3998.182 *
  3) species=Gentoo 123  31004250 5076.016  
    6) sex=female 61   4853135 4670.492 *
    7) sex=male 62   6250000 5475.000 *
...</code></pre>
</div>
</div>
<p>Die verbleibenden Zeilen enthalten die zuvor beschriebenen Informationen der Legende. In jeder Zeile steht entsprechend ein Knoten des Baums, wobei die Blattknoten mit einem <code>*</code> in der letzten Zeile versehen sind.</p>
<p>Die erste Splitting Variable ist durch <code>species</code> gegeben. Falls eine Beobachtung die Ausprägungen <code>species=Adelie</code> oder <code>species=Chinstrap</code> enthält (Knoten <code>2)</code>), so werden diese zur Splitting Bedingung <code>sex=female</code> (Knoten <code>4)</code>) bzw. <code>sex = male</code> (Knoten <code>5)</code>) geleitet. Hat eine Beobachtung die Ausprägung <code>species=Gentoo</code> (Knoten <code>3)</code>), dann wird ebenso geprüft, ob der entsprechende Pinguin das Geschlecht <code>male</code> (Knoten <code>7)</code>) oder <code>female</code> (Knoten <code>6)</code>) besitzt.</p>
<p>Es wurden in dem gegebenem Baum also lediglich die Variablen <code>species</code> und <code>sex</code> verwendet, um den Baum aufzuspannen.</p>
</section>
<section id="darstellung-des-baums" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="darstellung-des-baums"><span class="header-section-number">4.4.2</span> Darstellung des Baums</h3>
<p>Wir können den geschätzten Baum aus <a href="#sec-paramestimate" class="quarto-xref"><span>Section 4.4.1</span></a> als Binärbaum mithilfe der <code>rpart.plot</code> Library darstellen<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>tree_fit_penguins <span class="sc">%&gt;%</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart.plot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Das vorgehen ist hierbei (dank der <code>{tidymodels}</code>) Syntax, ähnlich wie beim extrahieren der Modellparameter eines linearen Modells:</p>
<ol type="1">
<li>Im ersten Schritt übergeben wir das <code>tree_fit_penguins</code> Objekt in die <code>extract_fit_engine()</code> Funktion.</li>
<li>Die <code>extract_fit_engine()</code> Funktion extrahiert die Modellparameter, welche dann an die <code>rpart.plot()</code> übergeben werden.</li>
<li>Die <code>rpart.plot()</code> Funktion visualisiert die Splittingvariablen und Schwellenwerte in einer binären Baumdarstellung.</li>
</ol>
<p>Der obere Wert in einem Knoten gibt dabei an, wie groß der relative Anteil der Datenpunkte im Vergleich zu allen Datenpunkten auf dieser Ebene des Baums ist. Da auf der Ebene des Wurzelknotens nur ein Knoten ist, ist der relative Anteil in diesem entsprechend <code>100%</code>. In der zweiten Ebene sind zwei Knoten, wobei der linke Knoten <code>64%</code> und der rechte Knoten <code>34%</code> der Datenpunkte enthält. Der untere Wert in einem Knoten gibt den Schätzwert der Zielvariable an. So ist zum Beispiel der Schätzwert <span class="math inline">\(\hat{y}\)</span> im linken unterem Blattknoten durch <span class="math inline">\(3421\)</span> g gegeben. Unter einem Knoten, welcher kein Blattknoten ist, steht eine Entscheidungsregel. Im Split nach dem Wurzelknoten wird zum Biepiel geprüft, ob ein Penguin zu den Spezies <code>Adelie</code> oder <code>Chinstrap</code> gehört.</p>
</section>
<section id="berechnung-der-improvement-werte" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="berechnung-der-improvement-werte"><span class="header-section-number">4.4.3</span> Berechnung der Improvement Werte</h3>
<p>Um die Improvement Werte, bzw. die Reduktion der Fehler durch einen Split wie in <a href="#sec-improvement" class="quarto-xref"><span>Section 4.2.2.3</span></a> zu berechnen, können wir auf das <code>cptable</code> Attribut des Baumes zugreifen. Diese können wir durch die Anwendung der <code>pluck</code> Funktion extrahieren:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>tree_fit_penguins <span class="sc">%&gt;%</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">"cptable"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          CP nsplit rel error    xerror       xstd
1 0.66944717      0 1.0000000 1.0037351 0.06129720
2 0.09074516      1 0.3305528 0.3351579 0.02223837
3 0.08326927      2 0.2398077 0.2533673 0.01869944
4 0.01000000      3 0.1565384 0.1594846 0.01174359</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Hinweis">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hinweis
</div>
</div>
<div class="callout-body-container callout-body">
<p>Anstatt der <code>extract_fit_engine</code> und <code>pluck</code> Funktion kann man die Complexity Parameter Tabelle auch durch folgendes Code Snippet extrahieren:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>tree_fit_penguins<span class="sc">$</span>fit<span class="sc">$</span>cptable</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Aus Konsistenzgründen ist es aber empfehlenswert die zuvor aufgeführte Tidy-Syntax zu verwenden.</p>
</div>
</div>
<p>Die <code>cptable</code> gibt neben der Fehlerreduktion durhc einen Split noch weitere Informationen, welche wir im Folgenden analysieren wollen.</p>
<ol type="1">
<li><p>Die Spalte <code>CP</code> (Complexity Parameter) gibt einen Improvment Wert des jeweiligen Splits an. In der ersten Zeile wird somit der Improvment Wert durch das Teilen des Wurzelknotes anhand der Formel in <span class="math inline">\(\eqref{eq:improvement}\)</span> berechnet. Die darauffolgenden Improvement Werte beziehen sich ebenfalls auf die Verbesserung bezüglich dem Fehler des Wurzelknotens, weshalb hier die Formel</p>
<p><span class="math display">\[\begin{align}\label{eq:lorem}
\frac{|K_{\text{Eltern}}|\cdot\text{MSE}_{K_{\text{Eltern}}} -(|K_{\text{Kind}_1}|\cdot\text{MSE}_{K_{\text{Kind}_1}}+|K_{\text{Kind}_2}|\cdot\text{MSE}_{K_{\text{Kind}_2}})}{|K_{\text{Wurzel}}|\cdot\text{MSE}_{K_{\text{Wurzel}}}}
\end{align}\]</span> verwendet wird.</p>
<p>In Gleichung <span class="math inline">\(\eqref{eq:lorem}\)</span> steht im Nenner nicht mehr <span class="math inline">\(|K_{\text{Eltern}}|\cdot\text{MSE}_{K_{\text{Eltern}}}\)</span>, sondern <span class="math inline">\(|K_{\text{Wurzel}}|\cdot\text{MSE}_{K_{\text{Wurzel}}}\)</span>. Der Wert <code>CP</code> beschreibt also den Anteil der Fehlerverbesserung, den ein Split erzeugt, relativ zum Gesamtfehler des Modells ohne jegliche Splits (also nur der Wurzelknoten). Um also zum Beispiel den <code>CP</code> Wert in der zweiten Zeile zu berechnen, können wir die tabellarisch-hierarchische Darstellung</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>n=342 (2 Beobachtungen als fehlend gelöscht)

node), split, n, deviance, yval
      * denotes terminal node

1) root 342 219307700 4201.754  
  2) species=Adelie,Chinstrap 219  41488530 3710.731  
    4) sex=female 109   8586055 3420.642 *
    5) sex=male 110  14640890 3998.182 *
  3) species=Gentoo 123  31004250 5076.016  
    6) sex=female 61   4853135 4670.492 *
    7) sex=male 62   6250000 5475.000 *</code></pre>
</div>
</div>
<p>verwenden. Der <code>CP</code> Wert berechnet sich dann durch die <code>deviance</code> Terme, welche durch das Teilen von Knoten <code>3)</code> in die Knoten <code>6)</code> und <code>7)</code> entsehen:</p>
<p><span class="math display">\[\begin{equation*}
\frac{31004250-(4853135+6250000)}{219307700} = 0.09074517
\end{equation*}\]</span></p>
<p>Der letzte Eintrag in der Spalte <code>CP</code> (<code>0.01</code>) ist der Default Parameter der <code>decision_tree</code> Funktion für das Argument <code>cp</code> (vgl. <a href="#sec-improvement" class="quarto-xref"><span>Section 4.2.2.3</span></a>).</p></li>
<li><p>Die Spalte <code>nsplit</code> beschreibt die Anzahl der Splits. Da der letzte Eintrag <code>3</code> ist, heißt das, dass der Feauture Space drei Mal geteilt wurde.</p></li>
<li><p>Die Spalte <code>rel error</code> beschreibt den relativen Fehler des Entscheidungsbaumes beim entsprechenden Split bezüglich dem Wurzelknoten. Dieser kann mithilfe der Formel <span class="math display">\[\begin{equation*}
  \text{rel error}_i = \begin{cases}
    1,\qquad &amp;\text{falls } i=1\\
    \text{rel error}_{i-1}-\text{CP}_{i-1},\qquad &amp;\text{falls } i&gt;1
  \end{cases}
\end{equation*}\]</span> berechnet werden. Um also zum Beispiel den <code>rel err</code> für den letzten Eintrag <span class="math inline">\((i=4)\)</span> berechnen wollen, dann lautet die Formel mit eingesetzten Zahlen hierfür <span class="math display">\[\begin{equation*}
0.2398077-0.08326927 = 0.1565384
\end{equation*}\]</span></p></li>
<li><p>Die Spalten <code>xerror</code> und <code>xstd</code> beschreiben den <code>rel error</code> und dessen Standardabweichung welche sich durch eine Cross-Validation ergeben haben.</p></li>
</ol>
</section>
</section>
<section id="sec-erweiterungen" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="sec-erweiterungen"><span class="header-section-number">4.5</span> Erweiterungen</h2>
<p>Baummodelle bilden neben linearen Modellen eine wichtige Grundlage für weiterführende Modelle der Regression, welche zum Standardrepertoire eines Data Scientist gehören. <em>Random Forests</em> sind eine dieser Erweiterungen, welche wir in diesem Abschnitt diskutieren wollen.</p>
<p>Die grundlegende Idee kann in zwei Teilen erklärt werden.</p>
<section id="erstellung-eines-bootstrap-datasets." class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="erstellung-eines-bootstrap-datasets."><span class="header-section-number">4.5.1</span> Erstellung eines Bootstrap Datasets.</h3>
<p>Angnommen ein Feautre Datensatz besteht aus <span class="math inline">\(K\)</span> Datenpunkten <span class="math inline">\((x_1,...,x_K)\)</span> und <span class="math inline">\(J\)</span> Variablen, also <span class="math inline">\(x_k\in\mathbb{R}^J\)</span> für <span class="math inline">\(k=1,...,K\)</span>. Wir nehmen außerdem an, dass zu jedem Datenpunkt <span class="math inline">\(x_k\)</span> mit <span class="math inline">\(k=1,...,K\)</span> ein Zielwert <span class="math inline">\(y_k\)</span> existiert. Der gesamte Datensatz ist somit durch <span class="math inline">\(D=\{(x_k,y_k)|x_k\in\mathbb{R}^J, y\in\mathbb{R}, k=1,...,K\}\)</span> gegeben. Ein Bootstrap Sample ist dann ein Datensatz <span class="math inline">\(D^{(b)}\)</span> der größe <span class="math inline">\(K\)</span>, welcher durch zufällgies Ziehen mit Zurücklegen von Samples aus dem Datensatz <span class="math inline">\(D\)</span> generiert wird. Die Datenpunkte in <span class="math inline">\(D^{(b)}\)</span> können also durchaus mehrfach im auftauchen!</p>
</section>
<section id="trainieren-der-baummodelle-und-aggregation" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="trainieren-der-baummodelle-und-aggregation"><span class="header-section-number">4.5.2</span> Trainieren der Baummodelle und Aggregation</h3>
<p>Nachdem ein Bootstrap Sample <span class="math inline">\(D^{(b)}\)</span> erstellt wurde, schätzen wir dann mithilfe dieses Samples einen Regressionsbaum. Beim Schätzen des Baumes verwenden wir allerdings in jedem Potenziellen Split nur <code>mtry</code><span class="math inline">\(&lt;J\)</span> zufällig ausgewählte Variablen um stark korellierte Bäume zu vermeiden.</p>
<p>Dieses Vorgehen wiederholen wir dann <span class="math inline">\(B&gt;1\)</span> mal, so dass wir schlussendlich <span class="math inline">\(B\)</span> Regressionsbäume mithilfe von <span class="math inline">\(B\)</span> Bootstrap Sample geschätzt haben. Ein Random Forest Schätzwert <span class="math inline">\(\hat{y}\)</span> für einen Datenpunkt <span class="math inline">\(x\)</span> berechnet sich dann durch den Durschnittlichen vorhersagewert aller <span class="math inline">\(B\)</span> Bäume:</p>
<p><span class="math display">\[\begin{equation*}
  \hat{y} = \frac{1}{B}\sum_{b=1}^B \hat{y}^{(b)},
\end{equation*}\]</span></p>
<p>wobei <span class="math inline">\(\hat{y}^{(b)}\)</span> der Vorhersagewert generiert durch Baum <span class="math inline">\(b\)</span> ist.</p>
</section>
<section id="random-forests-in-r" class="level3" data-number="4.5.3">
<h3 data-number="4.5.3" class="anchored" data-anchor-id="random-forests-in-r"><span class="header-section-number">4.5.3</span> Random Forests in R</h3>
<p>Ähnlich wie Regresseionsbäume können wir auch Random Forests mithilfe des <code>{tidymodels}</code> Pakets schätzen.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>rf_spec_penguins <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">"regression"</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">100</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>rf_fit_penguins <span class="ot">&lt;-</span> rf_spec_penguins <span class="sc">%&gt;%</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_penguin,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">formula =</span> body_mass_g <span class="sc">~</span>.</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Zuerst erstellen wir mithilfe der <code>rand_forest()</code> Funktion eine Modellspezifikation. Als Argumente übergeben wir wieder den Modus <code>"regression"</code> und zusätzlich das Argument <code>trees = 100</code>, welches Spezifiziert, dass <span class="math inline">\(B=100\)</span>. Das erstellen der Bootstrap Sample, das schätzen der Bäume und die Aggregation wird dann im zweiten Schritt durch die <code>fit()</code> Funktion vorgenommen. Als Argumente für die <code>fit</code> Funktion müssen wir wie gewöhnlich die Daten und die Formel übergeben. Dadurch, dass sowohl das erstellen der Bootstrap Samples als auch das Schätzen der Bäumen eine Zufallskomponente enthält, sollten wir durch die <code>set.seed()</code> Funktion reproduzierbare Ergebnisse ermöglichen.</p>
<p>Nach dem Schätzen des Random Forests können wir durch das Aufrufen des Objekts <code>rf_fit_penguins</code> einige Informationen über den Random Forest extrahieren:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>rf_fit_penguins</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>parsnip model object

Ranger result

Call:
 ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~100,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) 

Type:                             Regression 
Number of trees:                  100 
Sample size:                      333 
Number of independent variables:  7 
Mtry:                             2 
Target node size:                 5 
Variable importance mode:         none 
Splitrule:                        variance 
OOB prediction error (MSE):       87833.61 
R squared (OOB):                  0.8645322 </code></pre>
</div>
</div>
<ul>
<li>Der Parameter <code>Mtry</code> gibt an, wie viele Variablen zufällig für einen Split verwendet werden.</li>
<li>Der Parameter <code>Target node size</code> gibt an, wie viele Datenpunkte mindestens in einem Knoten sein müssen, bevor dieser wieder geteilt wird.</li>
<li><code>OOB prediction error (MSE)</code> gibt an, wie groß der MSE eines OOS Datensatzes ist, welcher im Zuge der Schätazung des Random Forests autmatisch generiert wird.</li>
<li><code>R squared (OOB)</code> gibt für das gleiche OOS Sample den berechneten <span class="math inline">\(R^2\)</span> an.</li>
</ul>
<p>Vorhersagen für die gegebenen Sample können wieder mithilfe der <code>predict()</code> Funktion erstellt werden:<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>data_penguin_cleaned <span class="ot">&lt;-</span> data_penguin <span class="sc">%&gt;%</span> <span class="fu">na.omit</span>()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>rf_fit_penguins <span class="sc">%&gt;%</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(data_penguin_cleaned)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 1
  .pred
  &lt;dbl&gt;
1 3761.
2 3602.
3 3435.
4 3540.
5 3891.</code></pre>
</div>
</div>
</section>
</section>
<section id="übungsaufgaben" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="übungsaufgaben"><span class="header-section-number">4.6</span> Übungsaufgaben</h2>
<section id="theorieaufgaben" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="theorieaufgaben"><span class="header-section-number">4.6.1</span> Theorieaufgaben</h3>
<div id="exr-tree_theory" class="theorem exercise">
<p><span class="theorem-title"><strong>Aufgabe 4.1</strong></span> &nbsp;</p>
<ol type="1">
<li><p>Angenommen ein Regressionsbaum besteht lediglich aus dem Wurzelknoten. Seine Performance wird mit einem linearen Modell verglichen, welches lediglich den Parameter <span class="math inline">\(b_0\)</span> enthält. Ist zu erwarten, dass das Baummodell den Zusammenhang in den Daten besser erklärt, oder das lineare Modell? Begründe die Antwort.</p></li>
<li><p>Angenommen es liegt ein Datensatz vor, welcher lediglich aus einer <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> Variable besteht. Beim betrachten einer Punktewolke fällt auf, dass der Zusammenhang zwischen den beiden Variablen schon sehr einer geraden ähnelt. Ist zu erwarten, dass im Vergleich zu einem einfachen linearen Regressionsmodell ein Regressionsbaum den Zusammenhang besser erklärt?</p></li>
</ol>
</div>
<div id="exr-tree_plot" class="theorem exercise">
<p><span class="theorem-title"><strong>Aufgabe 4.2</strong></span> Gegeben sei folgende Grafik welche die Prognosewerte eines Regressionsbaums zeigt.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol type="1">
<li>Bestimme wie viele Blattknoten der abgebildete Baum enthält.</li>
<li>Formuliere die Funktionsvorschrift des Regressionsbaums als Stückweise definierte Funktion. Runde die visuell abgelesenen Werte auf eine Nachkommastelle.</li>
<li>Ist zu erwarten, dass bei einer einfachen linearen Regression eine ähnlich gute Anpassung an die Daten stattfinden würde?</li>
</ol>
</div>
<div id="exr-create_tree_plot" class="theorem exercise">
<p><span class="theorem-title"><strong>Aufgabe 4.3</strong></span> &nbsp;</p>
<ol type="1">
<li><p>Gegeben seien folgende beiden Feature spaces geschätzten Baummodellen:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Skizziere für beide Abbildungen den entsprechenden Binärbaum unter der Angabe der Splitting Variable, des Schwellenwertes und des Schätzwertes in den Blattknoten. <em>Hinweis: In der unteren Abbildung sind die Schätzwerte in den entsprechenden Ausschnitten in Rot abgebildet.</em></p></li>
<li><p>Gegeben seien folgende beiden Bäume in Binärbaumdarstellung:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Regressions_Baeume_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Skizziere für beide Abbildungen die entsprechenden Featurespaces unter der Angabe der Splitting Variablen, des Schwellenwertes und des Schätzwertes auf den Geraden bzw. in den Regionen.</p></li>
</ol>
</div>
<div id="exr-cp_table" class="theorem exercise">
<p><span class="theorem-title"><strong>Aufgabe 4.4</strong></span> Gegeben seien folgende tabellarisch/hierarchische Darstellung eines Baums:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>n= 300 

node), split, n, deviance, yval
      * denotes terminal node

1) root 300 3516.58000 2.4522780  
  2) x&gt;=3.461538 196   90.79800 0.2780154 *
  3) x&lt; 3.461538 104  752.97340 6.5499260  
    6) x&lt; 0.8528428 26   28.73169 2.9676420 *
    7) x&gt;=0.8528428 78  279.37280 7.7440200 *</code></pre>
</div>
</div>
<p>Außerdem sei folgende <code>CP</code> Tabelle gegeben, welche durch den gleichen Baum erzeugt wurde:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>         CP nsplit rel error    xerror       xstd</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>         a      <span class="dv">0</span>         b <span class="fl">1.0080905</span> <span class="fl">0.07565504</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="fl">0.1265061</span>      <span class="dv">1</span> <span class="fl">0.2399409</span> <span class="fl">0.2481654</span> <span class="fl">0.02622409</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> <span class="fl">0.0500000</span>      <span class="dv">2</span>         c <span class="fl">0.1164630</span> <span class="fl">0.01292697</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Berechne die fehlende Werte <code>a</code>, <code>b</code> und <code>c</code>.</p>
</div>
</section>
<section id="r-aufgaben" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="r-aufgaben"><span class="header-section-number">4.6.2</span> R Aufgaben</h3>
<p>In dieser Übung verwenden wir den bereits bekannten <code>hotel_rates</code> Datensatz aus den letzten Übungen.</p>
<section id="modellvergleiche" class="level4" data-number="4.6.2.1">
<h4 data-number="4.6.2.1" class="anchored" data-anchor-id="modellvergleiche"><span class="header-section-number">4.6.2.1</span> Modellvergleiche</h4>
<p>Verwende die untenstehende Version des <code>hotel_rates</code> Datensatzes für die folgenden Aufgaben.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>hotel_rates_filtered <span class="ot">&lt;-</span> hotel_rates <span class="sc">%&gt;%</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">mutate</span>(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">arrival_month =</span> <span class="fu">factor</span>(<span class="fu">month</span>(arrival_date)),</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">num_guests =</span> adults<span class="sc">+</span>children,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">is_repeated_guest =</span> <span class="fu">factor</span>(is_repeated_guest),</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>   ) <span class="sc">%&gt;%</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">select</span>(num_guests,total_of_special_requests,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>          required_car_parking_spaces,arrival_month,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>          is_repeated_guest,lead_time,stays_in_week_nights,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>          avg_price_per_room,country) <span class="sc">%&gt;%</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="exr-cv_split" class="theorem exercise">
<p><span class="theorem-title"><strong>Aufgabe 4.5</strong></span> Generiere mithilfe des <code>hotel_rates_filtered</code> Datensatzes einen <span class="math inline">\(5\)</span>-fold Cross Validation (CV) Split. Verwende dabei das Seed <code>123</code>.</p>
</div>
<div id="exr-tree_comp" class="theorem exercise">
<p><span class="theorem-title"><strong>Aufgabe 4.6</strong></span> Verwende das CV Objekt aus <a href="#exr-cv_split" class="quarto-xref">Aufgabe&nbsp;<span>4.5</span></a> um jeweils eine multiple lineare Regression, einen Regressionsbaum und einen Randomforest (bestehend aus 500 Bäumen) zu schätzen und vergleiche die OOS Performance anhand den Metriken MSE, <span class="math inline">\(R^2\)</span> und AIC.</p>
</div>
<!-- 

#### Einfluss der Hyperparameter 

In @sec-stoppingcriteria haben wir gesehen, dass die Parameter `cost_complexity` (CP), `tree_depth` (Baumtiefe) und `min_n` (Mindestanzahl der Datenpunkte für einen weiteren Split) die Form des Baumes stark beeinflussen können.

Wir wollen deshalb in den folgenden Übungsaufgaben diesen Einfluss untersuchen.


:::{#erx-ttsplit}

:::

-->
</section>
</section>
</section>
<section id="lösungen" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="lösungen"><span class="header-section-number">4.7</span> Lösungen</h2>
<p>TBA</p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Diese sind durch die Mittelwerte aller benachbarten Punkte gegeben<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Diese muss eventuell zuerst mit dem Befehl <code>install.packages("rpart.plot")</code> installiert werden<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Exemplarisch wurden hier nur die ersten 5 Werte ausgegegben<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03_Wichtige_Konzepte.html" class="pagination-link" aria-label="Weiterführende Konzepte des Dataminings">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Weiterführende Konzepte des Dataminings</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>